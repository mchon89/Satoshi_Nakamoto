Formalizing and Securing Relationships on Public Networks

Nick Szabo Originally published in 1997



Abstract

Smart contracts combine protocols with user interfaces to formalize and secure relationships over computer networks. Objectives and principles for the design of these systems are derived from legal principles, economic theory, and theories of reliable and secure protocols. Similarities and differences between smart contracts and traditional business procedures based on written contracts, controls, and static forms are discussed. By using cryptographic and other security mechanisms, we can secure many algorithmically specifiable relationships from breach by principals, and from eavesdropping or malicious interference by third parties, up to considerations of time, user interface, and completeness of the algorithmic specification. This article discusses protocols with application in important contracting areas, including credit, content rights management, payment systems, and contracts with bearer.

Contents

Introduction

History has seen successive revolutions in the costs of doing global business. First transportation, then manufacturing, and recently communications costs have fallen dramatically. Yet there are still major barriers to doing business internationally. The cost of doing business globally is increasingly dominated by issues of jurisdiction, security, and trust: the costs of developing, maintaining, and securing our relationships.

Despite the recent rise of global computer networks, our institutions still take for granted that we live in a world of paper. We formalize our relationships with written contracts, written laws, and forms designed for paper. Our attitudes and laws regarding intellectual property and privacy have assumed a world of paper which is costly to copy. Increasingly, we can no longer take these deeply embedded, highly evolved paper institutions for granted. Nor, since these institutions involve complex human relationships, can we redesign them overnight. We are entering a period where civilization must once again adapt to a radical new media.

Over the long stretch civilization, paper represents only one of many technologies used to mediate commercial relationships. The Inca used quipu – accounts encoded on strings, a system with interesting tamper-resistance properties. Early Middle Eastern civilizations used clay tokens for thousands of years. These combined the function of, and were a precursor to, both cuneiform writing and coins. Coins started out as lumps of standardize metal and weight. Since these were too expensive to test during a normal business transaction, they came to be stamped by reputable or powerful authorities. Coins played a major role in commerce for thousands of years, but that era is now over.

Business is now dominated by paper and institutions of written literacy. Security measures have included chops, seals, and written signatures. Value has been transered via bills of exchange (which evolved into checks), bearer certificates, and accounts using the double-entry bookeeping system. Most importantly, we take for granted that contracts and law are written on this static medium, to be interpreted and enforced by human authorities.

We are now entering an era of online communications and software "literacy". The "physics of cyberspace", studied by computer scientists, are radically different from the properties of paper, to an even greater degree than paper was different from string, clay, and metal. Not only written but also aural, visual, and other sensory media can be combined. Most importantly, digital media are dynamic – they not only transmit information, but can also make some kinds of decisions. Digital media can perform calculations, directly operate machinery, and work through some kinds of reasoning much more efficiently than humans.

The movement from static to dynamic media promises to bring about a fourth cost revolution in the related areas of jurisdiction, trust, and security. Impacts on business will be felt in law, accounting, auditing, billing, collections, contracts, confidentiality, and so on: in short, the entire nature of our business relationships will be altered in ways only partially foreseeable.

The main traditional way to formalize a business relationship is the contract, a set of promises agreed to in a "meeting of the minds". We naturally think of contracts as written, but oral agreements are also considered contracts, and have been around since prehistory. The contract is the basic building block of a market economy. Over many centuries of cultural evolution has emerged both the concept of contract and principles related to it, encoded into common law. Such evolved structures are often prohibitively costly to rederive. If we started from scratch, using reason and experience, it could take many centuries to redevelop sophisticated ideas like contract law and property rights that make the modern market work. But the digital revolution challenges us to develop new institutions in a much shorter period of time. By extracting from our current laws, procedures, and theories those principles which remain applicable in cyberspace, we can retain much of this deep tradition, and greatly shorten the time needed to develop useful digital institutions.

Computers make possible the running of algorithms heretofore prohibitively costly, and networks the quicker transmission of larger and more sophisticated messages. Furthermore, computer scientists and cryptographers have recently discovered many new and quite interesting algorithms. Combining these messages and algorithms makes possible a wide variety of new protocols. These protocols, running on public networks such as the Internet, both challenge and enable us to formalize and secure new kinds of relationships in this new environment, just as contract law, business forms, and accounting controls have long formalized and secured business relationships in the paper-based world.

In electronic commerce so far, the design criteria important for automating contract execution have come from disparate fields like economics and cryptography, with little cross-communication: little awareness of the technology on the one hand, and little awareness of its best business uses other. These efforts are striving after common objectives, and converge on the concept of smart contracts[1].

Smart contracts reduce mental and computational transaction costs imposed by either principals, third parties, or their tools. The contractual phases of search, negotiation, commitment, performance, and adjudication constitute the realm of smart contracts. This article covers all phases, with an emphasis on performance. Smart contracts utilize protocols and user interfaces to facilitate all steps of the contracting process. This gives us new ways to formalize and secure digital relationships which are far more functional than their inanimate paper-based ancestors.

Contracts Embedded in the World

The basic idea behind smart contracts is that many kinds of contractual clauses (such as collateral, bonding, delineation of property rights, etc.) can be embedded in the hardware and software we deal with, in such a way as to make breach of contract expensive (if desired, sometimes prohibitively so) for the breacher. A canonical real-life example, which we might consider to be the primitive ancestor of smart contracts, is the humble vending machine. Within a limited amount of potential loss (the amount in the till should be less than the cost of breaching the mechanism), the machine takes in coins, and via a simple mechanism, which makes a freshman computer science problem in design with finite automata, dispense change and product according to the displayed price. The vending machine is a contract with bearer: anybody with coins can participate in an exchange with the vendor. The lockbox and other security mechanisms protect the stored coins and contents from attackers, sufficiently to allow profitable deployment of vending machines in a wide variety of areas.

Smart contracts go beyond the vending machine in proposing to embed contracts in all sorts of property that is valuable and controlled by digital means. Smart contracts reference that property in a dynamic, often proactively enforced form, and provide much better observation and verification where proactive measures must fall short.

As another example, consider a hypothetical digital security system for automobiles. The smart contract design strategy suggests that we successively refine security protocols to more fully embed in a property the contractual terms which deal with it. These protocols would give control of the cryptographic keys for operating the property to the person who rightfully owns that property, based on the terms of the contract. In the most straightforward implementation, the car can be rendered inoperable unless the proper challenge-response protocol is completed with its rightful owner, preventing theft. But if the car is being used to secure credit, strong security implemented in this traditional way would create a headache for the creditor – the repo man would no longer be able to confiscate a deadbeat's car. To redress this problem, we can create a smart lien protocol: if the owner fails to make payments, the smart contract invokes the lien protocol, which returns control of the car keys to the bank. This protocol might be much cheaper and more effective than a repo man. A further reification would provably remove the lien when the loan has been paid off, as well as account for hardship and operational exceptions. For example, it would be rude to revoke operation of the car while it's doing 75 down the freeway.

In this process of successive refinement we've gone from a crude security system to a reified contract:

(1) A lock to selectively let in the owner and exlude third parties; (2) A back door to let in the creditor; (3a) Creditor back door switched on only upon nonpayment for a certain period of time; and (3b) The final electronic payment permanently switches off the back door.

Mature security systems will be undertaking different behavior for different contracts. To continue with our example, if the automobile contract were a lease, the final payment would switch off leasee access; for purchase on credit, it would switch off creditor access. A security system, by successive redesign, increasingly approaches the logic of the contract which governs the rights and obligations covering the object, information, or computation being secured. Qualitatively different contractual terms, as well as technological differences in the property, give rise to the need for different protocols.

Contemporary Practice

Accounting Controls

Outside of the financial cryptography community, and long predating it, there is a deep tradition of protocols used in the course of performing contracts. These protocols consist of a flow of forms ("data flow", canonically displayed in data flow diagrams), along with checks and procedures called "controls". Controls serve many of the same functions as cryptographic protocols: integrity, authorization, and so on. This article uses "control protocols" or simply "controls" to refer to this combination of data flow and controls.

Control protocols, and the professions of auditing and accounting[2] based on them, play a critical but ill-analyzed role in our economy. Economists lump them, along with other costs of negotiating and ensuring the performance of contracts, under their catch-all rubric of "transaction costs". But without controls, large corporations and the economies of scale they create would not be possible. Controls allow a quarrelsome species ill-suited to organizations larger than small tribes to work together on vast projects like manufacturing jumbo jets and running hospitals. These control protocols are the result of many centuries of business experience and have a long future ahead of them, but the digital revolution will soon cause these paper-era techniques to be dramatically augmented by, and eventually integrate into, smart contracts.

Controls enable auditing of contract performances, allowing more precise inference of the behavior of an agent. Auditing is costly, so it is undertaken by random sampling. Economists study the substitutability between the probability of verifying a breach and the magnitude of legal fines, where physical enforcement is used. Conceivably, one could substitute increasingly high penalties for increasingly rarer and less expensive auditing. However, this is not robust to real-world conditions of imperfect information.

Since controls primarily address the implicit contracts between employees and employer, there is little mapping from contract to control. A secondary function of controls to to monitor contracts with other organizations. Here there is some mapping, but it is confounded by the integration of the two functions in most controls. Rather than based on contractual terms, controls are typically based on managerial authorization.

Controls are typically based around amounts of money and quantities of goods. A canonical control is double entry bookkeeping, where two books are kept, and there must be arithmetic reconciliation between the books. To conceal an irregularity, necessary to omit from both sides, or to record entries offsetting the irregularity. Notice that there is a problem distinguishing error from fraud. This problem crops up in many areas in both auditing and smart contracts. To illustrate, here are two common control techniques:

Imprest: this is a family of controls involving the receipt or disbursement of bearer certificates (usually notes and coins). One example is the protocol used at most movie theaters. Entry is segregated from payment by introducing tickets and establishing two employee roles, the ticket seller in a booth, and the ticket stub salesman at the entrance. Periodically, a bookkeeper reconciles the number of tickets with the total paid. Discrepancy again indicates fraud or error.

Customer audit: Techniques to get the customer to generate initial documentation of a transaction. For example, pricing goods at $.99 forces the employee to open the cash register to make change, generating a receipt.

A complete control protocol typically features the generation of initial documentation, segregation of duties, and arithmetic reconciliation of quantities of goods, standard service events, and money.

Of these, the segregation of duties deserves special comment.

In a large business, transactions are divided up so that no single person can commit fraud. Segregation of duties is an instance of the principle of required conspiracy. For example, the functions of warehouse/delivery, sales, and receipt of payments are each performed by different parties, with a policy that each party reports every transaction to a fourth function, accounting. Any singular reported activity (e.g., delivery without receipt of payment) indicates potential fraud (e.g., a delivery was made to a customer and the payment pocketed instead of being put into the corporate treasury). Segregation of duties is the auditor's favorite tool. Where it is absent the auditor cries "foul", just as a good engineer would react to a single point of failure. Many cryptographic systems have rightfully gone down to commercial failure because they ground down to trust in a single entity rather than segregating functions so as to require conspiracy.

There are least three significant differences between the scope and emphasis of smart contracts and controls. Controls are paper-era protocols designed around static forms, place little emphasis on confidentiality, and are based on management authorizations rather than one-to-one relationships.

Smart contracts can be based on a wide variety of interactive protocols and user interfaces, and can be involved in a wide variety of kinds of contractual performance. Control protocols, developed in the era of paper, are based on static forms passed as messages and processed in tables and spreadsheets. Controls focus on money and counts of standardized goods and service events, easily recorded by numbers and manipulated by arithmetic, while mostly ignoring other kinds or aspects of contractual performance. Checksums on numbers, the basis of reconciliation, are crude and forgeable compared to cryptographic hashes. Electronic Data Interchange (EDI) keeps these static forms and maintains reliance on controls. It uses cryptographic hashes for nothing more sophisticated than integrity checks on individual messages.

Controls place little emphasis on confidentiality, at least in the modern accounting literature. The emphasis on confidentiality in paper-era protocols is lacking because violation of often implicit confidences, via replication of data, was much more difficult with paper. Furthermore, technologies for protecting confidentiality while auditing were not feasible. Businesses traditionally trusted accounting firms with confidences, a trust that has eroded over the last century, and will erode still further as accounting firms start taking advantage of the vast amounts of inside and marketing information they are collecting from their customers' databases during audits. Using paper-based protocols in a digital world, there are few effective controls against the auditors themselves. Post-unforgeable transaction logs and multiparty secure computation, discussed below, indicate the possibility of cryptographic protocols to implement less relavatory but more effective auditing trails and controls; their use may be able to ameliorate the growing problems with data mining and breach of confidentiality.

Auditors place quite a bit of trust in management to authorize transactions in a secure and productive manner. Objecting to this dual trust in management and distrust of employees inherent in the accounting tradition, there has been a trend in the last two decades towards a loosening of controls as a part of hierarchy flattening and empowerment of professional employees. Unfortunately, loose controls have led to several recent scandals in the banking and investment trade. The most recent view is that there must be a learned tradeoff between controls and empowerment. The smart contract view is that we need smarter controls, originating at the ownership of the company, and entailing less asymmetry between management and other professional employees. This means converting many implicit employee contracts to more explicit smart contracts based on more direct relationships between owners (or at least their directors) and employees, and symmetric formalizations between employees.

Although most of these differences are biased against controls, these traditional protocols have a long future ahead of them, simply because they have a long past. They are highly evolved, hundreds of years old (double-entry bookkeeping, for example, predates the Renaissance). Smart contracts will incorporate many techniques and strategies from control protocols, such as generation of an initial record, segregation of duties, and reconciliation. It will not be long, however, before smart contracts start augmenting and transforming traditional business procedures, making a wide variety of new business structures possible and in the long run replacing traditional controls.

Electronic Data Interchange

Electronic Data Interchange (EDI) is the computer-to-computer communication of standardized business transactions between organizations, in a standard format that permits the receiver to perform the intended transaction. It renders traditional static business forms in cyberspace, and maintains the dependence on traditional controls. Beyond simple encryption and integrity checks, EDI does not take advantage of algorithms and protocols to add security and "smarts" to business relationships. It enables more rapid execution of traditional negotiation and performance monitoring procedures.

EDI loses some security features provided by physical paper (such as difficulty of copying) while not gaining advantages from the wide variety of protocols possible beyond simple message-passing of static forms. This article examples a much richer set of protocols.

EDI contracts tend to be merely reiterations of existing terms and conditions, with only some timing expectations changed for the electronic environment. By redesigning our business relationships to take advantage of a richer set of protocols, smart contracts can take us far beyond the paper-based paradigm of shipping around forms in a secure manner.

The following classification, derived from Sokol[3], illustrates the variety of business forms that have been rendered in electronic form:

Administrative Product code and price catalogs Catalog updates Forecasts and plans Deals and promotions Statements Prepurchasing Requests for quote (&response) Inventory inquiry/advice Purchasing Purchase order & acknowledgment Purchase order change & acknowledgment of change Material release Point of sale/inventory on hand Shipping and Receiving Shipment status inquiry & response Advance shipment notification Bill of Lading Freight bill Warehouse Inventory inquiry & status Shipping notice Receipt confirmation Shipment order Shipment confirmation Customs Declaration Release Billing and Paying Invoice Payment remittance Credit and debit memos Receipts

Automata as Authority

Focal (or Schelling) points are often designed and submitted into negotiations by one side or another, both to bias the negotiations and to reduce their cost. The fixed price at the supermarket (instead of haggling), the prewritten contract the appliance salesman presents you, etc. are examples of hard focal points. They are simply agreed to right away; they serve as the end as well as the beginning of negotiations, because haggling over whether the nearest neighbor focal point is better is too expensive for both parties.

There are many weak enforcement mechanisms which also serve a similar purpose, like the little arms in parking garages that prevent you from leaving without paying, the sawhorses and tape around construction sites, most fences, etc. Civilization is filled with contracts embedded in the world.

More subtle examples include taxi meters, cash register readouts, computer displays, and so on. As with hard focal points, the cost of haggling can often be reduced by invoking technology as authority. "I'm sorry, but that's what the computer says", argue clerks around the world. "I know I estimated $50 to get to Manhattan, but the meter reads $75", says the taxi driver.

Dimensions of Contract Design

Economists stress two properties important to good contract design: observability by principals and verifiability by third parties such as auditors and adjudicators. From the traditions behind contract law and the objectives of data security, we derive a third objective, privity. We flesh out the dimensions of contract design by disentangling mental from computational transaction costs, classifying the kinds of enforceability, characterizing the temporal phases of contracting, and discussing the nature of tradeoffs between the three design objectives.

Mental and Computational Transaction Costs

The costs that smart contracts address are lumped by economists under the catch-all rubric of "transaction costs". We can divide these into mental and computational transaction costs.

One major category of costs include the cost of anticipating, agreeing to, and clearly writing down the various eventualities. These are largely mental transaction costs, although online research tools, for example, may bring more information about eventualities.

Most contractual dispute involves an unforeseen or unspecified eventuality. We lack a good model for this. Such a model would account for the computational costs of foreseeing these eventualities, some of which may be uncomputable (and therefore of infinite cost). Where eventualities remain unspecified, contracts remain incomplete.

Where counterparties lack focal points, they lack a meeting of minds. Negotiation addresses this gap; the farther apart the focal points (in terms of value), the more expensive the negotiations. There are a variety of institutions of negotiation, which economists study under the rubric of "mechanisms". These range from simple haggling to sophisticated auctions and exchanges.

Contracting Phases

For the temporal phases of contracting we use the following schema, classified according to the two-phase model used in economics:

Ex-Ante Search Negotiation Commitment Ex-Post Performance Adjudication

Smart contracts often involve trusted third parties, exemplified by an intermediary, who is involved in the performance, and an adjudicator, who is invoked to resolve disputes arising out of performance (or lack thereof). Intermediaries can operate during search, negotiation, commitment, and/or performance. Hidden knowledge, or adverse selection, occurs ex-ante; hidden actions (moral hazards) occur ex-post.

Here are some examples of contemporary electronic commerce activities and the phases of contracting they deal with:

EDI commitment, performance Contract drafting negotiations Web surfing search Payment performance Online exchange search, negotiation, commitment "I agree" button commitment

Smart contracts often involve trusted third parties, exemplified by an intermediary, who is involved in the performance, and an adjudicator, who is invoked to resolve disputes arising out of performance (or lack thereof). Intermediaries can operate during search, negotiation, commitment, and/or performance. Hidden knowledge, or adverse selection, occurs ex-ante; hidden actions (moral hazards) occur ex-post.

Here are some examples of contemporary electronic commerce activities and the phases of contracting they deal with:

EDI commitment, performance Contract drafting negotiations Web surfing search Payment performance Online exchange search, negotiation, commitment "I agree" button commitment

This article covers all phases, with a particular emphasis on performance.

Observability, Hidden Knowledge, and Hidden Actions

The first objective of smart contract design is observability, the ability of the principals to observe each others' performance of the contract, or to prove their performance to other principals. The field of accounting is, roughly speaking, primarily concerned with making contracts an organization is involved in more observable.

Economists discuss "hidden knowledge", also known as "adverse selection", which can occur due to lack of ability to observe potential counterparties during the search and negotiation phases. Another major problem is "hidden actions", also known as "moral hazard", which can occur due to the lack of observability and ability to drop out of contract during the performance phase of a contract.

One important task of smart contracts, that has been largely overlooked by traditional EDI, is critical to "the meeting of the minds" that is at the heart of a contract: communicating the semantics of the protocols to the parties involved. There is ample opportunity in smart contracts for "smart fine print": actions taken by the software hidden from a party to the transaction.

Here's a small example of smart fine print:

if (x == true) { printf("x is false"); }

Without user interfaces smart contracts are largely invisible, like the electronics in newer car engines. This is both a blessing – counterparties don't have to feel like they're dealing with user-hostile computers – and a curse – the "smart fine print" problem of hidden actions.

To properly communicate transaction semantics, we need good visual metaphors for the elements of the contract. These would hide the details of the protocol without surrendering control over the knowledge and execution of contract terms. For example, encryption can be shown by putting the document in an envelope, and a digital signature by affixing a seal onto the document or envelope.

Online Enforceability

Amid all the hype about "information warfare", lost in the noise is the fact that it is impossible to commit an act of physical violence over the Net. That includes not only all physical crimes of coercion, but also arrest, incarceration, and other traditional methods of law enforcement. Because of this fact, and the jurisdictional swamp that is the multinational Internet, this article concentrates on means of protecting against breach and third parties that do not rely on law enforcement.

We can categorize the security measures against breach, eavesdropping, and interference in the following manner:

Proactive - breaching actions rendered impossible - either side can drop out with minimal loss upon counterparty breach Reactive Deterrence - reputation - physical enforcement third parties: tort law Damage Recovery - secured transaction - reputation - physical enforcement principals: contract law third parties: tort law

Currently, the most prevalent forms of security software are not proactive cryptography, but reactive and panoptic methods like virus scanning software, filtering firewalls, traceroutes of attackers, etc. Once modern cryptographic protocols are more widely deployed, the balance will likely shift towards preventative security.

Verifiability by Adjudicators

Reactive measures rely upon two areas: verifiability and penalties. As discussed in the section on accounting controls, under ideal economic conditions, the statistical distribution of verification failures is known, so that verification costs and penalties are can be traded off neatly. But with imperfect information, the jurisdictional swamp, and lack of collateral or other security, collection of damage awards is even more severely limited than in contracts confined to traditional geographic jurisdictions. Reputation costs may be the only practical source of penalties in many cases. For reactive measures to work, high verifiability is critical.

So our second objective is verifiability, the ability of a principal to prove to an adjudicator that a contract has been performed or breached, or the ability of the adjudicator to find this out by other means. The disciplines of auditing and investigation roughly correspond with verification of contract performance.

Privity: Protection from Third Parties

Our third objective of smart contract design is privity, the principle that knowledge and control over the contents and performance of a contract should be distributed among parties only as much as is necessary for the performance of that contract. This is a generalization of the common law principle of contract privity, which states that third parties, other than the designated adjudicators and intermediaries, should have no say in the enforcement of a contract. To maintain knowledge and control, performance must be encapsulated: protected from outside influences, especially sophisticated attacks. This is the idea behind both the legal doctrine of privity, which restricts redress to the parties to a contract, and the idea of property rights.

Attacks against privity are epitomized by third parties Eve the eavesdropper, a passive observer of contents or performance, and malicious Mallet, who actively interferes with performance or steals service. Under this model privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is subsumed under privity, as are property rights. The most common definitions of "security" in the online world roughly correspond to the goal of privity.

Our generalized privity thus encompasses property rights as stable objects linked to particular contracts (and thereby the parties in privity to such contracts, the "owners"). Privity creates a clear boundary within which operate a coherent set of rights, responsibilities, and the knowledge with which to carry out those responsibilities and protect those rights. Clarified boundaries also allow accountability. Protection from extraneous interference allows us to focus responsibility for the consequences of contract-related activity onto the parties to the contract.

Trading Off Contract Design Objectives

Privity says that we want to minimize vulnerability to third parties. Verifiability and observability often require that we invoke them. An intermediary must be trusted with some of the contents and/or performance of the contract. An adjudicator must be trusted with some of the contents, and some of the history of performance, and to resolve disputes and invoke penalties fairly. In smart contract design we want to get the most out of intermediaries and adjudicator, while minimizing exposure to them. One common outcome is that confidentiality is violated only in case of dispute.

Many kinds of specific performance are often entrusted to intermediaries. We must be able to trust the intermediary (credit agency, anti-virus software vendor, certificate intermediary, digital cash mint, etc.) with their particular claims (about creditworthiness, dangerous byte patterns, identity, conservation of the money supply, etc.) As Ronald Reagan remarked in a slightly different context, "trust but verify". To deserve our trust, intermediaries must convince us that their claims are true. We need to be able to "ping" their veracity, verifying that certain claimed transactions in fact occurred. An entire profession exists in market economies to perform this function: auditing.

Ideally, observability and verifiability can also include the ability to differentiate between intentional violations of the contract and good faith errors, but this is difficult in practice, since the difference is often largely one of subjective, unrevealed intent.

Building Blocks of Smart Contract Protocols

Protocols

A protocol[5] in computer science is a sequence of messages between at least two computers. At a higher level of abstraction, a protocol consists of algorithms communicating via messages. These programs act as proxies, or agents, for human users, who communicate their preferences via users interfaces. We distinguish protocol endpoints by names such as "Alice" and "Bob", but it should be kept in mind that the end points are really computer processing units, which may or may not be under the control of, or taking actions contrary to the intent of, the human user. Human users typically do not have full knowledge of the protocol in question, but rather a metaphorical understanding obtained via user interface, manuals, and so on. Unlike most real-world contracts, protocols must be unambiguous and complete.

Protocols come in three basic types. I have modified the terminology of Schneier[6] to match more closely to the corresponding business terminology:

self-enforcing: Alice Bob, mediated: Alice intermediary Bob adjudicated: (Alice Bob) --> [evidence] --> adjudicator

The corresponding smart contracts elaborate on "Alice" to distinguish between the software (in two components, the endpoint of protocol and the user interface), and Alice herself. Cryptographic and other computer security mechanisms give us a kit of tools and parts from which we can build protocols, which form the basis of smart contracts.

The "Physics of Cyberspace"

The security properties of physical media are based on physical properties we often take for granted, for example the unforgeability of an atom of gold. The structural constraints ("physics") of cyberspace relevant to security are described by the mathematical theories studied by computer scientists, especially in the specialty called cryptography. Here are the important "fundamental particles" of the cryptographic universe:

-- pseudorandom function families --> secret key encryption, hash, MAC, ... -- trapdoor one-way functions --> public key encryption -- pseudorandom bit generators --> generate keys, padding, cookies -- information-theoretic/unconditional --> one-time pads

These "particles" are potent building blocks for engineering secure protocols. Imagine a material so tough, it is completely impervious to a supernova, and so cheap you could use it to make walls, locks, safes, and envelopes to protect everyday items. This is not just a metaphor: cracking a 4,096 bit RSA key with best known algorithm really would require more electrical power for the computers than the power produced by a supernova. These cryptographic primitives promise to be a main driving force of the fourth cost revolution for global business.

Cryptographic Protocols

A family of protocols, called cryptographic protocols because their first application was computerized "secret writing", provide many of the basic building blocks that implement the improved tradeoffs between observability, verifiability, privity, and enforceability in smart contracts. Contrary to the common wisdom, obscurity is often critical to security. Cryptographic protocols are built around foci of obscurity called keys. A key's immense unknown randomness allows the rest of the system to be simple and public. The obscurity of a large random number, so vast that a lucky guess is astronomically unlikely, is the foundation upon which cryptographic protocols, and smart contracts based on them, are built.

Two significant cautions are in order when thinking about how cryptographic protocols can be used in online relationships. The first is that protocols usually provide security "up to" some assumption. This assumption is a remaining weak point which a complete working system must address in some reasonable manner. One common endpoint is is assumptions about trusted third parties. Often the degree or function of the trust is not well specified, and it is up to the real-world systems analyst to characterize and ameliorate these exposures. The best mediated protocols only trust the intermediary or counterparty with a well limited function.

Even without trusted third parties, cryptographic protocols often ground out in trust of the counterparty. For example, encryption of a message provides confidentiality up to the actions of parties with decrypting keys. Encryption does not stop key holders from posting plain text to Usenet. We cannot just say that encryption provides "confidentiality" and leave our concern for confidentiality at that.

The second caution is that much of the terminology used in the cryptographic literature to name protocols ("signatures", "cash", etc.) is misleading. Sometimes the terminology falls short on substantial matters: a "digital signature", for example, is not biometric and is based on a key that can easily be copied if not protected by another mechanism. Often cryptographic protocols can be generalized to much wider purposes than implied by the label. For example, "digital cash" is a very general protocol which can implement a wide variety of bearer certificates and conservation wrappers for distributed objects.

Attacks against Smart Contracts

Protocols for smart contracts should be structured in such a way as to make their contracts

robust against naive vandalism, and robust against sophisticated, incentive compatible (rational) attack

A vandal can be a strategy or sub-strategy of a game whose utility is at least partially a function of one's own negative utility; or it can be a mistake by a contracting party to the same effect. "Naive" simply refers to both lack of forethought as to the consequences of an attack , as well as the relatively low amount of resources expended to enable that attack. Naive vandalism is common enough that it must be taken into consideration. A third category, (c) sophisticated vandalism (where the vandals can and are willing to sacrifice substantial resources), for example a military attack by third parties, is of a special and difficult kind that doesn't often arise in typical contracting, so that we can place it in a separate category and ignore it here. The distinction between naive and sophisticated strategies has been computationally formalized in algorithmic information theory.

The expected loss due to third party attack is called the exposure. The cost of third parties to defeat the security mechanism is the disruption cost. If the disruption cost is greater than the expected benefit, we can expect an incentive compatible attacker to disrupt the security.

Public and Secret Key Cryptography

One of the drivers of the trust cost revolution will likely be the wide variety of new cryptographic protocols that have emerged in recent years. The most traditional kind of cryptography is secret key cryptography, in which Alice and Bob (our exemplar parties to a smart contract) use a single shared, prearranged key to encrypt messages between them. A fundamental problem we will see throughout these protocols is the need to keep keys secret, and public key cryptography helps solve this. In this technique, Alice generates two keys, called the private and public keys. She keeps the private key secret and well protected, and publishes the public key. When Bob wishes to send a message to Alice, he encrypts a message with her public key, sends the encrypted message, and she decrypts the message with her private key. The private key provides a "trapdoor" that allows Alice to compute an easy inverse of the encryption function that used the public key. The public key provides no clue as to what the private key is, even though they are mathematically related. The RSA algorithm is the most widely used method of public key cryptography.

Public Authentication

Public key cryptography also makes possible a wide variety of digital signatures. These proves that a piece of data (hereafter referred to as just an "object") was in active contact with the private key corresponding to the signature: the object was actively "signed" with that key. There are two steps to an authentication protocol: signing and verification. These may occur synchronously, or, in many public protocols, a signature may be verified at some distant time in the future.

The digital signature probably should have been called a "digital stamp" or "digital seal" since its function resembles more those methods than an autograph. In particular, it is not biometric like an autograph, although incorporation of a typed-in password as part of the private key used to sign can sometimes substitute for an autograph. In many Asian countries, a hand-carved wooden block, called a "chop", is often used instead of autographs. Every chop is unique, and because of the unique carving and wood grain cannot be copied. A digital signature is similar to the chop, since every newly generated key is unique, but it is trivial to copy the key if obtained from the holder. A digital signature relies on the assumption that the holder will keep the private key secret.

A blind signature publically authenticates privy information (but can we use non-privy signatures blindly as well?). This is a digital signature and secret-key encryption protocol that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. It's like stamping an unknown document through carbon paper (without having to worry about smudging). The effect is that Bob "signs" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't sign a blank check. Blind signatures used in digital bearer certificates, where Bob is the clearing agent, and in Chaumian credentials, where Bob is the credential issuer.

Privy Authentication

The blind signature is one example of the many "magic ink signatures" cryptographers have invented. Another class of these protocols are used to limit the parties allowed to either verify the signature or to learn the identity of the signer. The most privy are the zero-knowledge proofs, where only the counterparty can authenticate the prover. Designated confirmer signatures allow the signer to designate particular counterparties as verifiers. For example, a business could give particular auditors, investigators, or adjudicators the authority to verify signed objects, while other third parties, such as competitors, can learn nothing from the signature. Group signatures allow members to sign as an authentic member of a group, without revealing which member made the signature.

Protection of Keys

So far, we've assumed parties like Alice and Bob are monolithic. But in the world of smart contracts, they will use computer-based software agents and smart cards to do their electronic bidding. Keys are not necessarily tied to identities, and the task of doing such binding turns out to be more difficult than at first glance. Once keys are bound, they need to be well protected, but wide area network connections are notoriously vulnerable to hacking.

If we assume that the attacker has the ability to intercept and redirect any messages in the network protocol, as is the case on wide area networks such as the Internet, then we must also assume, for practical all commercial operating systems, that they would also be able to invade client if not merchant computers and find any keys lying on the disk.

There's no completely satisfactory solution to end point operations security from network-based attacks, but here's a strategy for practically defanging this problem for public-key based systems:

All public key operation can be performed inside an unreadable hardware board or smart card on a machine with a very narrow serial-line connection (ie, it carries only a simple single-use protocol with well-verified security) to a dedicated firewall. This is economical for high traffic servers, but may be less practical for individual users. Besides better security, it has the added advantage that hardware speeds up the public key computations.

If Mallet's capability is to physically seize the machine, a weaker form of key protection will suffice. The trick is to hold the keys in volatile memory. This makes the PC proof from physical attacks – all that needed to destroy the keys is to turn off the PC. If the key backups can be hidden in a different, secure physical location, this allows the user of this PC to encrypt large amounts of data both on the PC itself and on public computer networks, without fear that physical attack against the PC will compromise that data. The data is still vulnerable to a "rubber hose attack" where the owner is coerced into revealing the hidden keys.

Capabilities

Object-oriented, or capability, security is a deep and promising area, but beyond the scope of this article. Capabilities can potentially simplify the design of many distributed security protocols. Instead of developing a new or modified cryptographic protocol for each contracting problem, capabilities may allow us to design a rich variety of distributed security protocols over a common cryptographic framework.

For more information see Introduction to Capability Based Security.

Quora

Quorum distribution of performance or control over resources can be based on the secret sharing of keys needed to perform or control a resource. These are also known as threshold techniques. These are methods of splitting a key (and thus control over any object encrypted with that key) into N parts, of which only M are needed to recreate the key, but less than M of the parts provide no information about the key. Secret sharing is a potent tool for distributing control over objects between principals.

Markus Jacobsson has designed a quorum of mints for signing digital coins, for example. Quorum establishes a "required conspiracy" of M out of N to perform a function, providing an option for stronger protection than the typical 2 out of N used in segregation of duties, and greater confidence in the security underlying the segregation.

Post-Unforgeable Transaction Logs

Traditionally, auditors have contacted counterparties in order to verify that a transaction actually took place (The "principle of required conspiracy" at work again). With post-unforgeable logs, via a hierarchical system of one-way hash functions, a party can publically commit to transactions as they are completed by publishing signed cumulative hashes of the transaction stream. The confidentiality of the transaction is fully maintained until an auditor "pings" the transaction to determine its actual nature. The counterparty identity can remain confidential, because it is not required to establish the other facts of the transaction. The only attack is to forge transactions in real time, as the transaction itself takes place, which in most practical cases will be unfeasible. Most accounting fraud involves analyzing sets of completed transactions and then forging them to make them compute to a desired counterfactual result.

Mutually Confidential Computation

Cryptographers have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties. So, for example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas, set up the virtual computer with these formulas, and each input our own private data. We could only learn only as much about the other participants' inputs as we could infer from our own inputs and the output.

There are two major complications. The first is that this virtual computer is very slow: one machine instruction per network message. The second is that some parties learn the results before others. Several papers have disussed the fraction of parties one must trust in order to be assured of learning the correct output. The mechanism must be constructed so that a sufficient number of parties have an incentive to pass on the correct result, or reputation, side contracts, etc. used to the same effect.

With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the two complications, we usually construct more limited protocols out of more efficient elements.

Trusted Third Party

Mathematically Trustworthy Protocol

Multiparty secure computer theory, by making possible privy virtual intermediation, has major implications for all phases of contracting. This can be seen most clearly in the area of negotiations. A "mechanism" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.

Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, to their shared virtual computer which has one instruction, "A greater than B?". The computer then returns "true" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism "blind bargaining" with no trusted intermediary.

In principle, since any computable problem can be solved on this virtual computer (they are "Turing complete"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, these secure virtual computers run very slowly (one virtual machine instruction per network message), and the order in which participants learn results often matters. But the existence proof, that any economic mechanism can be run without a trusted intermediary, up to temporal issues, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining "hard" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), (b) nonsimultaneity problems in learning the decision, and (c) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract).

Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contracts can be perfectly and costlessly enforced. Some of the "transaction cost" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.

Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.

The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.

With mutually confidential auditing we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, and summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle may lead us to practical solutions.

Contracts with Bearer

Bearer Certificates

Bearer certificates implement transferable rights on standardized contracts. Each kind of contract (for example, each denomination of "coin" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.

In the most straightforward bearer certificate protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and add it to a list of issued certificates. The transfer agent clears a transfer by checking the signature to identify and nature of the bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.

Unlinkable Transfers

Unlinkability can be provided by combining the second variation above, a list of cleared certificates, with blind signatures and a mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a "plate" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.

Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or "double blinded" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.

Bearer certificates come in an "online" variety, cleared during every transfer, and thus both verifiable and observable, and an "offline" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).

This unlinkability is often called "anonymity", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.

When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash protocol from DigiCash actually takes advantage of this ambiguity, second-transferring certificates on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.

Conserved Objects

Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes "scarce" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor – as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.

Digital Cash

Digital cash is the premier example of a digital bearer certificate. The issue and transfer agent is called a "mint". Bearer certificate protocols enable online payment while honoring the characteristics desired of bearer notes, especially unforgeability (via the clearing mechanism) and transfer confidentiality (via mixing and blinding).

To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. Potential smart contract protocols in this area are discussed under Credit.

Content Rights Management

Content protection contracts are valuable in that they incentive publishers to allow users to view content directly, rather than indirectly and partially via queries to remote servers. Content protection of software distributed online would allow it to be run locally rather than remotely, while enforcing the contract rights and copyrights of the publisher against the user. This local usage billing of software often goes under the rubric of "superdistribution"[11].

Watermarks

Watermark schemes work by altering less significant bits of content – usually a picture; sound works less well and text is difficult. These altered bits typically contain the identities of the publisher and viewer, and perhaps other information related to the contract. The idea is that, when investigators scan released content, the watermark will finger the breacher of the contract (or violator of copyright law).

Watermark investigation can be assisted by a quite inexpensive technique, Web spiders. These spiders look for redistributed watermarked material on the Web. The customer originating the copy can then be fingered.

One attack against watermarks is to overwrite likely watermark bits with other patterns legitimate to viewing software. The entanglement of watermark bits with bits important to the picture can be made rather obscure, but not strongly so by the standards of cryptography. Another attack is to steal content from a customer and distribute it as is. The watermark will finger the victim, rather than the thief.

All watermark schemes can be defeated with sufficient effort. These schemes can then be distributed as software worldwide. Once the initial effort is put into breaking a scheme, the marginal cost of breaking it is minimal. Furthermore, once the watermark is removed, the content can be distributed and even published[12] with secure anonymity.

In sum, watermark schemes can add significant risk to the copying of of low value or ephemeral information. This will be sufficient for many kinds of content, such as news or product updates. It won't stop, for long, the redistribution of high-value content. Since watermarks require traceable identification, they reduce customer privacy and require the inconvenience of registration and authentication, adding to the transaction costs of content purchase.

Controlled CPUs

Contrary to the hype, there is no strong content protection software. Watermarks are as close as we've come, and they fall far short of the standards of computer security. Large sums have gone into attempts to develop such technology, resulting in hundreds of patents but no substantial results.

As a result, some publishers have begun putting their research dollars into a radical alternative, innocuously dubbed the "secure CPU" (SPU)[13]. This is a CPU that is "secure" against the owner of the computer! To enforce copyright or content contracts, the SPU monitors all content-related activity. Some marketing literature even lists, alongside the traditional copyright, a new "right" of publishers to monitor the usage of their content. Remarkably enough, these panoptic non-personal computers are the focus of major R&D efforts.

The radical SPU projects demonstrate both the high value of content contracts to publishers and the high price we have to pay to maintain the paper-era intellectual property model online. Strong content protection would be valuable in going beyond indirect and partial viewing of content on servers, to viewing content directly and locally. The price is the loss of control over our own computers, and loss of privacy over our activities on those computers.

The online content market is squeezed from above and below. From above, by the ease of redistributing high-value content. From below, by the mental transaction costs of charging for low value content – costs to which the requirements of registration and traceable identification add substantially. The size of the market in between is an open question. "Information wants to be free", but authors and publishers want to be paid for it. The current content market for more difficult to copy media, such as books, films, CD-ROM, and so forth is large, in the hundreds of billions of dollars per year. But on the Internet, free content dominates. Distributing ephemeral content in the form of service subscriptions is in most cases a more viable way to go. It remains to be seen how large the Internet content market will become, and to what extent customers will tolerate impositions on privacy and control of their computers in order to obtain legal content.

Reputation Systems

Reputation can be viewed as the amount of trust an agent has created for himself[14]. Reputation systems ultimately need to be based on fact rather than mere opinion or faith to be effective. For example, if we are to have a good credit rating system, we need to be confident that the credit record assembled by the agency is sufficiently accurate. Reputation information is typical gathered and distributed by intermediaries trusted to perform this task. Reputation can take the form of a public database (such as credit rating services) or credentials issued by the tracking agency and carried by the user. A bearer doesn't want to show his negative credentials, so credentials are often only positive. But we want to protect ourselves against negative behavior sources well as search out positive sources.

Tags that bundle the results of a wide variety of transactions - global names, or universal IDs, or "True Names" – may provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.

Robin Hanson[15] has observed that in a world of global names, the use of a local name may signal the hiding of negative credentials, so that the use of global names is in equilibrium. A further problem with local names is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. On the other hand, local names are essential for privacy. I suggest that we will want to reveal progressively more local names to our counterparties as our relationships with them become closer and more co-exposed.

While the global name equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing names outweigh the costs of being less or unable to differentiate newcomers from hostiles. For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, thereby protecting customers from exposure to strangers who might abuse that information. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.

Global name public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (e.g., have their alma mater create a new diploma).

The current universal (non-cryptographic) key in the U.S., the social security number (SSN), is very difficult to revoke; it's much easier to change your name. This policy is probably no accident, since the biggest economic win of global name identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.

Credit

One of the basic outstanding problems in smart contracts is the ensurement of credit. This comes up not only in loans, but in any other contract which involves a temporal lag between performance and reciprocal performance of the contractual terms.

In current practice, there are several partially effective processes for ensuring future performance:

Reputation (especially credit reports): often effective, but only to a point, as it is often hard for the debtor to accurately judge the future reputational effects of an action (e.g., failure to pay a bill, taking out too large a loan, etc.) that has clear, local, beneficial effects today. There is more imbalance in knowledge between current and distant consequences among individual consumers, but even among large organizations with high credit ratings it is not an irrelevant factor.

Secured transactions: liens, escrow, etc.

Garnishment of future income

Law enforcement, especially to enforce transfer of control over liened assets, garnishment, etc.

These processes have a fundamental property in common – they violate the privity of credit transactions – in other words, they bring in third parties to track reputations or enforce repayment. Do credit transactions entail a fundamental imbalance in incentives that can only be redressed by bringing in third parties, or can the security protocols be discovered which allow credit with minimal or no third party involvement?

Local Name Credit Ratings

Three important variables have been proposed for reputation economics:

operating value: expected future profits, given the reputation throw-away value: profit from cheating, which ruins reputation replacement cost: cost of recreating reputation

In turn, Peter Swire[16] describes two problems facing inadequately secured or unsecured loans to "credit names":

Adverse selection: Prior deadbeats can start fresh by signing up for the new service. Going in, it will be biased in favor of deadbeats. This problem may be addressed by using Chaumian credentials. These allow the established positive reputations of previous names to be carried over to the credit name, without allowing anyone to link the two names. Entrants without positive reputations can be rejected.

The endgame problem: A credit name can establish a good credit rating over time. When the limit is high enough, the borrower can quickly spend it all. A malicious borrower, with a good rating established under a previous name, can systematically profit at the expense of the lender, if the throw-away value is greater than the replacement cost. To address this problem, creditors will have to charge higher rates to new credit names and raise credit limits more slowly than for traceable names. Honest borrowers will subsidize the dishonest, to an even greater extent than they do in the current credit card system.

Secured Credit

Secured credit need not violate privity if the physical control over the securing property can be shared. So that, for example, automobile credit can be secured as long as repossession is possible, as described in the example above.

A standard mechanism of secured credit applicable online is the escrow. An escrow is an intermediary trusted to hold messages until messages from both sides are received, and, optionally, their contents verified - to extent the content is verifiable, and at the expense of some privity. The escrow then sends the messages off to their recipients, along with receipts. Messages can contain any sort of data: content, a bearer certificate, etc.

Ripped Instruments

Alice wants a New York City cab ride for which she's willing to pay $100, but she doesn't trust Bob the taxi driver to get her there on time if she pays up front. Bob in turn doesn't trust Alice to pay at the end of the trip. Commerce can be consummated by Alice tearing a $100 bill and giving half to Bob. After the trip she gives the other half to Bob, which he can then reassemble into a negotiable $100 bill. Alice loses her incentive to not pay. Bob gains incentive to get her there on time as promised. Both have made what economists call a "credible commitment" to perform their respective parts of the contract. Markus Jacobsson has digitized this idea, coming up with a protocol for ripped digital cash. As with many other aspects of digital cash, the idea can be further generalized to rip some other kinds of bearer instruments – specifically, those whose value can be divided roughly in half. If the transfer is double-blinded the transfer agent has no knowledge of the participants and therefore no bias to favor one over the other. The transfer agent must, however, be able to assess proof of performance, and the protocol is only workable where such proof (in the form of proof of receipt of a message, for example) is available.

The ripped bill is similar to using the transfer agent as an escrow agent. An advantage over using an escrow agent is that the need for extra anonymous channels between the parties and the escrow is avoided. A disadvantage is that the transfer agent now has taken on the major additional job of acting as an adjudicator, assessing proofs of performance (or at the very least, must be responsible for subcontracting out this job and implementing the adjudicator's judgement).

Credit Cards

Credit cards provide relatively little protection from third parties, especially in the area of privacy, but they do have an interesting contractual feature worth noting, the chargeback. With chargebacks customers can get refunds on allegedly unwanted merchandise. The issuer tracks the number of chargebacks both for customers and merchants; too many chargebacks can get you booted out of the system. This provides an efficient mechanism for refunds without resorting to expensive tort proceedings. Many customers who read the fine print or otherwise learn about chargeback limits often do chargebacks despite receiving and enjoying the merchandise; there is no practical way for the issuer to detect such fraud, and so it can only be pruned by limiting the number of chargebacks per customer. Some merchants complain vociferously about such customer "theft", and it seems to make possible coordinated attacks to put merchants out of business, but nevertheless merchants sign up for credit cards, because that's what their customers have signed up for. The chargeback feature makes customers more comfortable purchasing goods of unknown quality, especially mail-order and over the Internet. Chargeback provides a crude but effective partial solution to the information asymmetry problem between retailers and consumers.

Interval Instruments

"Time release" money that becomes good only after a certain date, and "interval money", that would expire after a certain date have been proposed. These can be implemented by a digital mint expiring or activating special issues of digital cash, or by a third party issuing escrowed keys at specific times. Since these keys are encrypted against the escrow agent, and that agent doesn't know what they will be used for, the escrow agent has no incentive to cheat. A generalization of this is that transfer and redeemability are each associated with interval sets, or validity periods when each can and cannot be performed. This is analogous to clipping coupons on bonds.

Known Borrowers of Unknown Amounts

Hal Finney[17] has described a loan mix, to unlink borrowers from amount borrowed. The identity of the potential borrowers is still public, as well as the system for enforcing payment, but the actual amount loaned or borrowed remains unknown. The system starts with participants putting unknown amounts into a pot and getting receipts (bearer bonds) for these amount. All participants then borrow a standard amount. Whether a participant is a net borrower or a net creditor, and of what amount, remains private. When the loan is due all participants repay the standard amount, and the creditors reclaim the amounts on their bearer bonds. The amount actually borrowed (or, if negative, loaned) is the public amount borrowed minus the amount put into the pot. One consequence is that while negative reputations can still be accumulated when participants fail to pay back the standard amount, positive reputations are minimal, since participants who borrow and loan are indistinguishable. If future creditors put stock in positive participation, one could gain a credit rating by perpetually participating as a net borrower of zero, by loaning and borrowing the same amounts.

Conclusion

Smart contracts combine protocols, users interfaces, and promises expressed via those interfaces, to formalize and secure relationships over public networks. This gives us new ways to formalize the digital relationships which are far more functional than their inanimate paper-based ancestors. Smart contracts reduce mental and computational transaction costs, imposed by either principals, third parties, or their tools.

Mark Miller[18] foresees that the law of the Internet, and the devices attached to it, will be provided by a grand merger of law and computer security. If so, smart contracts will be a major force behind this merger.

Notes

Editor's note: muted text indicates the text was commented out in the source file.A Formal Language for Analyzing Contracts

Nick Szabo Preliminary Draft from 2002



The author presents a mini-language for professionals and researchers interested in drafting and analyzing contracts. It is intended for computers to read, too. The main purpose of this language is to specify, as unambiguously and completely and succinctly as possible, common contracts or contractual terms. These include financial contracts, liens and other kinds of security, transfer of ownership, performance of online services, and supply chain workflow.

The following problems may be addressed by the language when interpreted by computer:

Accounting and auditing. Sophisticated contracts, including derivatives and combinations, can be specified in our formal language. Then automated or manual accounting rules may be applied to convert transactions completed under the contract to audit trails and ledger entries.

Analyze formally specified contracts for flaws in logic, scheduling, opportunities for parties to breach the contract, and conflicts with other contracts one is already committed to. [1]

Translate the formal contracts into an existing programming language such as E [2] , and/or cryptographic protocols [3] , for partially self-enforcing and protected execution as smart contracts.

Some kinds of contracts, especially financial and commodity contracts and their derivatives, can be converted into a decision or game tree that can be analyzed to determine risk, net present value, etc.

The process of designing this language is also a great way to explore the basic nature of contracts (what are the "elements" out of which a wide variety of useful contracts can be drafted?) and their composibility (what rules for composing these atoms rule out impossible contracts?) The language is also a creative tool for thinking up and "sketching" new kinds of contracts. I welcome your participation.

The words in our language follow legal terminology as much as possible – thus for example performance means execution to satisfy the terms of the contract (as in the legal field), rather than measured quantities like speed, memory usage, bandwidth, etc. (as programmers use the term). A law degree is not required to use the language, but some familiarity with contract law and the drafting of contracts is recommended. A lawyer who did reasonably well on the analytical and logical sections of the U.S. LSAT or its overseas equivalent, will, I suspect, have better luck drafting contracts in this language than than a programmer whose sole experience lies in traditional procedural language. That is why I call this a drafting language not a programming language.

Our language can specify the output of a negotiation (which could be an auction, an exchange, or two parties drafting the contract, or one party drafting and the other agreeing to it, etc. ). It also can define the input to an engine that drives and monitors the transactions that perform the contract:

negotiation --> contract --> performance

Performance of the contract, i.e. its reification as a smart contract, can thus be seen as (hypothetical, at this point) execution of a program written in our language. Furthermore, our language incorporates a wide variety of contractual terms, not just abstract monetary terms and their derivatives. These two characteristics make our language very different from special purpose financial contract languages such as[4]. While we use several financial contract examples to introduce our language and demonstrate its flexibility, its scope both in functionality and the kinds of contracts and transaction protocols it can represent is far broader.

Semantics

Each word and phrase in our language has a clear standard meaning. As a result, contracts can be drafted that will be far less subject to disputes over interpretation. On the other hand, the language is not very good at expressing many subjective and ambiguous concepts that are often necessary in contracts. Nor is it any good, in its present state, in referring to jurisdictions or doctrines of law. The language is nevertheless very different from a traditional programming language. Contractual terms are defined in terms of events that trigger their performance. Such events include dates and times, choices made by the parties, observable breaches of contract, and so on.

Our language is not a markup language. It is not about manipulating text for the purposes of drafting contracts. It is not about structuring text, specifying fill-out forms, defining static data formats, or similar tasks of languages such as HTML or XML. For those tasks one should use a markup language, or a text-manipulating programming language (e.g. Perl), not this language. Our language does something very different. It models the dynamics of contract performance – when and under what conditions obligations should be performed.

The words and sentences of the language do not consist of instructions followed down the page from one step to the next. Instead, a contract is read (both by human and computer) by following nested definitions of contractual terms as they expand, and by looking at events in when statements and seeing what they trigger. If the drafter does need to explicitly construct a step by step calendar schedule, this can be done by using calendar-driven events or words like for and then.

The language encourages composition of contracts. Contracts, rights, and obligations can be nested. We call these nested structures clauses. Contracts and clauses involve two parties, the Holder, from whose point of view we read the contract, and a Counterparty. Multi-party agreements can be drafted by composing several two-party contracts.

Example – Futures Contracts

Our first example is a well-known financial contract, the future. A future is an obligation on the part of the Holder of the futures contract to purchase a certain amount of a certain commodity in a certain month, and the obligation on the part of the future contract writer, the Counterparty, to deliver these goods. For the purposes of introducing this contract, we give it in the abstract form in which financial analysts usually deal with it, leaving out important details that describe the third parties who act as trusted intermediaries to define "fair bundles" of commodities, and we also leave out many details about the actual delivery.

future(rightA="1 round lot pork bellies", rightB="$1,500.00", p = "for delivery in July 2002") = when withinPeriod(p) to Holder rightA with to Counterparty rightB then terminate

Since this language is not yet being computer interpreted, the syntax is designed more for human than computer readability. I will be a bit fast and loose with the syntax, and you can be too. I mostly use tabs instead of brackets {} to structure clauses in a way that seems natural and readable to me – and I hope to you – but might confuse a computer. Feel free to develop your own style.

The top three lines in the contract, in the form name(parameters) = tells us that we are defining a named clause. The named clause can define an entire contract or just a clause in a larger contract. We can pass the names of other named clauses, lists of events, and other kinds of information that the named clause needs – these are the parameters.

when withinPeriod(p) means "when the first calendar or clock event generated during period p". The drafter can elsewhere set how often this regular "clock tick" event occurs. The first such clock tick after the start of the period, in this case the first scheduled delivery day in the month of July, triggers the clause with the brackets {}. More sophisticated schedules are possible, such as those that minimize delivery costs for the Counterparty by delivering to different Holders on different days in July. Fortunately, we can hide these scheduling details within the calendar event and schedule iterator mechanisms, leaving the drafter free from worrying about exactly when markets are open, which days are weekends or holidays or leap days, and the like. The Counterparty's delivery schedule can be negotiated or this detail can be left up to the Counterparty. In the contract above, the constraints on delivery are that it occur within July and only in conjunction with payment from the Holder.

The innermost clause says to swap rightA for rightB. This clause is split into a Holder right and a Counterparty right. The right clause Holder rightA means "Holder has the right to performance of rightA", in this case delivery of the pork bellies. The clause Counterparty rightB means "Counterparty has the right to performance of rightB", which here is the payment of 1,500 dollars. with indicates a simultaneous swap – the two transactions should occur together, perhaps intermediated by an escrow agent to enforce both the delivery and payment terms.

A then statement allows us to proceed step by step. If we had two clauses written thus:

to Holder right1 also to Holder right2

They could be performed in any order – right2 might be performed first, or right1 might be, or (most likely) performance on both might proceed at the sime time. Several when statements nested together at the same level have any implicit also as they can be triggered in any order.

Envision a dancing elf that follows nesting of clauses as they are performed and of events as they are caught. (Programmers call this dancing elf by the boring name "instruction pointer"). There can be more than one dancing elf if there is an also or if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.

If we wish to add the constraint that right2 cannot be performed until right1 has been, we use then:

to Holder right1 then to Holder right2

Traditional programmers will be sorely tempted to fill their contracts with then statements, mimicking the style of procedural programming. Do not! Those experienced with drafting contracts know that in some cases such a constraint is clearly appropriate and in some cases it clearly isn't, and it is important when adding constraints to be explicit. Therefore the following statement is illegal, and will be rejected both by the computer and by any right-thinking drafters working without a computer:

# Do not do this! to Holder right1 to Holder right2

Finally, we have already seen this kind of clause:

to Holder right1 with to Holder right2

This means that right1 and right2 should be performed simultaneously – and either both of them should be performed, or neither of them. In the lingo of computer scientists, it should be an "atomic" transaction.

The then terminate at the end of the named clause ensures that all rights and obligations under the contract are terminated once it has been performed. It is not triggered until the one-line body of the future contract has been completed. as well as any outstanding subordinate clauses with their rights and obligations. This clause is implicit at the end of every named clause, but for this one time we make it explicit. This clause is often used explicitly when the drafter wants to ensure the proper termination of non-named clauses nested within a named clause.

Let's now proceed through the futures contract step by step, as clauses are activated and then performed. A normal font indicates the clause is inactive. A bold font indicates an active state – the clauses is being performed.

When the parties commit to the contract its first clauses (the clauses at the highest level of indentation) are awoken. In our futures contract we have only one such clause, and so the when (but not the clauses nested underneath it) go to in an active state, waiting for the withinPeriod() event:

when withinPeriod(p) to Holder rightA with to Counterparty rightB then terminate

When the calendar has advanced to the end of trading on the last trading day of August, the withinPeriod(p) event occurs and the when activates the clauses nested at the next level inside. The when itself becomes inactive – it is no longer waiting for an event:

when withinPeriod(p) to Holder rightA with to Counterparty rightB then terminate

The then has cause the terminate to wait for the when and its subclauses to be performed. Once the swap of rights has been performed, the performed clauses convert to inactivity and the terminate fires:

when withinPeriod(p) to Holder rightA with to Counterparty rightB then terminate

It is easy to generalize in our language. The generic futures contract looks like this:

future(rightA, rightB, p) = when withinPeriod(p) to Holder rightA with to Counterparty rightB then terminate

Instead of pork bellies, we can swap any other rightA for rightB, which can be a wide variety of things beside money. Drafters can specify very general boilerplate and fill in details for specific contracts later.

Example – Option Contract

We now present another kind of financial contract. In this American option, the Holder has the right to buy for $20 (the option strike price) per share one round lot (100 shares) of XYZ Corp on or before the last trading day of August. These kinds of contracts are called "derivatives" because the call option is derived from the underlying right (here a stock).

callOptionAmerican (rightA="1 round lot XYZ Corp.", rightB="$2,000/lot", time="end of trading on last trading day of August") = when beforeTime(time) when choiceOf(Holder) to Holder rightA with to Counterparty rightB when afterTime(time) terminate

Think about that dancing elf again. (When reading or writing in our language it's important to follow these dancing elves. If the elves become annoying, think of some other dynamic character or process for a metaphor that suits). As it goes around it wakes up clauses, making them active, causing them to be performed. Sometimes there can be more than one elf dancing through the code at the same time, for example if more than one when statement is triggered while another is active, but usually we only need to think about one at a time.

The contract starts out with dancing elves in the two top-level clauses:

when beforeTime(time) when choiceOf(Holder) to Holder rightA with to Counterparty rightB when afterTime(time) terminate

These when statements are now waiting for their respective events. Since the events are mutually exclusive (it is first beforeTime(time), then afterTime(time), but never both) we only need to worry about the first to be executed. Note that, unless separated by a then, the order of the clauses at the same level is not important. The following code is identical to the code in our example:

when afterTime(time) terminate when beforeTime(time) when choiceOf(Holder) to Holder rightA with to Counterparty rightB

The beforeTime(time) is immediately activiated, so that we start with the nested clause(s) at the level immediate below it active as well – in this case, when choiceOf(Holder).

when beforeTime(time) when choiceOf(Holder) to Holder rightA with to Counterparty rightB when afterTime(time) terminate

A series of whenes at the same level in that clause all start waiting for any of them to be triggered. When a when receives an event thrown below it or at it, the nested clause below it becomes active. Then the clauses below it become active and are performed down to the wheness one level below. The whenes at that level go from inactive to active, now waiting for their events to occur.

The when beforeTime(time) becomes active when the option itself is first activated, and remains active until time. Being active it wakes up the when choiceOf(Holder). This when specifies the event that gives the contract its nature as an option -- the choice of its holder to exercise it or not. If the Holder chooses to do so, the Holder gets the stock (rightA) from the Counterparty (the writer of the call option) in exchange for the money (rightB). The dancing elves then move from the when clause to the swap clause:

when beforeTime(time) when choiceOf(Holder) to Holder rightA with to Counterparty rightB when afterTime(time) terminate

When code gets complicated, we might not be able to easily tell whether the implicit then terminate on the last line will get executed. So it's a good idea to terminate the contract explicitly when the option expires.

We will see examples where more than one kind of event, and even sequences of events (such as a calender schedule of payment dates) trigger the execution of contractual terms.

Remember that the language does not proceed by default step by step – instead the reader (human or computer) should follow down the nested contract definitions as they expand, and look at events in when statements to see what they trigger. Explicit step by step calendar schedules can be built using for, then, and calendar events.

Here's an example that uses such explicit steps. A bond makes a sequence of fixed payments, called coupons, on a regular schedule, and then makes a final payment, the principal. We don't show here the details of the schedule itself, but in general a schedule could be defined to be any kind of temporal sequence – we could pay out coupons on the last day of every month, on every Japanese holiday, according to the computation of Easter (don't laugh – schedulers of medieval fairs had to face this problem), or however we choose. When implemented the calendar events and schedule iterator will contain a very thorough implementation that solves many of the nasty calendar problems that often appear in transaction processing systems.

for iterates through the events in the schedule one by one, with the nested when handling them. When it appears after a for clause, a then advances the iterator one more step.

bond(coupon, principal, schedule) = for schedule when withinPeriod(schedule.next) to Holder coupon then when withinPeriod(schedule.next) to Holder principal

Next we sketch a contract to sell a car on credit. Being a sketch rather than a full-fledged design, this is an oversimplified or "toy" example – we leave out fees, any references to a related insurance contract, warrantees, waivers, etc. We also for simplicity have the bank (here the Holder) be the same as the car dealer. Finally, we don't show here any lien on the car to secure the loan. We will make a stab at a lien-like mechanism in an example below.

loanPayments(payment, schedule) = for schedule when withinPeriod(schedule.next) payment carPurchase(car, downPayment, monthlyPayment, schedule) = to Counterparty getTitle(car) with to Holder downPayment then to Holder loanPayment(monthlyPayment, schedule)

If we want to allow prepayment, our schedule would contain single times rather than periods with a begin time and an end time. And our loan payments would look as follows:

loanPayments(payment, schedule) = for schedule when beforeTime(schedule.next) payment

We could compute the above payment from other information we are more likely to see in the contract, but this involves just normal programming. We can use a function to perform the computation in the first place:

loanPayments(principal, interest, schedule) = constant payment.amount = computeInterest(principal, schedule, interest) # normal computational function goes here then for schedule when beforeTime(schedule.next) payment

"=" sets, for all time (thus constant), the number payment.amount to the value returned by the function computeInterest. We could also do more complicated things – deduct interest for prepayment, or conversely add prepayment penalties, or a wide variety of other conditions.

We can also structure the car purchase contract so that the new owner doesn't get the title until after the downPayment has been received:

carPurchase(car, downPayment, monthlyPayment, schedule) = to Holder downPayment then to Counterparty getTitle(car) then to Holder loanPayments(monthlyPayment, schedule)

Damage Clauses

Let's use our language to analyze some important advances in the history of economic institutions. Genoa was an independent and rather libertarian (for its time) city heavily involved in the Mediterranean sea trade. During its height in the twelth through fifteenth centuries it developed many commercial innovations, including two we will examine here, the "dry exchange" loan and pooled-risk insurance.

Here is a clause from a contract made in Genoa on June 23 in 1271 A.D. A man is co-signing an obligation being made by his son:

Wherefore and for which we promise, both of us [liable] for the whole amount, to give and to pay to you or to your accredited messenger 53 gold hyperpers, good and of correct weight, in Romania [Byzantium], by the Kalends of September. If, however, we do not give you these [hyperpers] within the said time limit, [we promise] for each of the said hyperpers 11 shillings Genoese in Genoa whenever you wish. Otherwise we promise, both of us [liable] for the whole amount, to give to you, making the stipulation, the penalty of the double of the said amount, the aforesaid [conditions] remaining as settled. And we pledge to you as security for the aforesaid [promises] all our goods, existing and future...[5]

Now, this is a very clever contract, called by scholars a "dry exchange". The Catholic Church forbad the charging of interest, so a loan contract that came right out and charged interest would be unenforceable and expose the drafters to further Church sanctions. But both long-distance exchange (making a trade at a distant market at a later date -- often via a sea voyage, thus a "wet" exchange) and currency exchange were quite legal, enforceable, and common. The above contract combined these two, along with damage clauses, in a clever way. None of the above parties had any intention of travelling to Byzantium, or even outside Genoa, to perform on this contract. Its logic can be analyzed as follows (the Holder is the creditor). We've added the statements "in (geographic location)", security, and foreclose to highlight important aspects of this contract. The latter sells enough of the goods at auction to satisfy penalty (if there was not enough to satisfy the creditors there was a bankruptcy procedure to fairly allocate the remain security among the creditors, but this is not shown):

counterpartySecurity = pledge(allGoods(Counterparty)) also cosignerSecurity = pledge(allGoods(co-signer)) then payment1() = when beforeTime("Kalends of September 1275") to Holder in Byzantium "53 hyperpers" terminate payment2() = when breachedPerformance(payment1) to Holder in Genoa "53*11 = 583 shillings" terminate payment3() = when breachedPerformance(payment2) to Holder in Genoa "2*583 shillings" terminate payment3() = when breachedPerformance(payment3) when choiceOf(Holder) to Holder in Genoa foreclose(counterpartySecurity, penalty) terminate when choiceOf(Holder) to Holder in Genoa foreclose(cosignerSecurity, penalty) terminate continue

Neither party expected payment1 to be performed. The amounts of hyperpers and shillings probably reflected accurately the exchange rate between the two coins at the time – there's no sense being too obvious. But it would have been far too expensive to travel to Byzantium just to do this exchange. So in fact both parties expected payment2, a fake damage clause, to normally be performed. If it wasn't, then we have two real damage clauses – the somewhat reasonable "penalty of the double" and the lethal "all our goods, existing and future". Another interpretation of the latter clause is that it would only refer to a value of goods up to the double penalty amount, but the goods could be chosen from among all the goods of the debtor and the co-signer. Certainly a modern court would consider the interpretation I have placed on it in our language to be unconscionable, therefore unenforceable.

Above the part we quoted, the contract does not specify how much the original loan amount was – the debtors simply acknowledge that they have received from the creditor "a number of Genoese deniers" and then promise other currencies in return as quoted above. So a Church investigator couldn't prove just from reading the contract that any interest was charged. As for the Genoese judge arbitrating a dispute, he would likely be in favor of loans at interest, and happy to wink and nod and interpret the contract literally.

Modern derivatives traders do this all the time, creating synthetic assets or combinations that mimic the financial functionality of some other contract while avoiding its legal limitations. Our language is ideal for drafting and analyzing such contracts.

Insurance

The earliest risk-pooling insurance contracts were structured similarly to, and enforced under the same legal principals as, loans. Indeed, let's start with a simple loan for a purchase of goods with no interest where the Holder (the creditor) can call in the loan any time between days t1 and t2:

loan(goods, principal, penalty, t1, t2) = counterpartySecurity = pledge(allGoods(Counterparty)) with to Counterparty getTitle(goods) loanPayment(principal, t1, t2) with when breachedPerformance(loanPayment) to Holder foreclose(counterpartySecurity, penalty) loanPayment(principal, t1, t2) = when withinPeriod(t1,t2) when choiceOf(Holder) to Holder principal

Let's add to our language a safeArrival(goods) event – the event that a ship carrying goods arrives safely in port and that goods are offloaded and accounted for. Now by adding to this loan contract only one extra line, whening safeArrival(), and slightly modifying a few others we can transform it into a marine insurance contract. The insured is the Holder, the insurer is the Counterparty. For this simple version damages are paid in a fixed amount (principal) if safeArrival does not occur:

insureGoods(goodsPremium, principal, penalty, t1, t2, goodsInsured) = counterpartySecurity = pledge(allGoods(Counterparty)) with to Counterparty getTitle(goodsPremium) insurancePayment(goodsInsured, principal, t1, t2) with when breachedPerformance(insurancePayment) to Holder foreclose(counterpartySecurity, penalty) insurancePayment(goodsInsured, principal, t1, t2) = when safeArrival(goodsInsured) terminate when withinPeriod(t1,t2) when choiceOf(Holder) to Holder principal

Here's an example of an early insurance contract of this kind – again from Genoa, the birthplace of modern commercial institutions. For the first time we see a pool of insurers – not one but many counterparties, each pledging their entire property as security. Often these were feudal lords with large landholdings, so the value that could be brought to bear to back these insurance contracts was vast. This is how Lloyds Names still work today. Since several Names back a single contract (e.g. covering a single shipment of goods, as here), each Name puts only a tiny fraction of their estate at risk in that voyage. An insurance exchange like Lloyds allows the agents of goods owners, shippers, and Names to meet and mass-produce these kinds of contracts.

...Geri, [son] of the late Ser Lapo of Florence, Simone Guascone, [9 more Names listed], each of them [liable] for the amount written below, have acknowledged and in truth have declared to me, notary undersigned, as a public official [holding] a public office, making the stipulation and receiving in the name and stead of Federico Vivaldi, citizen of Genoa, that they have bought, have had, and have received from him a certain amount of goods of the said Frederico...And for these goods and in consideration of their price each of them has promised to give and to pay to said Frederico or to his accredited messenger: [from] the said Geri, 150 gold florins, the said Simone, 50 florins, [100 florins each from the other Names] within the next five months from now. Otherwise they have promised to give and to pay to the said Frederico the penalty of the double of it and of the entire amount to which and to the extent of which [this agreement] is violated or is not observed as above, together with restitution of all losses, unrealized profits, and expenses which might be incurred because of it in court or outside – the aforesaid remaining as settled, and under hypothecation and pledge of their goods and [the goods] of any one of them, existing and future. [The above is binding] with the exception and special reservation that if the amount of goods, property, and merchandise which was loaded or is to be loaded by Frederico Imperiale or by another in his behalf for the account of the said Frederico Vivaldi in Aigues-Mortes – to be transported to Ayassoluk and Rhodes or to either of these two localities in a certain ship...and which departed from Aigues-Mortes or is about to depart in order to sail to aforesaid regions – is brought and unloaded in the said localities of Ayasoluk and Rhodes or in either of them, in safety, then and in such a case the present intrument is cancelled, void, and of no value and pro rata. And be it understood that such a risk begins when the said ship departs and sets sail from Aigues-Mortes, and it remains and lasts, while the captain goes, stays [in port], sails, loads and unloads, from the said locality of Aigues-Mortres up to the said localities of Ayassoluk and Rhodes, in whatever manner and way he wishes, until said amount of goods, property, and merchandise has been brought and unloaded in Ayassoluk and Rhodes or in either of these two localities in safety, and pro rata. Let the present instrument also be cancelled if the said Frederico refrains from asking payments of the aforesaid amounts of money for the space of one year after the time or the time limit has elapsed for asking or obtaining their payment....Done as above, September 15th, around nones. [1393 A.D.][5]

Ignoring the pro rata language, the specific definition of the risks that prevent generation or not of the safeArrival() event, and ignoring the multiple Names (i.e. treating them as one Counterparty), the contract can be modelled by the insurance contract we drafted above with its parameters filled in as follows, and with Frederico Vivaldi as the insured (the Holder):

insureGoods(goodsPremium="a certain amount of goods", principal="100 fl + 50 fl + 7*100 fl", penalty=2*principal, t1="5 months from now", t2="1 year after [legal] time limit has expired" goodsInsured="that amount of goods, property, and merchandise which was loaded")

This contract was still, legally speaking, a loan. This had at least two interesting consequences on what we now call the insurance premium. Firstly, the premium was treated as goods purchases by the insurer on credit. Secondly, even at this late date, contracts were coy about the actual value of such goods. Leaving the value of those goods unspecified made usury difficult to prove in this "loan".

Rules: Logically Combined and Superimposed Events

Events in a when clause can be combined in logical conditions which must evaluate to true in order to trigger the subclause. This can be used to model conditional clauses in contracts, and, more broadly, procedural and substantive rules of law. When constructing rules we call the primitive events elements. For example, here is, roughly following the Restatement(Second) of Contracts, a legal rule for promissory estoppel:

when "there is a promise" P "has relied on that promise" D "should reasonably expect P would rely on that promise" and "injustice can only be remedied by enforcing the promise" then "the promise will be enforced" else "the promise will not be enforced"

We include a gratuitous "then" here for readability. Computer programmers should note that we are following a shorthand here used by lawyers – we write the logical phrase (A and B and C and D) as (A B C and D). When mixing and and or, write out the complete logic, and use parentheses where appropriate.

The rule elements, such as "there is a promise", exist in a superimposed state. By default, the logic is ignorant of the facts, and each element is genuinely at issue. As a result, "there is a promise" and the other elements of the above rule are both true and false, at the same time. (Those familiar with quantum mechanics or legal reasoning know what I'm talking about here). In the initial state, where every element is genuinely at issue, nontrivial rules will always evaluate to both true and false. Thus, both "promise will be enforced" and "promise will not be enforced" clauses will be triggered. When the clauses are incompatible, as these appear to be by their label, it is up to the implementor of the clause to deal with this properly. In this case, such a clause should only be treated as advisory until all material elements have been decided – i.e., they are no longer genuinely at issue, at which point the rule can be used to make a decision, i.e. trigger a single clause which takes a consistent action. A future version of this document will describe how to resolve elements genuinely at issue into elements not genuinely at issue, and thus decide on a single outcome or course of action. It will also describe how to deal with advisory clauses; for example, to analyze which elements are most favorable to one outcome or another. Finally, another future feature will include elements that cover a range of numerical values, rather than just true or false, and a formalized "balancing test" that determines outcomes based on underlying numerical estimates.

Property – Estates and Future Interests

Our rule language is ideal for specifying estates and future interests in real estate deeds. One can also apply these patterns to other kinds of property where appropriate. Here are some examples:

Lease for Term: (n.b. – Grantor = self). This is an old common law lease that actually transfers title for a certain period of time.

leaseWithTerm(Property, Lessee, Start, Term) = when afterTime(Start) to Lessee Property then when afterTime(Start+Term) to Grantor Property

Life Estate with Reverter: (n.b. – Grantor = self)

lifeEstateReverter(Property, Grantee) = to Grantee Property then when afterDeath(Grantee) to Grantor Property

Assignable Reverter for Lease. To make future interests assignable, define them separately. Note to make the Grantor explicit. (As usual we are looking at things from the obligor's side):

Reverter (Grantor, Grantee, Property) = when afterDeath(Grantee) to Grantor Property

We can now redefine the Life Estate with Reverter in terms of the separately defined future interest:

lifeEstateReverter(Property, Grantee, Reverter) = to Grantee Property then Reverter(Grantor, Grantee, Property)

Life Estate with Remainder. The only difference here is that the property is remaindered to a third party instead of reverting to the grantor.

lifeEstateRemainder(Property, Grantee, Remainderman) = to Grantee Property then when afterDeath(Grantee) to Remainderman Property

Fee Simple Determinable. The Condition can be any verifiable event or change of state of the property or its title. A common real estate condition, for example, is "used for commercial purposes" – i.e., a restriction that the property may not be used for commercial purposes, otherwise the grantee is penalized by losing title to the grantor.

feeSimpleDeterminable(Property, Grantee, Condition) = to Grantee Property then when Condtion(Property) to Grantor Property

Fee Simple Subject to Executory Limitation. Same as Fee Simple Determinable, except the property gets remaindered to a third party instead of revertin to the grantor.

feeSimpleSubjectToExecutoryLimitation(Property, Grantee, Condition, Remainderman) = to Grantee Property then when Condtion(Property) to Remainderman Property

Fee Simple Subject to Condition Subsequent. Here title is not automatically transferred upon occurence of the condtion. Instead the Grantor must do some affirmative and verifiable act (in this example "entering" the property), to reclaim the title.

feeSimpleSubjectToConditionSubsequent(Property, Grantee, Condition, Enters) = to Grantee Property then when Condtion(Property) when Enters(Grantor, Property) to Grantor Property

Some More Advanced Examples

In this section we will look at ways to construct multiparty agreements, distinguish ambient from thrown events, and examine a number of other more advanced features of or ways to use our language.

We will complete the life cycle of the American option we drafted above by "writing" the option – creating it from an underlying security rightA and selling it for rightX. Here the Holder (same party as the Holder above, in this case the person who will buy the written option) first verifies that the Counterparty indeed holds the underlying security (rightA) with Broker. The Broker is trusted by the Holder to make sure Counterparty continues to hold the security until the option is exercised or expired. The contract between the Broker and Holder is escrowRight().)

Since Counterparty, the option writer, is not paying anything up front for an option on rightB, this right does not need to be escrowed.

escrowRight(right, escrow, newHolder, currentHolder, newHolderReleaseEvents, currentHolderReleaseEvents) = to escrow right then when (holderReleaseEvents) to rightHolder right then terminate when (counterpartyReleaseEvents) to currentHolder right then terminate writeCallOptionAmerican(rightA, rightB, rightX, time) = escrowRight(rightA, Holder, Counterparty, (optionExercised), (optionExpired)) then to Counterparty callOptionAmercian(rightA, rightB, time) with to Holder rightX

We now redraft the option itself to take advantage of the escrow. rightA is transferred to Holder by the throw upon excercise, or back to Counterparty if the option expires.

callOptionAmerican(escrowRight, rightB, time) = when beforeTime(time) when choiceOf(Holder) { throw optionExercised at escrowRight } with to Counterparty rightB then terminate when afterTime(time) throw optionExpired at escrowRight then terminate

We can think of events as coming in two kinds. The first, ambient events, occur spontaneously in the environment, or are generated by an entity external to our specification such as a user or a schedule. The second, thrown events, are events we explicitly throw as above.

In this manual I have expressed contract clauses in terms of rights. Often contract language is expressed in terms of obligations, which can be done as a mirror image – to Holder right is the same as from Counterparty obligation and vice versa. Use from to distinguish an obligation.

Hooking Up Machines

Further showing the flexibility of our language we can add sensors and effectors, adding "smarts" to our contracts and augmenting legal enforcement with technological constraints.

First we draft a specification for the contract-like bevavior of a vending machine:

sellCandy(candyPrice = $0.90) = variable moneyAmount = $0.00 then # coins also fall into a temporary till tempTill when (nickel) add(moneyAmount, $0.05) when (dime) add(moneyAmount, $0.10) when (quarter) add(moneyAmount, $0.25) when (moneyReturn) dropCoins(tempTill, returnTill) with moneyAmount = $0.00 when threshold(moneyAmount, candyPrice) when (nickel | dime | quarter) redirectNewCoinsTo(returnTill) also display("ready to dispense -- please select candy") then when (candySelection) dropCandy(candyRacks, candySelection) with dropCoins(tempTill, permTill) with moneyAmount = $0.00 continue

We have here introduced a new language feature, a state variable. Our state variable moneyAmount generates an event upon surpassing the candy price threshold of $0.90. Note that nickels, dimes, etc. are actual physical objects that the sensors (generating events "nickel", "dime", etc.) detect and treat separately – they are not merely abstract amounts of money.

State variables can be troublesome, and should be avoided unless utterly necessary as here. This one is relatively harmless because the coin slot tends to force the coins to come in one at a time, so that no two clauses are trying to change the state variable at the same time. Even if they were, the addition operation is what mathematicians call "commutative", meaning it doesn't matter what order it's done in. But if the operation on the state variable were more complicated or involved certain other kinds of operations, we wouldn't know whether it was commutative. The order in which events occured and changed the state variable might matter very much, and we could get into big trouble. So avoid state variables whenever possible.

To simplify things, we've left out making change – our machine has to have one of those signs you sometimes see, "exact change only". If the customer puts in a coin that pushes the amount from, say, $.80 to $1.05 – too bad, the machine eats it. If the customer puts in $0.90 (or more) and then adds more coins, however, the machine automatically returns the extra coins. The machine will also return whatever has been put in the till, if the customer changes her mind and decides not to buy the candy. Exercise for the reader: verify for yourself that the above behavior descriptions are correct as the code is written.

RedirectNewCoinsTo(returnTill) causes any further coins to drop into the return chute instead of onto the sensor that triggers the above events. The reader must here imagine what the mechanism looks like, as part of the behavior is "encoded" in its mechaninism rather than explitly in this statement.

Think of the nested contracts and rights as an upside-down tree – a hierarchy of nested clauses. Events propagate from up from the "leaves" of the tree towards the "root" at the top. They are caught by the first when event they encounter for that event. In this case, once we enter the when threshold() clause, the when (nickel | dime | quarter) clause overrides the when(nickel) and so on clauses above them.

Like a perpetuity, our vending machine has no scheduled time or condition where it stops performing – therefore we have a continue statement to overrid the implicit then terminate on the last line.

Alas, neither I nor real world candy machine makers have any code to solve the case where the candy gets stuck in the machine.

The above is a transcription of machine behavior. Now we make it even more like a contract. Here we incorporate the customer and his choices, which implicitly generated the coin events in the code above – here the coins are rights of the Holder. Thinking more about the party, rather than the machine, allows us to recognize that at each step the customer wants feedback on how much money they have put in, thus to Counterparty display(moneyAmount). This display is done by the Holder (the vending machine as an agent of the vendor) as a right of the Counterparty (the customer). To enable better customer choice, we add a new construct to our language: choiceOf(agent, right) which allows the customer multiple choice, based on which right they wish to transfer to the agent's counterparty (here the vending machine, the Holder).

sellCandy(candyPrice = $0.90) = variable moneyAmount = $0.00 then # coins also fall into a temporary till tempTill when choiceOf(Counterparty, nickel) to TempTill nickel then to Counterparty add(moneyAmount, $0.05) then to Counterparty display(moneyAmount) when choiceOf(Counterparty, dime) to TempTill dime then to Counterparty add(moneyAmount, $0.10) then to Counterparty display(moneyAmount) when choiceOf(Counterparty, quarter) to TempTill quarter then to Counterparty add(moneyAmount, $0.25) then to Counterparty display(moneyAmount) when choiceOf(Counterparty, moneyReturn) to Counterparty dropCoins(tempTill, returnTill) with moneyAmount = $0.00 then to Counterparty display(moneyAmount) when threshold(moneyAmount, candyPrice) to Holder (nickel | dime | quarter) to CounterParty redirectNewCoinsTo(returnTill) also display("ready to dispense -- please select candy") then when (candySelection) to Counterparty dropCandy(candyRacks, candySelection) with to PermanentTill dropCoins(TempTill) with moneyAmount = $0.00 continue

How is it that we have specified the behavior of a vending machine in a language designed for drafting contracts? Can nickels, dimes, quarters, and operations like dropping coins from one till to another be thought of as rights and obligations? I think so. They are not legal rights and obligations, to be sure. There is no explicit contract between the vendor and candy machine customers, and if their were it would probably waive liability for violating most of the clauses in our code. What this code describes is the logical and typical behavior of a vending machine. It also reifies the implicit understanding most customers have when using a vending machine. Thus it models a contract-like "meeting of the minds" between the customer and the vendor that is mediated by the machine.

Here is a stab at formally describing the hypothetical "auto repo auto". The car is controlled by a proplet and the proplet looks to property titles to determine ownership authority. The proplet lets only the titled owner enter and drive the car. "Holder" is the bank that made the loan and "Counterparty" is the new owner. As above we ignore the car dealer; the bank originally owning the car. This example highlights the ability of the language to very succinctly describe contracts but also its inability to describe the actual security that will enforce the contract. There is of course a lot missing here, including the items missing from the above car loan contract. From a smart contracts viewpoint, the biggest thing missing is that there is nothing to motivate the "Holder getTitle(car)" in the last when, nor any way specified here to enforce it. And of course all connection between ownership and authority to enter, start, and drive the car is here implicit – the actual proplet behavior in this regard would have to account for safety, emergency use, etc.

For all that work-up, we've only actually added one clause to our car purchase contract above. The clause forfeits the title and is structured much like the damage clauses we have seen. A breachedPerformance() event is generated if it is detected (by the Holder, a third party auditor, or the proplet itself) that the Countparty failed to make a payment according to the schedule specified by loan.

loan(payment, schedule) = for schedule when withinPeriod(schedule.next) payment carPurchase(car, downPayment, monthlyPayment, schedule) = to Counterparty getTitle(car) with to Holder downPayment then to Holder loan(monthlyPayment, schedule) when breachedPerformance(loan) to Holder getTitle(car)

Technical Note – A Computer-Readable Syntax

Here is a formal specification of the language's grammar in "Backus-Naur Form"(BNF). The specification is for a planned computer-readable version of the language and there are a few minor differences, such as the use of brackets {} instead of tabs to denote nesting. BNF is used to define what linguists call "context-free grammars". It is also used, as here, to define the syntax of languages that computers can also interpret and execute. I also include some more discussion of the meanings of the words and structures, especially how the computer might interpret them. As you can see, this is an evolving language, a work in progress with many unresolved issues. Your suggestions for changing or adding more kinds of contractual terms to our language are quite welcome.

agent = Holder | Counterparty ## makes contract look different on each side period = (startTime,finishTime) # period is the window within which the performance must be # executed, e.g. a European option must be exercised # between the start to finish of the business day on which # it expires. [for periodIterator "{" ...periodIterator.next... "}"] [then ... periodIterator.next...]* # rights performed in temporal order. # sequence of periods used as inputs to sequence of withinPeriod(p) events. # can this be more general, an iterator of events? but periods have # a natural order while other kinds of events can occur in any order. # each periodIterator.next generates an event which is caught by # the next tempral event (withinPeriod() if the iterator generates # periods, aftertime() or beforeTime() if it generates times) # *down* from the *for*. The implicit "throw" occurs at periodIterator.next # so we can still view it, just barely, as propagating up from # the "throw". # (this is different from the normal event semantics where throws # propagate *up* the parse tree) -- should I change it to *up* # and rewrite the schedule iterator code above? but it confuses # me & perhaps the comuter to put it *outside* the loop. event = choiceOf(agent) | withinPeriod(period) | performed(right) | breachedPerformance(right) | threshold(amount,threshold) | afterTime(time) | beforeTime(time) right = throw event at [ contract | right] | passEvent([right | contract]) # generates an event to be caught by the specified contract or right. # if contract or right is not specified, the first parent when(event) # is triggered. # just use when withinPeriod(whenWritten,time) # right = doBefore time { right } # semantically equivalent: # Holder right = O Counterparty obligation right = getTitle(property) # transfer property title from obligor to obligee # see http://nakamotoinstitute.org/secure-property-titles/ right = null right = [ when event "{" right "}" ]* ## envision an "instruction pointer" that ## follows nesting and events as they occur. ## there can be more than one instruction pointer ## if there is an "also" or two events occur at ## the same time, but usually we only need to think ## about one. ## a clause is either active or inactive. ## when a when clause is active, it is waiting for ## an event to occur. ## when the instruction pointer a nested when, ## the when goes from inactive to waiting. ## A series of when's at the same level ## all wait for any of them to be triggered. ## When it receives an event thrown below ## it or at it, it becomes active. Then ## the clauses below it become active up ## to the when's one level below. The ## whenes at that level go from inactive ## to waiting. ## alternative design being considered: continue where left off ## unless an explicit "terminate" in the when right = functionPerformance ## functional specification of a specific ## service goes here ## function sig, pre-, post-conditions obligation = throw event at [contract | right] # generates an event to be caught by the specified contract or right. # if contract or right is not specified, the first parent when # is triggered. # semantically equivalent: Holder obligation = Counterparty right obligation = surrenderTitle(property) # transfer property title from obligor to right holder # see http://nakamotoinstitute.org/secure-property-titles/ obligation = null obligation = [ when event "{" obligation "}" ]* ## alternative design being considered: continue where left off ## unless an explicit "terminate" in the when obligation = functionPerformance ## functional specification of a specific ## service goes here ## function sig, pre-, post-conditions contract = agent [right | obligation] ["with" agent [right | obligation]]* ## "with" allows composing Holder and Counterparty ## rights vs. each other contract = [ when event "{" contract "}" ]*

Basic Fucntions

doOn(right, period) = when withinPeriod(p) { right } # must perform "right" within (period) # = zero-coupon bond = coupon # doOnDemand(right) = when choiceOf(Holder) { right } # must perform "right" anytime/on demand # doOn(contract, period) = when withinPeriod(p) { contract } # must perform "contract" within (period) # doOnDemand(contract) = when choiceOf(Holder) { contract } # must perform "contract" anytime/on demand #

More Examples

future(rightA, rightB, p) = Holder doOn(rightA, p) with Counterparty doOn(rightB, p) # # [additional constraint p=p is not mere algebraic composition] # callOptionAmerican(rightA, rightB, t) = when withinPeriod(whenWritten, t) when choiceOf(Holder) Holder rightA with Counterparty rightB # callOptionEuro(rightA, rightB, p) = when choiceOf(Holder) Holder doOn(rightA, p) with Counterparty doOn(rightB, p)) # putOptionAmerican(rightA,rightB,t) = when withinPeriod(whenWritten, t) when choiceOf(Holder) Holder rightA with Counterparty rightB # event semantics need to store the choiceOf even # by waiting for the next when. putOptionEuro(rightA,rightB,p) = when choiceOf(Holder) Holder doOn(rightB, p) with Counterparty doOn(rightA, p)) # note(right) = demandDeposit(right) = Holder doOnDemand(right) # [distinction of bearer vs. account holder has not # been introduced] # zeroCouponBond(right,p) = doOn(right, p) # callableZeroCouponBond(right,p) = when choiceOf(Holder) { right } when withinPeriod(p) { right } # bond(coupon, principal, schedule) = for schedule { doOn(coupon, schedule.next) } then doOn(principal, schedule.next) bond(coupon, principal, schedule) = for schedule { doOn(coupon, schedule.next) } then doOn(principal, schedule.next)

Frequently Asked Questions

Q: There are already languages for specifying financial contracts[3], what is the novelty here?

A: This the first specification language to generalize contractual structures to any kind of exclusive rights, not just money. This is also the first language that incorporates the dynamic nature of many contracts, (their dependence on time or events) in a succinct, complete, and potentially executable manner. Surprisingly, this often makes the specification more not less succinct.

Where's the money?

A: This language is targeted toward an economy of distributed software and devices performing services for each other. A money economy can be constructed out of a barter economy but not vice versa. Real online money is far more subtle than a mere shared variable (or even the specification of "bank notes" in this language). Money is just one kind of fungible exclusive right, and the structure of financial contracts are generalized by converting money terms into any fungible exclusive right.

Q: What assumptions are you making?

A: This is the most important question to ask of any novel scheme! I have identified at least the following:

I'm assuming away, for the moment, issues of the protection and enforcement of performance, which I've addressed elsewhere (http://szabo.vwh.best.com/ has many essays that focus on this topic). An eventual goal is to create protocols to enforce the language's atoms and then to compose these atoms maintaining the enforceability. Two specific enforcement assumptions – there exists a secure, agreed-upon time source, and the occurence of other defined events can be agreed upon by the parties and/or audited by third parties. I am assuming some kind of atomicity for each right atom performance – for example, when an event triggers a "when", a functionPerformance in another thread is gracefully either rolled back or completed. There are only two parties to the contract, the Holder and Counterparty. A contract comes in two mirror forms, one of which can be inferred from the other. A party always sees himself as the Holder. Obligations of the Holder can always be expressed in and inferred from rights of the Counterparty, and vice versa. I'm probably making other assumptions I haven't discovered yet – if you find any please let me know!

Q: What are some problems with this language you'd like to see solved?

A: Implementations that satisfy the above assumptions for the particular language atoms, and also for compositions of the atoms. (Of course, various protocols in the "financial cryptography" field, in my own proposals, in the E language, etc. provide many valuable building blocks for such solutions).

References

There are many instances of deals gone sour at the last minute when the salesfolk check with legal and discover that the deal is not possible due to a clause in another contract – for example a promise not to sell to a customer's competitors in an industry for a certain period of time. Worse, such a conflict might not be discovered until the contraditory commitment has been made. ↩ The E programming language ↩ Proceedings of the Financial Cryptography Conferences, Springer-Verlag ↩ Composing contracts: an adventure in financial engineering – A different kind of language for specifying financial contracts in order to compute their risk and value. ↩ Lopez and Raymond, Medieval Trade in the Mediterranean World: Illustrative Documents, Columbia University Press 2001. ↩ ↩

Copyright © 2002 by Nick Szabo

Preliminary draft -- Redistribution only with written permission of author.

Editor's note: The source file contains comments with additional notes and thoughts by the author. Some links may be broken.Secure Property Titles with Owner Authority

Nick Szabo Originally published in 1998



The advent of writing greatly improved the tracking of property rights, and indeed gave rise to our modern systems of property rights and law. However, written records have proven to be quite vulnerable to abuse. A common pattern during eras of political instability or oppression has been the confiscation of land via the forgery or destruction of public records. Reconstruction from informal records, such as residency recorded in phone books, even when possible is costly and fraught with error and potential for fraud[1]. Large amounts of, in some areas most, property in developing countries is not formally titled[2]. Even during eras of political stability in developed countries, there occur many expensive problems with titles.[3] Straightforward transcription of written records into a centralized online repository would make many of these problems even worse – electronic records can be highly vulnerable to loss and forgery, and insiders are the most common source of such attacks. This paper proposes a secure, distributed title database to prevent such attacks against property rights in the future.

Many kinds of Internet resources have a basic characteristic: users must agree on their control across trust boundaries. A big example is names. The article "Names: Decentralized, Secure, Human-Meaningful: Choose Two" dismisses not only the ubiquity and importance of this problem, but also the possibility of solution.[4] Instead petnames are proposed. These are at best mere mnemonics to translate human-readable into cryptographic names; petnames don't do anything to secure naming across trust boundaries. All three attributes – decentralized, secure, and human-meaningful – must be provided if people are to communicate and be communicated about securely over the Internet, and this paper along with the article Advances in Distributed Security shows how to provide all three.

More generally, we show how to implement transferable global rights, enforced entirely by protocol, to names, attributions, bit gold, and similar purely informatic property owned by a particular entity but possessed and relied upon by the public, and how to implement a secure title database for other kinds of property. For a particular example of cross-trust-boundary rights enforced entirely by protocol, see my proposal for name integrity in cross-trust-boundary file systems.

In all cases of property rights there is a defined space, whether a namespace or physical space, and the task is to agree on simple attributes of or rights to control subdivisions of that space. In some cases a name or other symbol corresponds to a person or object owned or controlled by that person. For example, Internet users must agree on which domain name corresponds to which web site operator. In other cases we are simply concerned with control over a subdivision of the space. With real estate we must agree on who owns various rights (to occupy the surface, to mine the minerals under, etc.) to a piece of land. With radio spectrum we must agree on who owns what range of frequencies and in what physical space (or transmitting power as an easily observed approximation of physical space used).

It is the author's hypothesis that all such agreements of control, including control over the semantics of symbols, to be made and respected across trust boundaries are problems of agreeing on and maintaining property rights. Thus the results of this paper are far more general than they might first appear – I believe this paper provides a solution to secure namespaces and similar problems as well as the problem of securely recording agreements on traditional property rights. Highlighting the property rights nature of public directories also highlights the limitations of these mappings – for example that names, addresses, and other symbols whose semantics are controlled by a person can often be delegated, just as property can be given or rented.

New advances in replicated database technology will give us the ability to securely maintain and transfer ownership for a wide variety of kinds of property, including not only land but chattels, securities, names, and addresses. This technology will give us public records which can "survive a nuclear war", along the lines of the original design goal of the Internet. While thugs can still take physical property by force, the continued existence of correct ownership records will remain a thorn in the side of usurping claimants.

I use political words in this essay as metaphors to describe how our hypothetical property title software, and especially its protocol for distributing the title database across a public network, could work. A group, called a property club, gets together on the Internet[5] and decides to keep track of the ownership of some kind of property. The property is represented by titles: names referring to the property, and the public key corresponding to a private key held by its current owner, signed by the previous owner, along with a chain of previous such titles. Title names may "completely" describe the property, for example allocations in a namspace. (Of course, names always refer to something, the semantics, so such a description is not really complete). Or the title names might simply be labels referring to the property. Various descriptions and rules – maps, deeds, and so on – may be included.

The property club can be thought of as a "microgovernment", an entity that performs globally and independently one narrow function normally associated with government. In particular it is a "constitutional microdemocracy" with low entry and exit costs. After the rules of property transfer have been decided, each vote should stay within this constitution – so that normally the vote will simply implement a distributed operation according to the property rules. The voting is necessary not due to a democratic political ideology but because it is the optimal result in analysis of distributed databases with malicious attackers.[6] If the rules are violated by the winning voters, the correct losers can exit the group and reform a new group, inheriting the old titles. Users of the titles (relying parties) who wish to maintain correct titles can securely verify for themselves which splinter group has correctly followed the rules and switch to the correct group. If the rules are violated by losing voters, they can be excluded from further participation both by correct winners and rule-following relying parties.

This voting-or-reformation method works well where exit costs are low. Thus in practice users should not "put all their eggs in one basket", but different title clubs should be used for different kinds of property. Note that the key security feature of the club is not the voting, but a set of objective, often automated, rules and an unforgeable audit trail that allows both club members and relying parties to check whether each vote followed the rules. So, to go further with the political metaphor, a property club is a "constitutional microdemocracy" with most of the emphasis on the "constitutional". The voting is necessary, but is quite regulated.

To implement a property club, we set up a replicated database so that the club members, hereafter "servers", can securely maintain titles of ownership, and securely transfer them upon the request of current owners. Actually getting end users to respect the property rights agreed upon by this system will be dependent on the specific nature of the property, and is beyond the scope of the current inquiry. The purpose of the replicated database is simply to securely agree on who owns what. The entire database is public.

Confidentiality will be addressed below.

The ideal title database would have the following properties:

Current owner Alice should be able transfer her title to only a single relying counterparty (similar to the "double spending" problem in digital cash) Servers should not be able to forge transfers Servers should not be able to block transfers to or from politically incorrect parties.

We cannot achieve ideals (1) and (3), so we introduce "voting" as follows. A good model of secure replicated databases is the "Byzantine Quorum System" of Malkhi & Reiter[6]. In contrast to most recent work in peer-to-peer software, our design is based on mathematical proofs of security rather than hand-waving. For a short discussion of such threshold-of-servers approaches, see my essay "Coalition Design for Secure Protocols". The database is replicated across a universe of servers U, |U|=n. The "quorum system" is a collection of subsets (quora) of these servers, each pair of which intersect. Each quorum can operate on behalf of the system; intersection guarantees that operations done on distinct quora preserve consistency. A quorum system tolerant of Byzantine (unconditionally malicious) server failures is a collection of subsets of servers, each pair of which intersect in a set containing sufficiently many correct servers to guarantee the consistency of the replicated data. The authors construct a protocol such that any intersection contains at least 2f+1 servers, thus providing resilience against up to f malicious servers, n > 4f.

Using these results it looks like we can approach our ideal title database as follows:

Alice signs the title and Bob's public key, and sends this message to 2f+1 servers, committing her to transfer title to Bob. Bob checks at least 2f+1 servers before relying on Alice's transfer. No collusion of servers can forge Alice's signature (we achieve at least this property ideally!) A conspiracy of >=(1/4)n servers can block a transfer. Alice's only recourse is to use some other channels to broadcast her intention, demonstrating that the registry did not follow her wishes, and hoping the alternative channels are more reliable. Bob only has similar recourse if he signed a document with Alice demonstrating their intentions to transfer title from Alice to Bob. The most basic recourse is a correct subset of servers which exits the property club and establishes a new one, then advertises its correctness (and proves the incorrectness of its rival group) as described above.

Sharing control over property, for example as security for a loan, could be accomplished by sharing the private key corresponding to the current owner's public key. Possession of this private key is required to sign over title; multiparty threshold signatures could also be handled. So it may be a good idea to use one keypair for each combination of title and current owner, rather than keypairs representing the identities of owners. When certain contractual conditions are met, such as the last payment on a loan, this could trigger the generation of a new keypair held solely by the owner, and transfer of title from the shared keypair to the new keypair.

Divisibility and Homesteading

The initial allocations might occur by mapping existing property rights from their current institutional incarnation, or by using traditional methods of staking and negotiating mutual recognition of claims. Some methods less dependent on an existing legal regime for the rights will be discussed in this section.

For some kinds of allocation, such as spatial regions or a hierarchical namespace, we wish to be able to subdivided and re-merge properties. Current owner Alice should be able to transfer various fractional portions of her title to multiple single relying counterparties. One possibility is to have "divide" or "merge" messages whereby the current owner of a property can retire the old property specifications(s) and link them to new property spec(s), the whole message being signed by the owner. Then the new property spec(s) are introduced and considered active, and the old ones considered deactivated. It would be the responsibility subsequent transferees to ensure that the new specifications do not intersect, and are otherwise in good order.

One way to approach the homesteading, or initial allocation, problem, I call the "emergent respect" style: Alice claims the entire unallocated universe. Bob also claims it, the same property spec under a different digital signature. They then may choose to subdivide, sell, give away, etc. property. Each conflicting root grows like a tree into an allocation of all property.

How to resolve trees with conflicting roots? Eventually, the thugs, mechanisms, or informal agreements which enforce property rights converge on a particular tree as the standard, proper allocation. Roots who give away more property to more people, or who actually deploy mechanisms to protect their property, will gain more respect for the tree they started.

In a namespace, conflicts may be resolved by giving names to the conflicting roots, and keeping track of those name-subtree mappings as property.

Usurpers may be able to steal property by setting up their own root and enforcing it, but they can't delete the alternative allocations. The history is always there as evidence for claims.

Those with no firsthand knowledge of conflicting claims may resolve them by consulting authorities, and weighing the opinions of these authorities according to trust metrics, similar to trust metrics sometimes used for public key certificates.

With secure timestamps, homesteading could be done on a first-come rather than emergent respect basis.

Adverse Possession

For some kinds of property we might want to add the right of adverse possession, or formalized squatting. Here's one general way to implement a kind of adverse possession:

Transfers must be securely timestamped. Transfers expire. To maintain ownership, the owner must issue a new transfer to self before expiration. Upon expiration, the property may be homestead on a first-come or emergent respect basis.

This method doesn't attempt to define or utilize a state of "disuse". Instead it equates activity of the property with the ongoing active online presence of an owner who knows about the title and wishes to continue ownership. Cost of maintaining the title might be made high by requiring a periodic registry fee from owners. However, this introduces the problem of who obtains the benefit, by property club rules, of the profits from this fee, and the problem of that the fee lowers the profit of owning the property, even perhaps making it negative. One possibility, where costs of protecting the property are high, is to charge a "Georgian tax" based on some imprecise but objective estimate of the value potential of the property, and allocate the fees to the task of securing the property. To come up with this estimate, or to account for usage of the property itself, would involve mechanisms or observation of characteristics specific to the kind of property, to which subject we now turn.

Correspondence to Ground

Largely unaddressed above is the problem of divergence between actual conditions and directory rights. For example, squatters might legitimately, in the eyes of most property rights enforcers, occupy and improve unused land which a title registry indicates is owned by others. De Soto[2] describes squatters and emergent property rights on the American frontier and today's developing world. When names are property, a name may violate a pre-existing trademark, causing the confusion that both the new namespace and the old trademark namespace were designed to solve.

When divergence becomes too great, a solution to address the unreality of the title registry is needed. One such solution is for the squatters to set up their own rival registry, and then prove the superior correspondence of their registry to actual reality over control and use of the resources. Another solution for squatters is to use the adverse possession mechanism described above – but this works only if the cost of maintaining the title is sufficiently high.

Another solution is to examine the incentives of the titled owner, to see if they correspond to truthfully claiming control over a resource. In most cases there may be incentive to lie, and we can't use this method. In some cases there is incentive to tell the truth and we can, with caveats, rely on it. Any such incentive assumption in the property rules should be explicated, so that relying parties can examine whether the conditions creating the incentive still hold.

Another solution is for property club rules and the registry to originally incorporate rich information about the actual state of property, and modify the actual ownership and transfer on this property based on that state, in a way that leaves few ambiguities so it can be fully audited by club members and third parties. It is most advantageous when this auditing can remain automated, as envisioned above. However the introduction as rule criteria of unrecorded (or unsecurely recorded) transient states common in physical property causes auditing, and thus the titles, to become both less secure and more expensive.

Confidential Ownership

Using a new key pair for each transfer, besides facilitating shared control over property, can also help solve the confidentiality problem, and make it so that servers cannot discriminate against politically incorrect parties. This takes advantage of the "blindfolded justice" effect provided by anonymity. The holder of the unique key can remain anonymous (to some extent, see caveats below) and still transfer the title to others. One could contact the owners if they incorporate remailer-return envelopes with the title.

Anonymous property titles would have some other interesting consequences. Let's say there's a public good which nobody has incentive to fund unless they own most of a certain kind of property. (For example, the classic stock market takeover, where only holders of large voting blocks will put in the oversight needed to straighten out management). They could purchase property under different keys without raising suspicion that a takeover is underway. Of course, the same strategy could be used to create monopolies for less useful purposes.

If potential users of a property don't know who the owner of the property is, that might make practical enforcement of some kinds of property rights difficult. To enforce Alice's rights, she may have to prove to a jurisdiction that she owns the property. She can prove that the titled owner claims that she owns (not the same thing as proving that she owns, but perhaps good enough for enforcement purposes) by signing her jurisdictional name with the current owner's key. To completely prove that she owns, she would have to transfer the title to her jurisdictional name. (The jurisdiction being the entity that actually physically enforces the property rights, where this is necessary). In either case, it seems she has to reveal her jurisdictional identity in order to enforce her rights.

Self-enforcing property protection protocols might allow more anonymity, where these are feasible.

Some kinds of property would naturally be associated with some physical location, and thereby not be very anonymous. Furthermore, a mass of transaction detail can accumulate in the public database, revealing unique patterns of behavior. So overall the anonymity is pretty weak even with use-once keys, and may raise problems with hidden monopolies and enforcement.

So it would be nice if the servers could be trusted not to block trades even when they know the identities of the owners. In the design I suggested a conspiracy of >=1/4 of the servers can so block. It might also be nice if some sort of blinding/mixing mechanism (a la digital cash) could be introduced to unlink trades between these identities while maintaining the integrity of ownership transfer, so that the public database doesn't reveal so much traffic information.

Keeping Servers Honest

The two theoretical areas dealing with this are Byzantine agreement (used here) and multiparty secure computation. Some recent work in these areas has been done by:

The Byzantine agreement and related results typically require n>3f. (n is the number of servers and f is the number of maliciously faulty, or "Byzantine", servers that can be tolerated). Multiparty secure comptutions achieve n>2f but assume Byzantine agreement for synchronization, so they have in theory a 3f "security hole".

Variations don't always achieve such numbers. The Malkhi/Meiter replicated database achieved only n>4f. (They do have a newer paper I haven't read which may improve upon this by going to "highly probable" security).

Under the assumption of digital signatures, agreement can be reached in n > f. This gives the same abstract trust model as the untraceability of anonymous remailers. (Of course, actually getting the message through requires all n remailers to work properly, so in that sense even cf reliability is better than remailers). It would be neat if one could do a replicated database with such a high trust threshold, but I haven't seen anything like that in the literature and there may be good reasons why we can't.

Economic security models would be desirable here, but are not ready for prime time. Deciding what the preferences and resources of the attacker should be is tough. Economists assume some typical probability distribution of preferences, and some constant amount of wealth. Cryptographers, and even some people studying fault tolerance, assume a much more powerful and malicious adversary: with polynomial computational resources, and preferring to do the most damage possible to the user. The Byzantine attacker's utility is precisely the negative utility of the user!

Economic models tend to look at linear or constant differences (Mallet can't make more money than it costs him to crack the security, so Mallet won't try to crack it) whereas cryptographers prefer super-polynomial differences (the cost to Mallet is super-polynomial in a security parameter controlled by the defender). Economic models bear some similiarity to the "benign" models of statistically distributed error in fault tolerance (as opposed to the "Byzantine" models of maximally malicious faults). However, once security models bubble up to the level of trading off f vs. 2f vs. 3f security, we have the same linear structure as an economic model. So it would make sense to introduce economics at that level of analysis.

Economic security ideas like "exposure" make a lot of sense, especially for financial security. An example is the the ATM limit of $300/day: this is the user's "exposure", the most she can lose, to a crack of the ATM system. This is a "knob" which can be adjusted to reflect the current costs of cracking the security.

So it would be nice to come up with good theories along these lines at some point. Another nice thing might be a theoretical regime "in between" economics and cryptography, dealing with resource and preference differences within the polynomial range (e.g., O(n4) vs. O(n)).

Acknowledgements

My thanks to Gregory Burch, J.D., Eileen O'Connor, J.D., Melora Svoboda, and many others for their helpful comments.

References

Byzantine Quorum Systems

Dahlia Malkhi and Michael Reiter. Byzantine quorum systems. Journal of Distributed Computing, 11(4):203--213, 1998.

Dahlia Malkhi, Michael Reiter, and Rebecca Wright. Probabilistic quorum systems. Proceeding of the 16th Annual ACM Symposium on the Principles of Distributed Computing (PODC 97), pages 267--273, Santa Barbara, CA, August 1997.

Lorenzo Alvisi, Dahlia Malkhi, Evelyn Pierce, Michael Reiter, and Rebecca Wright. Dynamic Byzantine Quorum Systems International Conference on Dependable Systems and Networks (DSN, FTCS-30 and DCCA-8), New York, 2000.

Copyright © 1998,1999,2002,2005 by Nick Szabo

Permission to redistribute without alteration hereby granted

Editor's note: muted text indicates the text was commented out in the source file.Trusted Third Parties Are Security Holes

Nick Szabo Originally published in 2001



Introduction

Commercial security is a matter of solving the practical problems of business relationships such as privacy, integrity, protecting property, or detecting breach of contract. A security hole is any weakness that increases the risk of violating these goals. In this real world view of security, a problem does not dissapear because a designer assumes it away. The invocation or assumption in a security protocol design of a "trusted third party" (TTP) or a "trusted computing base" (TCB) controlled by a third party constitutes the introduction of a security hole into that design. The security hole will then need to be plugged by other means.

If the risks and costs of TTP institutional alternatives were not accounted for in the protocol design, the resulting protocol will in most cases be too costly or risky to be practical. If the protocol beats these odds and proves practical, it will only succeed after extensive effort has gone into plugging the TTP security hole(s). TTP assumptions cause most of the costs and risks in a security protocol, and plugging TTP security holes produces the most benefit and profit.

As a result, we propose a security protocol design methodology whereby the most risky and expensive part(s) of a security protocol, the trusted third partie(s), are designed in parallel with security protocol(s) using those parties. The objectives of cost and risk minimization are focused on the TTPs rather than the security protocols themselves, which should be designed to suit the cost and risk minimized TTPs.

We also briefly discuss and reference research and implementation in security mechanisms that radically reduce trusted third party costs and risks by distributing automated TTPs across several parties, only a portion of which need to act in a reliable or trustworthy matter for the protocol to be reliable or trustworthy.

New Trusted Third Parties are Costly and Risky

This author has professional experience implementing a TTP that was assumed by early advocates of public key cryptography. This TTP has come to be called a "certificate authority" (CA). It has been given the responsibility of vouching for the "identity" of participants. (Here I focus on the costs imposed by the TTP; alternatives such as PGP's Web of Trust and SPKI have been discussed amply elsewhere).

The certificate authority has proved to be by far the most expensive component of this centralized public key infrastructure (PKI). This is exacerbated when the necessity for a TTP deemed by protocol designers is translated, in PKI standards such as SSL and S/MIME, into a requirement for a TTP. A TTP that must be trusted by all users of a protocol becomes an arbiter of who may and may not use the protocol. So that, for example, to run a secure SSL web server, or to participate in S/MIME, one must obtain a certifcate from a mutually trusted certificate authority. The earliest and most popular of these has been Verisign. It has been able to charge several hundred dollars for end user certificates – far outstripping the few dollars charged (implicitly in the cost of end user software) for the security protocol code itself. The bureaucratic process of applying for and renewing certificates takes up far more time than configuring the SSL options, and the CA's identification process is subject to far greater exposure than the SSL protocol itself. Verisign amassed a stock market valuation in the 10's of billions of U.S. dollars (even before it went into another TTP business, the Internet Domain Name System(DNS) by acquiring Network Solutions). How? By coming up with a solution – any solution, almost, as its security is quite crude and costly compared to the cryptographic components of a PKI – to the seemingly innocuous assumption of a "trusted third party" made by the designers of public key protocols for e-mail and the Web.

Some more problems with CAs are dealt with here.

The Internet DNS is another example of the high costs and risks imposed by a TTP. This one tiny part of the TCP/IP protocol stack has accounted for a majority of the disputes and handwringing involving that protocol. Why? Because it is one of the few areas of the TCP/IP stack that depends on a centralized hieararchy of TTPs rather than on protocol negotiations between individual Internet nodes. The DNS is also the single component of the Internet most likely to fail even when its names are not being disputed or spoofed.

The high costs of implementing a TTP come about mainly because traditional security solutions, which must be invoked where the protocol itself leaves off, involve high personnel costs. For more information on the necessity and security benefits of these traditional security solutions, especially personnel controls, when implementing TTP organizations, see this author's essay on group controls. The risks and costs borne by protocol users also come to be dominated by the unreliability of the TTP – the DNS and certificate authorities being two quite commom sources of unreliability and frustration with the Internet and PKIs respectively.

Existing Trusted Third Parties are Valuable

Companies like Visa, Dun and Bradstreet, Underwriter's Laboratories, and so forth connect untrusting strangers into a common trust network. Our economy depends on them. Many developing countries lack these trust hubs and would benefit greatly from integrating with developed world hubs like these. While these organizations often have many flaws and weaknesses – credit card companies, for example, have growing problems with fraud, identity theft, and innacurate reports, and Barings recently went belly up because their control systems had not properly adapted to digital securities trading – by and large these institutions will be with us for a long time.

This doesn't help us get TTPs for new protocols. These institutions have a particular way of doing business that is highly evolved and specialized. They usually cannot "hill climb" to a substantially different way of doing business. Substantial innovations in new areas, e.g. e-commerce and digital security, must come from elsewhere. Any new protocol design, especially paradigmatically different areas such as capabilities or cryptographic computations, will be a mismatch to the existing institutions. Since building new TTPs from scratch is so costly, it is far cheaper when introducing protocols from these institutionally novel security technologies to minimize their dependencies on TTPs.

New Trusted Third Parties Can Be Tempting

Many are the reasons why organizations may come to favor costly TTP based security over more efficient and effective security that minimizes the use of TTPs:

Limitations of imagination, effort, knowledge, or time amongst protocol designers – it is far easier to design security protocols that rely on TTPs than those that do not (i.e. to fob off the problem rather than solve it). Naturally design costs are an important factor limiting progress towards minimizing TTPs in security protocols. A bigger factor is lack of awareness of the importance of the problem among many security architects, especially the corporate architects who draft Internet and wireless security standards.

The temptation to claim the "high ground" as a TTP of choice are great. The ambition to become the next Visa or Verisign is a power trip that's hard to refuse. The barriers to actually building a successful TTP business are, however, often severe – the startup costs are substantial, ongoing costs remain high, liability risks are great, and unless there is a substantial "first mover" advantage barriers to entry for competitors are few. Still, if nobody solves the TTP problems in the protocol this can be a lucrative business, and it's easy to envy big winners like Verisign rather than remembering all the now obscure companies that tried but lost. It's also easy to imagine oneself as the successful TTP, and come to advocate the security protocol that requires the TTP, rather than trying harder to actually solve the security problem.

Entrenched interests. Large numbers of articulate professionals make their living using the skills necessary in TTP organizations. For example, the legions of auditors and lawyers who create and operate traditional control structures and legal protections. They naturally favor security models that assume they must step in and implement the real security. In new areas like e-commerce they favor new business models based on TTPs (e.g. Application Service Providers) rather than taking the time to learn new practices that may threaten their old skills.

Mental transaction costs. Trust, like taste, is a subjective judgment. Making such judgement requires mental effort. A third party with a good reputation, and that is actually trustworthy, can save its customers from having to do so much research or bear other costs associated with making these judgments. However, entities that claim to be trusted but end up not being trustworthy impose costs not only of a direct nature, when they breach the trust, but increase the general cost of trying to choose between trustworthy and treacherous trusted third parties.

Personal Property Has Not and Should Not Depend On TTPs

For most of human history the dominant form of property has been personal property. The functionality of personal property has not under normal conditions ever depended on trusted third parties. Security properties of simple goods could be verified at sale or first use, and there was no need for continued interaction with the manufacturer or other third parties (other than on occasion repair personel after exceptional use and on a voluntary and temporary basis). Property rights for many kinds of chattel (portable property) were only minimally dependent on third parties – the only problem where TTPs were neededwas to defend against the depredations of other third parties. The main security property of personal chattel was often not other TTPs as protectors but rather its portability and intimacy.

Here are some examples of the ubiquity of personal property in which there was a reality or at least a strong desire on the part of owners to be free of dependence on TTPs for functionality or security:

Jewelry (far more often used for money in traditional cultures than coins, e.g. Northern Europe up to 1000 AD, and worn on the body for better property protection as well as decoration)

Automobiles operated by and house doors opened by personal keys.

Personal computers – in the original visions of many personal computing pioneers (e.g. many members of the Homebrew Computer Club), the PC was intended as personal property – the owner would have total control (and understanding) of the software running on the PC, including the ability to copy bits on the PC at will. Software complexity, Internet connectivity, and unresolved incentive mismatches between software publishers and users (PC owners) have substantially eroded the reality of the personal computer as personal property.

This desire is instinctive and remains today. It manifests in consumer resistance when they discover unexpected dependence on and vulnerability to third parties in the devices they use. Suggestions that the functionality of personal property be dependent on third parties, even agreed to ones under strict conditions such as creditors until a chattel loan is paid off (a smart lien) are met with strong resistance. Making personal property functionality dependent on trusted third parties (i.e. trusted rather than forced by the protocol to keep to the agreement governing the security protocol and property) is in most cases quite unacceptable.

TTP Minimizing Methodology

We now propose a security protocol design methodology whereby protocol(s) are designed to minimize these costs and risks of the TTPs. Minimizing the costs and risks of the security protocol(s) themselves is an important but secondary priority.

Currently, security designers usually invoke or assume TTPs to suit the most elegant and secure or least computationally costly security protocol. These naive TTPs are then used in a proof of concept of an overall protocol architecture. But this does not discover the important things that need to be discovered. Once a security protocol is implemented the code itself costs very little, and exponential cost functions such as Moore's law keep reducing computational, bandwidth, and many other technological costs. The costs of the security protocol itself (except for the costs of message rounds, limited by the speed of light, and the costs of the user interface, limited by mental transaction costs) approach zero. By far the largest long-term cost of the system (as we learned with PKI) is the cost of implementing the TTPs.

It's far more fruitful to estimate from the beginning what the TTPs will cost, rather than try to design the security protocols to minimize the costs of the TTPs. This will likely bring the designer to quite different trust assumptions and thus security protocols than if (s)he assumes pure, unanalyzed TTPs in certain places in order to simplify the security protocol. A natural corrolary is if that there exists a security protocol that can eliminate or greatly reduce the costs of a TTP, then it pays greatly to implement it rather than one which assumes a costly TTP. Even if the latter security protocol is simpler and much more computationally efficient.

A corollary of "trusted third parties are security holes" is "all security protocols have security holes", since no protocol is fully free of such assumptions. The key steps in estimating TTP costs and risk are to (1) examine one's assumptions thoroughly to uncover all TTP assumptions and characterize specifically what each TTP is and is not expected to do, (2) observe that each such specific hole and task has an associated cost and risk.

There are several other important considerations, including:

Design costs. Minimizing TTPs often involves learning and applying nonintuitive and complex cryptographic and fault tolerance techniques, like some of those mentioned below. This can be a major burden or impractical for a small smart contracts project. On the other hand, design costs for a novel TTP institution are usually much higher than the design costs for a new protocol, as expensive as the latter may be. Determining whether the new institution is robust over the long term is more expensive still, while protocols can be formally analyzed and implementations audited against this analysis to achieve a very high level of confidence in a typical product development timeframe.

User mental transaction costs – multiplying TTPs, even ones with a reasonably limited function, can quickly tax the ability of end users to track the reputation and quality of the different trusted brands. When TTPs are distributed (as in the technology described below) reputation tracking must be automated, which is much easier when the TTPs redundantly perform the same function.

If for a new context like e-commerce we can find a security protocol which replaces a TTP organization (a complex set of traditions quite unproven in the new context) with mathematics (which at least in itself is quite clear and provable) it will often be a very big win to do so. More often we will replace a complex costly TTP with one or more much simpler TTPs plus mathematics. That too is a big win. We can only tell if and by how much it is a win by focusing on the trust assumptions and the resulting costs of the TTPs rather than focusing on the efficiency of the security protocol. The key is to focus on the cost of the TTPs and design the security protocol to minimize them, rather than assuming TTPs in order to simplify or optimize the efficiency of the security protocol.

A good digital security protocol designer is not only an expert in computer science and cryptography, but also very knowledgeable about the traditional costly techniques of physical security, auditing, law, and the business relationships to be secured. This knowledge is not used to substitute these costly security methods for more cost effective digital security, but in order to minimize hidden dependence on costly methods for the real security. A good protocol designer also designs, rather than merely assumes, TTPs that work with minimal use of costly techniques.

TTP Minimizing Protocols

We saw above that the keys to minimizing TTPs are to identify them, characterize them, estimate their costs and risks, and then design protocols around TTPs of minimal cost and risk. When the risk is mitigated with techniques like those in this session, it can be very substantially reduced.

Three areas of research and implementation show special promise in improving trust. Two of these involve the particularly thorny area of privacy, where breach of trust is often irreversible – once data gets out it can be impossible to put back.

The first protocol family in which trust can be distributed to preserve privacy is the Chaum mixes. Mixes allow communications immune from third party tracing. Only any one out of N proxies in a proxy chain need be trustworthy for the privacy to be preserved. Unfortunately, all N of the proxies need to be reliable or the message will be lost and must be resent. The digital mix protocol's tradeoff is to increase messaging delays (resends) in order to minimizes the risk of irreversible privacy loss.

Another protocol family in which trust can be distributed to preserve privacy is the multiparty private computations. Here a virtual computer is distributed across the N parties who provide specially encrypted input to each other rather than to a trusted third party. The distributed computer takes inputs from each of the N parties, computes an agreed to algorithm, then outputs the answer. Each party learns only the answer not the inputs of any other party. The threshold of parties that that must collude to violate privacy or threaten reliability can be traded off and have been studied in detail in the ample literature on this topic. Multiparty private computations can be used for confidential auditing, confidential preference gathering and data mining, auctions and exchanges with confidential bids, and so on.

A protocol family that replicates data, and distributes operations on that data, while preserving the integrity of that data, are the Byzantine resilient replicated databases. Implementations of Byzantine resilient replicated databases include Fleet and Phalanx. Fleet implements replicated persistence of general purpose objects. Some open source implementations, which approach but do not achieve Byzantine resilience, general purpose, or complete decentralization include Mojo Nation and Freenet. Applications include secure name registries and property titles as well as securely published content in Mojo Nation and Freenet. The most advace work in this area involves Byzantine fault tolerant quorum systems and other recent advanced in distributed security.

It is important to note that these threshold techniques are only meant to enhance the integrity of a single step or run of the protocol. Practical systems, such as Mojo Nation, combine a majority or super-majority within a particular run with failure detection and choice by clients of servers between runs. So we can add back all the reputation systems, auditing, and so on that add robustness in the long term to distributed systems. The majorities or super-majorities within an invocation create a very good short-term robustness that is missing from current systems like Freenet and Mojo Nation. (It's only party missing from Mojo, which has a 4-of-8 voting scheme but this has not been shown to be Byzantine resilient up to 4-of-8).

Remote Attestation of Server Code

Remote attestation has been proposed for verifying the state of software running on clients to protect intellectual property. A more valuable use for remote attestation is for verifying the behavior of servers. This is also called the transparent server approach. Through remote attestation, clients can verify that the specific desired code is running on a server. Combined with the ability to audit that code as open source, remote attestation of servers can greatly decrease the vulnerability of clients and users to the server. Given the importance of the trusted third party problem we have discussed here, this approach has vast potential to convert trusted third party protocols into secure protocols, and to make possible a wide variety of secure protocols that were heretofore impossible. For example, Hal Finney has implemented a version of bit gold called reusable proofs of work, based on a secure coprrocessor board that allows users to remotely attest the code running on the card. While one still needs to trust the manufacturer of the card, this manufacturer is separated from the installation of server code onto and the operation of the server on the card.

Leaving Small Holes Unplugged

Often the protocol designer can't figure out how to fix a vulnerability. If the attack one needs a TTP to protect against is not a serious real-world threat in the context of the application the designer is trying to secure, it is better to simply leave the small hole unplugged than to assign the task to a TTP. In the case of public key cryptography, for example, protocol designers haven't figured out how to prevent a "man-in-the-middle" (MITM) attack during the initial key exchange. SSL tried to prevent this by requiring CAs as trusted third parties, as described above, and this solution cost the web community billions of dollars in certificate fees and lost opportunities to secure communications. SSH, on the other hand, decided to simply leave this small hole unplugged. The MITM hole has, to the best of my knowledge, never even once been exploited to compromise the privacy of an SSH user, yet SSH is far more widely used to protect privacy than SSL, at a tiny fraction of the cost. This economical approach to security has been looked at at greater length by Ian Grigg.

Unscrambling the Terminology

Alan Karp, Mark Miller, and others have observed the confusion over words like "trust" and "trusted" as used in the security community, and proposed replacing the verb "trusts" with "is vulnerable to". This substitution is a great way to radically clarify security protocol designs. "Trusted third party" as used in this essay becomes "vulnerable to a third party", and the point of this paper, that this is a security hole, becomes obvious.

In the context of protocol designs, instead of saying the protocol designer trusts some little-known generic class of parties (referred to in the singular as "a trusted third party") with a given authorization (which probably really means the protocol designer just can't figure out how to plug a security hole), an honest protocol designer will admit that there is a vulnerability here – and that it is up to "out of band" mechanisms to plug or minimize, or up to users to knowledgeably ignore, that hole. The class of parties is little-known because security protocol designers typically don't know much about the traditional non-digital security, legal, and institutional solutions needed to make such a party trustworthy. The substitution of "vulnerable to" for "trusted" works well in protocol design, and in communicating honestly about the security of a protocol.

Alas, are security designers and sellers of security systems who invoke "trusted third parties", "trusted computing", and the like really going to come out and admit that their protocols are "vulnerable"? Security designs sound so much more secure when they use the euphemism "trust".

In the real world, beyond the technical context of security protocol design, "trust" has a variety of meanings. One different use of "trust" is well-informed trust, for example "I trust this armor to protect me from normal bullets, because it's been very well tested", "I trust this site with this authorization because we're using a strong security protocol to protect me when I grant this authorization", or "I trust my wife with the kids", in which cases translating "trust" to "am vulnerable to" would be to reverse its meaning. That "trust" can take on practically opposite meanings, depending upon the context, is another strong argument for avoiding use of the word when describing the vulnerabilities, or lack thereof, of security protocols. Whether a designer thinks he does or must trust some generic class of parties is one thing. Whether a particular user will actually trust a particular entity in that class when the protocol actually runs is quite another matter. Whether either the user's trust or the designer's trust is well informed is yet another matter still.

Conclusion

Traditional security is costly and risky. Digital security when designed well diminishes dramatically in cost over time. When a protocol designer invokes or assumes a TTP, (s)he is creating the need for a novel organization to try to solve an unsolved security problem via traditional security and control methods. Especially in a digital context these methods require continuing high expenditures by the TTP and the TTP creates a bottleneck which imposes continuing high costs and risks on the end user.

A far better methodology is to work starting from TTPs that either well known, or easy to characterize, and of minimal cost. The best "TTP" of all is one that does not exist, but the necessity for which has been eliminated by the protocol design, or which has been automated and distributed amongst the parties to a protocol. The latter strategy has given rise to the most promising areas of security protocol research including digital mixes, multiparty private computations, and Byzantine resiliant databases. These and similar implementations will be used to radically reduce the cost of current TTPs and to solve the many outstanding problems in privacy, integrity, property rights, and contract enforcement while minimizing the very high costs of creating and operating new TTP institutions.

References

Links in the text.

Acknowledgements

My thanks to Mark Miller who encouraged me to write down these thoughts and provided many good comments. My thanks also to Hal Finney, Marc Stiegler, David Wager, and Ian Grigg for their comments.

Copyright © 2001, 2004, 2005 by Nick Szabo

Permission to redistribute without alteration hereby grantedContracts with Bearer

Nick Szabo Originally published in 1997



Bearer Certificates

"Digital bearer certificate" is a broad term developed by this author[1] incorporating at least two emerging technologies: digital cash and distributed capabilities (secure distributed object references). I will first describe the Chaumian protocol and its innovative privacy feature. I will then discuss how these ideas map to the world of capabilities in the section on generic vs. specific rights. I have altered digital cash terminology from digital cash to bearer certificate or token, from mint to issuer or transfer agent, and so on to reflect the ability of Chaum's protocols to generalize. Chaumian bearer certificates implement standardized rights transferable regardless of the identity of the holder. Each kind of contract (for example, each denomination of "coin" in digital cash) corresponds to a digital signature, just as each issue of Federal Reserve Notes or stock certificates corresponds to a particular plate.

In the most straightforward Chaumian protocol, the issuer and transfer agent (the same entity, for our purposes, though they can easily be unbundled) create a serial number (really a large unguessable random number, rather than a sequence), and append it to a list of issued certificates. The transfer agent clears a transfer (i.e., redeems the certificate) by checking the signature to identify the class of bearer contract and verify that it was made, then looking on that contract's issued list to make sure the serial number is there, then removing the serial number. Alternatively, the issuer can let the issuee make up the serial number, then, when cleared, check the signature and put the number on the list of cleared certificates. The signature provides the assurance that the certificate is indeed the the particular kind of contract with bearer, while the serial number assures that the same instance of that contract is not cleared or redeemed more than once. In these simple versions, the transfer agent can link the transferee to the transferor for all transfers. To implement the privacy characteristics of coins and physical bearer certificates, we need to add unlinkability features.

Blind Signatures

Meet the greatest simple equation since e=mc2:

gSf(m) = S(m)

S is a digital signature. f is the blinding function, and g an unblinding function. The blinding functions are usually based on a secret random number called the "blinding factor". m is another random number, a unique identifier which can, for example, refer to an instance of some object.

The idea is very clever but very simple. It may be counterintuitive because the simplest physical world metaphor of this highly useful e-commerce primitive sounds worse than useless: Alice can get Carol to sign a blank check! Here's how:

Alice generates m and blinds it. "Blinding" is just a one-time-pad encryption to oneself, f(m) . She sends this to Carol. This is like taking a piece of paper and sealing it inside an envelope which Carol can't open or see through. Carol signs it: Sf(m) , and sends this back to Alice. This is like Carol signing the outside of the envelope. Alice unblinds it: gSf(m) = S(m) . Carol has also signed the paper Alice put inside the envelope!

The genius behind this discovery: cryptography guru David Chaum. The brilliance lies in step 3: Chaum discovered that some signatures have the property of being "commutative" with the blinding functions: Alice can strip off the blinding in the reverse order which the blinding and signature were applied, leaving just Alice's signature of n. It is as if Alice put a piece of carbon paper inside the envelope!

In particular for RSA signatures, with public key (pq, e) and private key d, the blind signature functions are the following modulo pq:

S(x) = xd g(x) = xk-1 f(x)= xke

We can check that the blind signature property holds: gSf(m) = (m(ke))d * k-1 = md * k * k-1 = md , which is the valid RSA signature of private key d on m.

Unlinkable Transfers

Distinguish between either a counter or third party tracing one person's true name, via lack of or weak communications mix, and a third party linking two entities (whether nyms, use-more-than-once-addresses, account numbers, or true names) as being involved in the same transaction. By unlinkability herein we mean the latter. The goal where true names are used (this occurs, for example, when using true name accounts or not using good communications mixes), is to prevent third party linking of two people doing business with each other. Where nyms are used the goal is to minimize the release of traffic information, to prevent the unwanted accumulation of unique behavior patterns, which could be used to link nyms (including to their true names), or could augment other means of breaching privacy. Blinding especially helps where rights holders want to keep third party or public accounts denominated in generic rights. In that case a communications mix doesn't even in principle give us what blinding does.

Besides protecting against the transfer agent, Chaum's transferor-, transferee-, and double-blinding protocols protect against collusion of a party with a transfer agent to identify the countparty account or nym.

Unlinkability can be provided by combining a list of cleared certificates with blind signatures and a delay-mixing effect. Enough instances of a standardized contract are issued over a period of time to create a mix. Between the issuing and clearing of a certificate, many other certificates with the same signature will be cleared, making it highly improbable that a particular clearing can be linked to a particular issue via the signature. There is a tradeoff between the mixing effect and the exposure to the theft of a "plate" for a particular issue: the smaller the issue, the smaller the exposure but the greater the linkability; a larger issue has both greater exposure and greater confidentiality.

Blind signatures can be used to make certificate transfers unlinkable via serial number. Privacy from the transfer agent can take the form of transferee-unlinkability, transferor-unlinkability, or "double blinded" where both transferor and transferee are unlinkable by the transfer agent or a collusion of a transfer agent and counterparty.

A use-once-address communications mix plus foreswearing any reputation gain from keeping accounts, in theory also buys us unlinkability, but a communications mix is weak and very expensive.

Bearer certificates come in an "online" variety, cleared during every transfer, and thus both verifiable and observable, and an "offline" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing name of any intermediate holder who transferred the object multiple times (a breach of contract).

This unlinkability is often called "anonymity", but the issue of whether accounts are issued to real names or pseudonyms, and whether transferor and transferee identify themselves to each other, is orthogonal to unlinkability by the transfer agent in the online model. In the off-line model, account identification (or at least a highly reputable and/or secured pseudonym) is required: passing an offline certificate a second time reveals this identity. Furthermore, communications channels can allow Eve to link transferor and transferee, unless they take the precaution of using an anonymous remailer. Online clearing does make lack of identification a reasonable option for many kinds of transactions, although common credit and warrantee situations often benefit from or even require identification.

When confronting an attempted clearing of a cleared serial number, we face an error-or-fraud dilemma similar to the one we encountered above in double entry bookkeeping. The ecash protocol from DigiCash actually takes advantage of on purpose to recover from a network failure. When certificates are lost over the net it is not clear to the transferor whether they have been received and cleared by the transferee or not. Second-transferring directly with the transfer agent resolves the ambiguity. This only works with the online protocol. The issue of distinguishing error from fraud is urgent in the offline protocol, but there is as yet no highly satisfactory solution. This problem is often intractable due to the subjectivity of intent.

With ideal two-way anonymous communications between use-once keys, and completely accountless clearing, unlinkability via blind signatures becomes redundant. This ideal case has yet to be even closely approached with implemented technology, and necessarily involves long communications delays which are often intolerable. Real imperfect communications mixes and less expensive blinded tokens complement each other.

Conserved Objects

Issuance and cleared transfer of references to a distributed object conserves the usage of that object. This object becomes "scarce" in economic terms, just as use of physical objects is finite. Conserved objects provide the basis for a software economics that more closely resembles economics of scarce physical objects. Conserved objects can be used to selectively exclude not only scarce physical resources (such as CPU time, network bandwidth and response time, etc.), but also fruits of intellectual labor – as long as one is willing to pay the price to interact with that information over the network rather than locally (cf. content rights management). Conservation immunizes objects and the resources they encapsulate to denial of service attacks. Bearer certificate protocols can be used to transfer references to a particular instance or set of instances of an object, just as they can be used to transfer other kinds of standardized rights.

To implement a full transaction of payment for services, we often need need more than just the digital cash protocol; we need a protocol that guarantees that service will be rendered if payment is made, and vice versa. Current commercial systems use a wide variety of techniques to accomplish this, such as certified mail, face to face exchange, reliance on credit history and collection agencies to extend credit, etc. I discuss such issues in my article on smart contracts.

Credentials

A credential is a claim made by one party about another. A positive credential is one the second party would prefer to reveal, such as a degree from a prestigious school, while that party would prefer not to reveal a negative credential such as a bad credit rating.

A Chaumian credential is a cryptographic protocol for proving that one's pseudonym (for example, the identification number one uses in a health care system) possesses credentials issued to one's other pseudonyms, without revealing linkages between these pseudonyms or between pseudonym and true name. It's based around the is-a-person credential the true name credential, used to prove, without revealing, the linkage between pseudonyms, and to prevent the transfer of pseudonyms between parties.

Generic vs. Specific Rights

To discuss the mapping between Chaumian certificates and distributed capabilities as implemented in for example E I introduce some different, partly overlapping terminology: generic vs. specific, exclusive vs. non-, Transfer Agent vs. Provider, token vs. Swiss number.

Rights can be generic or specific. Generic rights correspond to a class of objects, specific rights to an instance. So a specific right is implemented with a Swiss number, a large random number. The signed numbers corresponding to generic rights I will call "tokens".

Rights can also be exclusive or non-exlusive. Any object which must be conserved, or finally allocated to a specific user, is "exclusive".

Simple example: the right to an exclusive lock on some 1 MB of memory is generic and exclusive. The right to an exclusive lock on the specific address space 100-101 is specific and exclusive. The right to two dozen particular stock quotes at 12:22 p.m. today is specific and non-exclusive.

The main motivation for these distinctions are different mechanisms of unlinkable transfer of these rights, set out below.

For simplicity generic rights are all "use-once": the life cycle of a token consists of issuance, followed by a series of transfers, followed by consumption. More sophisticated life cycles, such as alternating transfer and consumption, are likely possible with some extra protocol.

With a perfect communications mix, including use-once return addresses, and no reputation building, we wouldn't need blinded tokens. However, communications mixes are expensive, and we want the option of having certain public records by which to build reputations, yet do certain rights transfers privately. For these reasons, we should allow clients to blind token transfers in addition to providing a communications mix.

For inexpensive, unlinkable, and verifiable transfer of exclusive generic rights, using blinded tokens, there must be a signficant population of interchangable generic rights. Such rights bundled with nonexlusive specific rights can also be cheaply transferred since online clearing is not required for the latter. Unlinkable and verifiable transfer of exclusive specific rights seems to require online clearing via an expensive communications mix.

Two kinds of TTPs: a Transfer Agent (TA) and a Provider. The TA operates like an accountless digital cash mint, clearing the transfer of tokens for generic rights. Digital cash is a special case: money is the most generic of rights.

The Provider is responsible for actually holding the object, which can contain unique state. The Provider issues a Swiss number, or better a signed description of the specific right and its Swiss number. This signature allows offline verification of the nonexlusive right where the Provider is reputable. The TA issues a token for the corresponding generic rights.

Chaum has also developed other means for dealing with unique state[2].

I'm assuming the TA and Provider have known reputable signatures. The trust or reputation needed to ensure correctness of transfer between Provider, TA, and users is partly left for later analysis. The two main goals here are to assure that users can verify their rights (including exclusivity from transferors where promised) and retain full privacy from TAs and Providers. Some other trust assumptions are likely made here which need to be explicated and analyzed.

To implement exclusive transfers, the TA keeps a list of cleared (cancelled) token numbers. The TA corresponds to a "mint" in the Chaumian online digital cash protocol (see above). A class of generic rights corresponds to a "denomination" of coin. The Provider may also keep a list of outstanding or used Swiss numbers, like an E Registrar.

Here is another example of a generic right, or class of fungible objects: "A queriable SQL database with up to 10 MB of storage, and certain standard response time guarantees".

The TA sees only classes of fungible objects. The Provider and users see particular instances with unique state, for example a database filled with unique information.

The Provider acts analogously to a "shop". It is just another token client to the TA, which like other clients can transfer or receive tokens. Its special role is that it is responsible for issuance, where it tells the TA about a new instance, obtains a new token, and transfers it to the client to whom the new generic right is being issued. The TA generates and destroys token supply only at the behest of the Provider; otherwise all its transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client bearing the promised right(s), at which time the Provider "deposits" the generic token(s), instructing the TA to decrement the token supply. In digital cash terminology, the Provider is the only entity which has to keep something like a bank account. Rights holders can also keep an account, if they wish to use it to help build reputation, or they can just use the TA for accountless conserved rights transfer.

The Provider issues along with the initial generic rights token a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's Swiss number and the public key(s) of the generic right(s) for which it is valid. For example, it might say "a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tokens.

This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.

If the Provider wished to guarantee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded token. For example, "Deep Space Station 60 from 0500-0900 Sunday" or "a lock on autoexec.bat now" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, "A one hour block on DSS-60 in May" and "the right to lock autoexec.bat at some point" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other tokens for this class of generic right transfered between the issuance and consumption of a given token.

Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.

Acknowledgements

My thanks to David Chaum, Mark Miller, Bill Frantz, Norm Hardy, and many others for taking the time to give me their valuable insights into these issues.

References

The first public references to this idea can be found here, here. I also referred to this idea during this period in many personal communications, using the phrases "digital bearer instrument", "digital bearer certificate", "scarce object", and "conserved object". The idea of digital bearer certificates as a serious proposal for the financial industry has been popularized, with many intruiging additional ideas, by Bob Hettinga. The phrases "digital bearer certificate" and "digital bearer settlement(DBS)" were soon thereafter popularized by a correspondent of mine, Robert Hettinga, as referring to a legal/institutional idea of instant, irrevocable settlement made possible by both the instant clearing and privacy features of this technology. ↩ David Chaum, Online Cash Checks ↩ "Blind Signatures for Untraceable Payments," D. Chaum,

Advances in Cryptology Proceedings of Crypto 82,

D. Chaum, R.L. Rivest, & A.T. Sherman (Eds.), Plenum, pp. 199-203. The E distributed object language

Copyright © 1997, 1999 by Nick Szabo

Permission to redistribute without alteration hereby granted

Editor's note: muted text indicates the text was commented out in the source file.The God Protocols

Nick Szabo Originally published in 1997



Imagine the ideal protocol. It would have the most trustworthy third party imaginable – a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.

Alas, in the our temporal world we deal with humans rather than deities. Yet, too often we are forced to treat people in a nearly theological manner, because our infrastructure lacks the security needed to protect ourselves.

Trusted Third Party

Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.

For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.

Mathematically Trustworthy Protocol

There are three major limitations. The first is that this virtual computer is very slow: in some cases, one arithmetic calculation per network message. Currently it is at best practical only for small logic or arithmetic calculations used as an adjunct to or component of more efficient computations and protocols.

The second is that there is a tradeoff between privacy, fairness, and fault tolerance. Fairness means everybody learning the results in such a way that nobody can gain an advantage by learning first. Fault tolerance can provide robustness against a minority, so that it takes a majority dropping out to halt the protocol, or it can be nonrobust but fail-stop, so that a single participant can terminate the protocol. Many papers have discussed the fraction of parties one must trust in order to be assured of learning the correct output. In traditional results, fairness and privacy could not both be achieved with a faulty majority. Recent papers[3][4][5][6] have produced fair and private protocols even with faulty majorities. They trade robustness for privacy and fairness against any proportion of faulty parties. The advantage of this fail-stop approach is that one can usually find new partners and start over again, but one does not want to suffer irreversible losses such as leaking information, being left holding the bag, or being convinced of an incorrect result.

The third limitation is that, far from being omniscient or omnipotent, the protocol will accomplish only what is specified in the algorithm and the inputs. It won't be able to replace human trusted third parties where those parties provide insight or knowledge that cannot be provided by a computer.

With these caveats, any algorithmic intermediary can, in principle, be replaced by a trustworthy virtual computer. In practice, because of the three complications, we usually construct more limited protocols out of more efficient elements.

Multiparty computation theory, by making possible privy virtual intermediation, has major implications, in theory, for all kinds of contractual relationships. This can be seen most clearly in the area of negotiations. A "mechanism" in economics is an abstract model of an institution which communicates with its participants via messages, and whose rules can be specified algorithmically. These institutions can be auctions, exchanges, voting, and so on. They typically implement some kind of negotiation or decision making process.

Economists assume a trusted intermediary operates the mechanism. Here's a simple example of using this virtual computer for a mechanism. Alice can submit a bid price, and Bob an ask price, then their shared virtual program which has one instruction, "A greater than B?". The computer then returns "true" if Alice's bid is greater than Bob's offer. A slightly more sophisticated computer may then decide the settlement price according to a number of different algorithms (Alice's bid, Bob's ask, split the difference, etc.) This implements the mechanism "blind bargaining" with no trusted intermediary.

In principle, since any computable problem can be solved on this virtual computer (they are "Turing complete"), any computable economic mechanism can be implemented without a trusted intermediary. In practice, we face the three limitations discussed above. But the existence proof, that any economic mechanism can be run without a trusted intermediary, is very exciting. This means that, in principle, any contract which can be negotiated through a trusted third party (such as an auction or exchange) can be negotiated directly. So, in some abstract sense, the only remaining "hard" problems in smart contract negotiations are (a) problems considered hard even with a trusted intermediary (for the standard economic reasons), and (b) the task of algorithmically specifying the negotiating rules and output contract terms (This includes cases where an intermediary adds knowledge unavailable to the participants, such as a lawyer giving advice on how to draft a contract). In practice, many problems which can be solved in principle with multiparty computation will re-arise when we implement protocols in an efficient, practical manner. The God Protocols give us a target to shoot for.

Applying this kind of analysis to the performance phase of contracts is less straightforward. For starters, economic theories of the performance phase are not as well developed or simple as the mechanism theory of negotiations. Indeed, most economic theory simply assumes that all contraccts can be perfectly and costlessly enforced. Some of the "transaction cost" literature has started to move beyond this assumption, but there are few compelling results or consensus theories in the area of techniques and costs of contract enforcement.

Performance phase analysis with multiparty secure computer theory would seem to apply only to those contracts which can be performed inside the virtual computer. But the use of post-unforgeable auditing logs, combined with running auditing protocols inside the shared virtual computer, allows a wide variety of performances outside the virtual computer to at least be observed and verified by selected arbitrators, albeit not proactively self-enforced.

The participants in this mutually confidential auditing protocol can verify that the books match the details of transactions stored in a previously committed transaction log, and that the numbers add up correctly. The participants can compute summary statistics on their confidentially shared transaction logs, including cross-checking of the logs against counterparties to a transaction, without revealing those logs. They only learn what can be inferred from the statistics, can't see the details of the transactions. Another intriguing possibility is that the virtual computer can keep state over long periods of time, allowing sophisticated forms of privy and self-enforcing secured credit.

If mutually confidential auditing ever becomes practical, we will be able to gain high confidence in the factuality of counterparties' claims and reports without revealing identifying and other detailed information from the transactions underlying those reports. These would provide the basis for solid reputation systems, and other trusted third party systems, that maintain integrity across time, communications, summarization, and preserve confidentiality for transaction participants. Knowing that mutually confidential auditing can be accomplished in principle will hopefully lead us to practical solutions to these important problems.

References

D. Chaum, C. Crépeau, and I. Damgaard, Multiparty unconditionally secure protocols; In 19th Symp. on Theory of Computing, pages 11-19. ACM, 1988. "The Spymasters Double Agent Problem: Multiparty Computations Secure Unconditionally from Minorities and Cryptographically from Majorities," D. Chaum, Advances in Cryptology CRYPTO'89, G. Brassard (Ed.), Springer-Verlag, pp. 591-601. C. Crépeau, J. van de Graaf, and A. Tapp, Committed Oblivious Transfer and Private Multi-Party Computations; Advances in Cryptology: Proceedings of Crypto '95, Springer-Verlag, pages 110-123, 1995. ↩ Complete Characterization of Adversaries Tolerable in Secure Multi-Party Computation, Martin Hirt and Ueli Maurer. Computer Science Department, ETH Zürich. 1997. in Proceedings of PODC '97 ↩ Matthias Fitzi, Martin Hirt, and Ueli Maurer: Trading correctness for privacy in unconditional multi-party computation. In Advances in Cryptology — CRYPTO '98, volume 1462 of Lecture Notes in Computer Science, 1998. ↩ R. Cramer, I. Damgaard, S. Dziembowski, M. Hirt, T. Rabin, Efficient Multi-Party Computations with Dishonest Majority, Proceedings of Eurocrypt '99, Springer Verlag LNCS, to appear (May '99). ↩

Copyright © 1997-1999 by Nick Szabo

Permission to redistribute without alteration hereby grantedMultinational Small Business

Nick Szabo 1993



Currently the vast majority of businesses on the planet are small, but the vast bulk of multinational business is conducted by large corporations.

In the future the size distribution of multinationals will approach that of local business. The phase change between these states may be quite rapid as telecomm and transport costs pass through a "melting point", creating a wide variety of new multinational small businesses, and industries to support those businesses.

Barriers to multinational small business include

legal: prohibitively complex maze of jurisdictions

language/culture

telecomm costs

transport costs

Both transport and telecomm costs have become unprecedentedly low, and with fiber optics telecomm costs will drop orders of magnitude further.

Small business can cut through the Gordian knot of jurisdictions with the technologies of jurisdictional independence, including strong encryption for communications and databases, digital cash, firewalls, foiling of traffic analysis with proxy servers and digital mixes, and other system security measures. For use of these capabilities to become routine they must be made seamlessly available in the telecommunications equipment and software used by small business. In their commercial dealings, businesses will increasingly deal with industry specific dispute arbitrators rather than traditional legal jurisdictions, and auditing information from transactions will be shared only between the parties necessary to resolve the dispute. Businesses will learn to share the information needed to attract investment and sales, only to those investors and customers, without jeopardizing their legal status in any major market in the maze of obscure jurisdictions they operate in. The companies that first bring these capabilities to international small business at affordable prices stand to reap large fortunes. The new paradigm of smart contracts may provide the cornerstone for building these tools.

Once jurisdictional indepdence is won, small business has nearly endless opportunities to arbitrage between the relative strengths and weaknesses of various localities in various aspects of their business, much like multinationals currently take advantage of relaxed regulatory burdens and low labor costs in Third World countries now. Government intervention probably costs the global economy over $3 trillion U.S. dollars annually; thus vast markets wait to be cracked open by short-circuiting the intervention of governments in both macro and micro markets.

Language and culture may remain the largest barriers. Two methods of attack:

The rise of virtual nations. Multinational small businesses might speak entirely English, Japanese, Mandarin, etc. Their employees might live primarily within a single cultural milieu, dispersed thru a large number of small ethnic communities around the world, keeping close culture-specific, multimedia communications links between the communities. The worldwide Anglo, Japanese, and Mandarin business networks will be taken up by other cultures, and physically dispersed in most cases.

Language-translation software. Crude, specialized versions might soon be reliable, convenient, and inexpensive enough for many kinds of small business uses, such as translating technical manuals.

English is becoming increasingly the de facto language for business and technology.

One interesting question is what small changes might bring about the phase change faster. Something as simple as a user-friendly voice teleconferencing system, might be enough to tip the penguins into the water. Or it might be widespread Internet access with encrypted, route-mixed TCP/IP connections and virtual whiteboards.

Another interesting question in any major new trend is what will be the bottleneck pieces. With the clonable PC, Intel's CPUs and Microsoft's DOS turned out to be the only proprietary elements, with assembly, disk drives, terminals, and the like highly competitive. Wealth will flow to the businesses that provide the bottleneck tools for the coming explosion in multinational small business.

The flip side of multinational small business is setting up market processes internal to the large multinational corporation.

Copyright © 1997, 1999 by Nick Szabo

Permission to redistribute without alteration hereby grantedShelling Out: The Origins of Money

Nick Szabo Originally published in 2002



Abstract

The precursors of money, along with language, enabled early modern humans to solve problems of cooperation that other animals cannot – including problems of reciprocal altruism, kin altruism, and the mitigation of aggression. These precursors shared with non-fiat currencies very specific characteristics – they were not merely symbolic or decorative objects.

Table of Contents

Money

From the very start, England's 17th century colonies in America had a problem – a shortage of coins[D94][T01] The British idea was to grow large amounts of tobacco, cut timber for the ships of their global navy and merchant marine, and so forth, sending in return the supplies they felt were needed to keep the Americans working. In effect, early colonists were supposed to both work for the company and shop at the company store. The investors and the Crown much preferred this to paying in coin what the farmers might ask, letting the farmers themselves buy the supplies – and, heaven forbid, keep some of the profit as well.

The colonists' solution was at hand, but it took a few years for them to recognize it. The natives had money, but it was very different from the money Europeans were used to. American Indians had been using money for millenia, and quite useful money it turned out to be for the newly arrived Europeans – despite the prejudice among some that only metal with the faces of their political leaders stamped on it constituted real money. Worse, the New England natives used neither silver nor gold. Instead, they used the most appropriate money to be found in their environment – durable skeleton parts of their prey. Specifically, they used wampum, shells of the clam venus mercenaria and its relatives, strung onto pendants.

Necklace of wampum. During trade the beads were counted, removed, and re-assembled on new necklaces. Native American shell beads were also sometimes woven into belts or other mnemonic and ceremonial devices that demonstrated the wealth and commitment of a tribe to a treaty.

Clams were found only at the ocean, but wampum traded far inland. Sea-shell money of a variety of types could be found in tribes across the American continent. The Iriquois managed to collect the largest wampum treasure of any tribe, without venturing anywhere near the clam's habitat.[D94] Only a handful of tribes, such as the Narragansetts, specialized in manufacturing wampum, while hundreds of other tribes, many of them hunter-gatherers, used it. Wampum pendants came in a variety of lengths, with the number of beads proportional to the length. Pendants could be cut or joined to form a pendant of length equal to the price paid.

Once they got over their hangup about what constitutes real money, the colonists went wild trading for and with wampum. Clams entered the American vernacular as another way to say "money". The Dutch governor of New Amsterdram (now New York) took out a large loan from an English-American bank – in wampum. After a while the British authorities were forced to go along. So between 1637 and 1661, wampum became legal tender in New England. Colonists now had a liquid medium of exchange, and trade in the colonies flourished.[D94]

The beginning of the end of wampum came when the British started shipping more coin to the Americas, and Europeans started applying their mass-manufacturing techniques. By 1661, British authorities had thrown in the towel, and decided it would pay in coin of the realm – which being real gold and silver, and its minting audited and branded by the Crown, had even better monetary qualities than shells. In that year wampum ceased to be legal tender in New England. In 1710 briefly became legal tender in North Carolina. It continued to be used as a medium of exchange, in some cases into the 20th century – but its value had been inflated one hundred fold by Western harvesting and manufacturing techniques, and it gradually went the route that gold and silver jewelry had gone in the West after the invention of coinage – from well crafted money to decoration. The American language of shell money became a quaint holdover – "a hundred clams" became "a hundred dollars". "Shelling out" came to mean paying in coins or bills, and eventually by check or credit card.[D94] Little did we know that we had touched the very origins of our species.

Collectibles

Native American money took many forms besides shells. Furs, teeth, and a variety of other objects with properties we will discuss below were also commonly used as media of exchange. 12,000 years ago, in what is now Washington state, the Clovis people developed some marvelously long chert blades. The only problem – they break far too easily. They were useless for cutting. The flints were being made "for the sheer enjoyment" – or for some other purpose that had nothing to do with cutting.[G01] As we shall see, this seeming frivolity was, quite likely, actually very important to their survival.

Native Americans had not, however, been the first to make artful but useless blades, nor had they invented shell money. Nor, for that matter, had Europeans, even though they, too, in ages past had widely used shells and teeth for money – not to mention cattle, gold, silver, weapons, and much else. Asians had used all that and faux axes issued by governments to boot, but they as well imported this institution. For archaeologists have found pendants of shells dating to the early Paleolithic that could easily have substituted for Native American money.

Beads made from shells of the pea-sized snail Nassarius kraussianus, that lived in a nearby estuary. Blombos Cave, South Africa, 75,000 B.P.[B04]

In the late 1990s archaeologist Stanley Ambrose discovered, in the a rock-shelter in the Rift Valley of Kenya, a cache of beads made of ostrich eggshell, blanks, and shell fragments. They are dated using the argon-argon (40Ar/39Ar) ratio to at least 40,000 years old[A98]. Pierced animal teeth have been found in Spain also dating to this time.[W95] Perforated shells have also been recovered from early Paleolithic sites in Lebanon[G95]. Recently regular shells, prepared as strung beads and dating further back still, to 75,000 BP, have been found in Blombos Cave in South Africa.[B04]

Ostrich-eggshell beads, Kenya Rift Valley, 40,000 B.P. (Courtesy Stanley Ambrose)

Our modern subspecies had migrated to Europe and necklaces of shell and tooth appear there, from 40,000 B.P. onward. Shell and tooth pendants appear in Australia from 30,000 B.P. onward[M93]. In all cases, the work is highly skilled, indicating a practice that probably dates much further back in time. The origin of collecting and decorating is quite likely Africa, the original homeland of the anatomically modern subspecies. Collecting and making necklaces must have had an important selection benefit, since it was costly – manufacture of these shells took a great deal of both skill and time during an era when humans lived constantly on the brink of starvation[C94].

Practically all human cultures, even those that do not engage in substantial trade or that use more modern forms of money, make and enjoy jewelry, and value certain objects more for their artistic or heirloom qualities than for their utility. We humans collect necklaces of shells and other kinds of jewelry – for the sheer enjoyment of it. For the evolutionary psychologists an explanation that humans do something for "the sheer enjoyment of it" is not an explanation at all – but the posing of a problem. Why do so many people find the collection and wearing of jewelry enjoyable? For the evolutionary psychologist, this question becomes – what caused this pleasure to evolve?

Detail of necklace from a burial at Sungir, Russia, 28,000 BP. Interlocking and interchangeable beads. Each mammoth ivory bead may have required one to two hours of labor to manufacture.[W97]

Evolution, Cooperation, and Collectibles

Evolutionary psychology starts with a key mathematical discovery of John Maynard Smith[D89]. Using models of populations of co-evolving genes, from the well-developed area of population genetics, Smith posited genes that can code for strategies, good or bad, used in simple strategic problems (the "games" of game theory). Smith proved that these genes, competing to be propagated into future generations, will evolve strategies that are Nash equilbria to the strategic problems presented by the competition. These games include the prisoner's dilemma, a prototypical problem of cooperation, and hawk/dove, a prototypical problem of aggression and its mitigation.

Critical to Smith's theory is that these strategic games, while played out between phenotypes proximately, are in fact games between genes the ultimate level – the level of competition to be propagated. The genes – not necessarily the individuals – influence behavior as if they were boundedly rational (coding for strategies as optimal as possible, within the limits of what phenotypes can express given the biological raw materials and previous evolutionary history) and "selfish" (to use Richard Dawkins' metaphor). Genetic influences on behavior are adaptations to the social problems presented by genes competing through their phenotypes. Smith called these evolved Nash equilibria evolutionary stable strategies.

The "epicycles" built on top of the earlier individual selection theory, such as sexual selection and kin selection, disappear into this more general model which, in a Copernican manner, puts the genes rather than individuals at the center of the theory. Thus Dawkins' metaphorical and often misunderstood phrase, "selfish gene", to describe Smith's theory.

Few other species cooperate on the order of even Paleolithic humans. In some cases – brood care, the colonies of ants, termites, and bees, and so forth, animals cooperate because they are kin – because they can help copies of their "selfish genes" found in their kin. In some highly constrained cases, there is also ongoing cooperation between non-kin, which evolutionary psychologists call reciprocal altruism. As Dawkins describes it[D89], unless an exchange of favors is simultaneous (and sometimes even then), one party or the other can cheat. And they usually do. This is the typical result of a game theorists call the Prisoner's Dilemna – if both parties cooperated, both would be better off, but if one cheats, he gains at the expense of the sucker. In a population of cheaters and suckers, the cheaters always win. However, sometimes animals come to cooperate through repeated interactions and a strategy called Tit-for-Tat: start cooperating and keep cooperating until the other party cheats – then defect yourself. This threat of retalation motivates continued cooperation.

The situations where such cooperation in fact occurs in the animal world are highly constrained. The main constraint is that such cooperation is restricted to relationships where at least one of the participants is more or less forced to be in the proximity of the other. The most common case is when parasites, and hosts whose bodies they share, evolve into symbiotes. If the interests of the parasite and the host coincide, so that both working together would be more fit than either on their own, (i.e. the parasite is also providing some benefit to the host), then, if they can play a successful game of Tit-for-Tat, they will evolve into symbiosis – a state where their interests, and especially the exit mechanism of genes from one generation to the next, coincides. They become as a single organism. However, there is much more than cooperation going on here – there is also exploitation. They occur simultaneously. The situation is ananalogous to an institution humans would develop – tribute – which we will analyze below.

Some very special instances occur that do not involve parasite and host sharing the same body and evolving into symbiotes. Rather, they involve non-kin animals and highly constrained territory. A prominent example Dawkins describes are cleaner fish. These fish swim in and out of the mouths of their hosts, eating the bacteria there, benefiting the host fish. The host fish could cheat – it could wait for the cleaner to finish its job, then eat it. But they don't. Since they are both mobile, they are both potentially free to leave the relationship. However, the cleaner fish have evolved a very strong sense of individual territoriality, and have stripes and dances that are difficult to spoof – much like a difficult to forge brand logo. So the host fish know where to go to get cleaned – and they know that if they cheat, they will have to start over again with a new distrustful cleaner fish. The entrance costs, and thus the exit costs, of the relationship are high, so that it works out without cheating. Besides, the cleaner fish are tiny, so the benefit of eating them is not large compared to the benefit of a small number of, or even one, cleaning.

One of the most pertinent examples.is the vampire bat. As their name suggests, they suck the blood of prey mammals. The interesting thing is that, on a good night, they bring back a surplus; on a bad night, nothing. Their dark business is highly unpredictable. As a result, the lucky (or skilled) bats often share blood with the less lucky (or skilled) bats in their cave. They vomit up the blood and the grateful recipient eats it.

The vast majority of these recipients are kin. Out of 110 such regurgitations witnessed by the strong-stomached biologist G.S. Wilkinson, 77 were cases of mothers feeding their children, and most of the other cases also involved genetic kin. There were, however, a small number that could not be explained by kin altruism. To demonstrate these were cases of reciprocal altruism, Wilkinson combined the populations of bats from two different groups. Bats, with very rare exception, only fed old friends from their original group.[D89] Such cooperation requires building a long-term relationship, where partners interact often, recognize each other, and keep track of each other's behavior. The bat cave helps constrain the bats into long-term relationships where such bonds can form.

We will see that some humans, too, chose highly risky and discontinuous prey items, and shared the resulting surpluses with non-kin. Indeed, they accomplished this to a far greater extent than the vampire bat. How they did so is the main subject of our essay. Dawkins suggests, "money is a formal token of delayed reciprocal altruism", but then pursues this fascinating idea no further. We will.

Among small human groups, public reputation can supercede retaliation by a single individual to motivate cooperation in delayed reciprocation. However, reputational beliefs can suffer from two major kinds of errors – errors of about which person did what, and errors in appraising the value or damages caused by that act.

The need to remember faces and favors is a major cognitive hurdle, but one that most humans find relatively easy to overcome. Recognizing faces is easy, but remembering that a favor took place when such memory needs to be recalled can be harder. Remembering the specifics about a favor that gave it a certain value to the favored is harder still. Avoiding disputes and misunderstandings can be improbable or prohibitively difficult.

The appraisal or value measurement problem is very broad. For humans it comes into play in any system of exchange – reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors – say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be "fair", or in other words not a defection? Is twenty minutes of backscratching worth one piece of fruit or two? And how big a piece?

Even the simple case of trading blood for blood is more complicated then it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of "you scratch my back and I'll scratch yours".

For the vast majority of potential exchanges, the measurement problem is intractible for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.

Just the stone tool-kit of even early Paleolithic man that has survived for us to find was in some ways too complicated for brains of our size. Keeping track of favors involving them – who manufactured what quality of tool for whom, and therefore who owed whom what, and so on – would have been too difficult outside the boundaries of the clan. Add onto that, quite likely, a large variety of organic objects, ephemeral services (such as grooming), and so on that have not survived. After even a small fraction of these goods had been transferred and services performed our brains, as inflated as they are, could not possibly keep track of who owed what to whom. Today we often write these things down – but Paleolithic man had no writing. If cooperation occured between clans and even tribes, as the archaeological record indicates in fact occured, the problem gets far worse still, since hunter-gatherer tribes were usually highly antagonistic and mutually distrustful.

If clams can be money, furs can be money, gold can be money, and so on – if money is not just coins or notes issued by a government under legal tender laws, but rather can be wide variety of objects – then just what is money anyway? And why did humans, often living on the brink of starvation, spend so much time making and enjoying those necklaces when they could have been dong more hunting and gathering? Nineteenth century economist Carl Menger[M1892] first described how money evolves naturally and inevitably from a sufficient volume of commodity barter. In modern economic terms the story is similar to Menger's.

Barter requires a coincidence of interests. Alice grows some pecans and wants some apples; Bob grows apples and want some pecans. They just happen to have their orchards near each other, and Alice just happens to trust Bob enough to wait between pecan harvest time and apple harvest time. Assuming all these conditions are met, barter works pretty well. But if Alice was growing oranges, even if Bob wanted oranges as well as pecans, they'd be out of luck – oranges and apples don 't both grow well in the same climate. If Alice and Bob didn't trust each other, and couldn't find a third party to be a middleman[L94] or enforce a contract, they'd also be out of luck.

Further complications could arise. Alice and Bob can't fully articulate a promise to sell pecans or apples in the future, because, among other possibilities, Alice could keep the best pecans to herself (and Bob the best apples), giving the other the dregs. Comparing the qualities as well as the quantities of two different kinds of goods is all the more difficult when the state of one of the goods is only a memory. Furthermore, neither can anticipate events such as a bad harvest. These complications greatly add to the problem of Alice and Bob deciding whether separated reciprocal altruism has truly been reciprocal. These kinds of complications increase the greater the time interval and uncertainty between the original transaction and the reciprocation.

A related problem is that, as engineers would say, barter "doesn't scale". Barter works well at small volumes but becomes increasingly costly at large volumes, until it becomes too costly to be worth th effort. If there are n goods and services to be traded, a barter market requires n^2 prices. Five products would require twenty-five prices, which is not too bad, but 500 products would require 250,000 prices, which is far beyond what is practical for one person to keep track of. With money, there are only n prices – 500 products, 500 prices. Money for this purpose can work either as a medium of exchange or simply as a standard of value – as long as the number of money prices themselves do not grow too large to memorize or change too often. (The latter problem, along with an implicit insurance "contract", along with the lack of a competitive market may explain why prices were often set by long-evolved custom rather than proximate negotiation).

Barter requires, in other words, coincidences of supply or skills, preferences, time, and low transaction costs. Its cost increases far faster than the growth in the number of goods traded. Barter certainly works much better than no trade at all, and has been widely practiced. But it is quite limited compared to trade with money.

Primitive money existed long before large scale trade networks. Money had an even earlier and more important use. Money greatly improved the workings of even small barter networks by greatly reducing the need for credit. Simultaneous coincidence of preference was far rarer than coincidences across long spans of time. With money Alice could gather for Bob during the ripening of the blueberries this month, and Bob hunt for Alice during the migration of the mammoth herds six months later, without either having to keep track of who owed who, or trust the other's memory or honesty. A mother's much greater investment in child rearing could be secured by gifts of unforgeable valuables. Money converts the division of labor problem from a prisoner's dilemma into a simple swap.

The proto-money used by many hunter-gatherer tribes looks very different from modern money, now serves a different role in our modern culture, and had a function probably limited to small trade networks and other local institutions discussed below. I will thus call such money collectibles instead of money proper. The terms used in the anthropological literature for such objects are usually either "money", defined more broadly than just government printed notes and coins but more narrowly than we will use "collectible" in this essay, or the vague "valuable", which sometimes refers to items that are not collectibles in the sense of this essay. Reasons for choosing the term collectible over other possible names for proto-money will become apparent. Collectibles had very specific attributes. They were not merely symbolic. While the concrete objects and attributes valued as collectible could vary between cultures, they were far from arbitrary. The primary and ultimate evolutionary function of collectibles was as a medium for storing and transfering wealth. Some kinds of collectibles, such as wampum, could be quite functional as money as we moderns know it, where the economic and social conditions encouraged trade. I will occasionally use the terms "proto-money" and "primitive money" interchangeably with "collectible" when discussing pre-coinage media of wealth transfer.

Gains From Wealth Transfers

People, clans or tribes trade voluntarily because both sides believe they gain something. Their beliefs about the value may change after the trade, for example as they gain experience with the good or service. Their beliefs at the time of the trade, although to some degree inaccurate as to the value, are still usually correct as to the existence of gain. Especially in early intertribal trade, restricted to high value items, there was strong incentive for each party to get their beliefs right. Thus trade almost always did benefit both parties. Trade created value as much as the physical act of making something.

Because individuals, clans, and tribes all vary in their preferences, vary in their ability to satisfy these preferences, and vary in the beliefs they have about these skills and preferences and the objects that are consequent of them, there are always gains to be made from trade. Whether the costs of making these trades – transaction costs – are low enough to make the trades worthwhile is another matter. In our civilization, far more trades are possible than were through most of human history. Nevertheless, as we shall see some kinds of trades were worth more than the transaction costs, for some cultures, probably back to the beginning of homo sapiens sapiens.

Voluntary spot trades are not the only kinds of transactions that benefit from lower transaction costs. This is the key to understanding the origin and evolution of money. Family heirlooms could be used as collateral to remove the credit risk from delayed exchanges. The ability of a victorious tribe to extract tribute from the vanquished was of great benefit to the victor . The victor's ability to collect tribute benefited from some of the same kinds of transaction cost techniques as did trade. So did the plaintiff in assessment of damages for offenses against custom or law, and kin groups arranging a marriage. Kin also benefited from timely and peaceful gifts of wealth by inheritance. The major human life events that modern cultures segregate from the world of trade benefited no less than trade, and sometimes more so, from techniques that lowered transaction costs. None of these techniques was more effective, important, or early than primitive money – collectibles.

When H. sapiens sapiens displaced H. sapiens neanderthalis, population explosions followed. Evidence from the takeover in Europe, c. 40,000 to 35,000 B.P, indicates that H. sapiens sapiens increased the carrying capacity of its environment by a factor of ten over H. sapiens neanderthalis – i.e., the population density increased tenfold[C94]. Not only that, the newcomers had spare time to create the world's first art – such as the wonderful cave paintings, a wide variety of well crafted figurines – and of course the wonderful pendants and necklaces of seashells, teeth, and eggshell.

These objects were not useless decorations. Newly effective wealth transfers, made possible by collectibles as well as other probable advance of the era, language, created new cultural institutions that quite likely played the leading role in the increase of carrying capacity.

The newcomers, H. sapiens sapiens, had the same size brain, weaker bones, and smaller muscles than the Neanderthals. Their hunting tools were more sophisticated, but in 35,000 B.P. they were basically the same tools – they were probably not even twice as effective, much less ten times more effective. The biggest difference may have been wealth transfers made more effective or even possible by collectibles. H. sapiens sapiens took pleasure from collecting shells, making jewelry out of them, showing them off, and trading them. H. sapiens neanderthalis did not. The same dynamic would have been at work, tens of thousands of years earlier, on the Serengeti, when H. sapiens sapiens first appeared in that dynamic maelstrom of human evolution, Africa.

We shall describe how collectibles lowered transaction costs in each kind of wealth transfer – in the voluntary free gift of inheritance, in voluntary mutual trade or marriage, and in the involuntary transfers of legal judgments and tribute.

All these kinds of value transfer occured in many cultures of human prehistory, probably from the beginning of Homo sapiens sapiens. The gains to be made, by one or both parties, from these major life event transfers of wealth, were so great that they occurred despite high transaction costs. Compared to modern money, primitive money had a very low velocity – it might be transferred only a handful of times in an average individual's lifetime. Nevertheless, a durable collectible, what today we would call an heirloom, could persist for many generations and added substantial value at each transfer – often making the transfer even possible at all. Tribes therefore often spent large amounts of time on the seemingly frivolous tasks of manufacturing and exploring for the raw materials of jewelry and other collectibles.

The Kula Ring

The Kula trading network of pre-colonial Melanesia. The kula valuables doubled as "high power" money and mnemonic for stories and gossip. Many of the goods traded, mostly agricultural products, were available in different seasons, and so could not be traded in kind. Kula collectibles solved this double-coincidence problem as an unforgeabaly costly, wearable (for security), and circulated (literally!) money. Necklaces circulated clockwise, and armshells counter-clockwise, in a very regular pattern. By solving the double-coincidence problem an armshell or necklace would prove more valuable than its cost after only a few trades, but could circulate for decades. Gossip and stories that about prior owners of the collectibles further provided information about upstream credit and liquidity. In other Neolithic cultures collectibles, usually shells, circulated in a less regular pattern but had similar purposes and attributes.[L94]

Kula armshell (mwali).

Kula necklaces (bagi).

For any institution in which wealth transfer is an important component, we will ask the following questions:

What coincidence in time between the event, the supply for the transfered good, and demand for the transfered good was necessary? How unlikely or how high a barrier to the wealth transfer did the improbability of coincidence represent? Would the wealth transfers formed a closed loop of collectibles just based on that institution, or were other wealth transfer institutions necessary to complete circulation cycles? Taking the actual flow graph of monetary circulation seriously is critical to understanding the emergence of money. General circulation among a wide variety of trades did not and would not exist for most of human prehistory. Without completed and repeated loops collectibles would not circulate and would become worthless. A collectible, to be worth making, had to add value in enough transactions to amortize its cost.

We shall first examine the kind of transfer most familiar and economically important to us today – trade.

Starvation Insurance

Bruce Winterhalder[W98] surveys models of how and why food is sometimes transfered between animals: tolerated theft, producing/scrounging/opportunism, risk-sensitive subsistence, by-product mutualism, delayed reciprocity, trade/exchange not in kind, and other selection models (including kin altruism). Here we focus on risk-sensitive subsistence, delayed reciprocity, and trade (exchange not in kind). We argue that substituting trade of food for collectibles for delayed reciprocity can increase food sharing. It does so by mitigating the risks of a variable food supply while avoiding the largely insurmountable problems of delayed reciprocity between bands. We will deal with kin altruism and theft (tolerated or not) in broader contexts below.

Food is worth far more to starving people than to well fed ones. If the starving man can save his life by trading his most precious valuables, it may be worth to him months or even years of the labor it might take to replace that value. He will usually consider his life worth more than the sentimental value of the family heirlooms. Like fat itself, collectibles can provide insurance against food shortages. Starvation from local shortages could be staved off with at least two different kinds of trades – for the food itself, or for foraging or hunting rights.

Nevertheless, the transaction costs were usually too high – bands were far more likely to fight than ever trust each other. The hungry band that couldn't find its own food usually starved. However, if the transaction costs could be lowered, by lowering the need for trust between bands, food that was worth a day's labor to one band might be worth several months' labor to the starving band.

Local but extremely valuable trade was, this essay argues, made possible among many cultures by the advent of collectibles, by the time of the Upper Paleolithic. Collectibles substituted for otherwise necessary but non-existent trusting long term relationships. If there had existed a high degree of sustained interaction and trust between tribes, or individuals of different tribes, so that they gave each other unsecured credit, this would have stimulated time-lagged barter trade. However, such a high degree of trust then is highly implausible – for the reasons stated above regarding reciprocal altruism, confirmed by the empirical evidence that most hunter-gatherer tribal relations have been observed to be quite antagonistic. Hunter-gatherer bands usually broke up into small bands for most of the year and gathered into "aggregates", something like medieval European fairs, for a few weeks out of the year. Despite the lack of trust between bands, an important trade in staples, of the kind illustrated in the accompanying figure, almost surely occurred in European and probably elsewhere, such as with the big game hunters of America and Africa.

The scenario illustrated by the accompanying figure is hypothetical, but it would be very surprising if it did not occur. While many Europeans even in the Paleolithic enjoyed wearing shell necklaces, many lived farther inland and made necklaces instead out of the teeth of their prey. Flints, axes, furs, and other collectibles were also quite likely used as media of exchange.

Reindeer, bison, and other human prey migrated at different times of the year. Different tribes specialized in different prey, to the point where over 90%, and sometimes as much as 99%, of the remains from many sites during the Paleolithic in Europe come from a single species[C94]. This indicates at least seasonal specialization and perhaps full-time specialization by a tribe in a single species. To the extent they specialized, the members of a single tribe would have become experts at the behavior, migration habits, and other patterns surrounding their specific prey species, as well as the specialized tools and techniques for hunting them. Some tribes observed in recent times are known to have specialized. Some North American Indian tribes specialized respectively in hunting bison, antelope, and fishing for salmon. In northern Russia and parts of Finland, many tribes, including the Lapp even today, specialized in herding a single species of reindeer.

Such specialization was probably far higher when more large prey (horse, auroch, giant elk, bison, giant sloth, mastadon, mammoth, zebra, elephant, hippopotamus, giraffe, musk oxen, etc.) roamed North America, Europe, and Africa in large herds during the Paleolithic. Large wild animals unafraid of humans no longer exist. During the Paleolithic they were either driven extinct or adapted to be afraid of humans and our projectiles. However, for most of the time span of H. sapiens sapiens these herds were abundant and easy pickings to specialist hunters. According to our theory of trade-based predation, specialization was quite likely far higher when large prey roamed North America, Europe, and Africa in large herds during the Paleolithic. Trade-based division of labor in hunting between tribes is consistent with (although not securely confirmed by) the archaeological evidence from the Paleolithic in Europe.

These migrating bands, following their herds, frequently interacted, creating many opportunities for trade. American Indians preserved food by drying, making pemmican, and so on in ways that lasted for a few months but typically not a full year. Such food was commonly traded, along with skins, weapons, and collectibles. Often these trades occurred during annual trading expeditions[T01].

Large herd animals migrated through a territory only two times a year, with a window most often of one or two months. Without any other source of protein besides their own prey species, these specialist tribes would have starved. The very high degree of specialization demonstrated in the archaeological record could only have occurred if there was trade.

Thus, even if the time-offset barter of meat were the only kind of trade, this is quite sufficient to make the use of collectibles quite worthwhile. The necklaces, flints, and any other objects used as money circulate in a closed loop, back and forth, in roughly equal amounts so long as the value of meat traded remains roughly equal. Note that it is not enough, for the theory of collectibles put forth in this paper to be correct, that single beneficial trades were possible. We must identify closed loops of mutually beneficial trades. With closed loops the collectibles continue to circulate, amortizing their costs.

As mentioned, we know from archaeological remains that many tribes specialized in a single large prey species. This specialization was at least seasonal; if there was extensive trade it could have been full-time. Becoming experts in the habits and migration patterns, and best methods of taking down, a tribe reaped enormous productive benefits. These benefits, however, would normally be unattainable, for specializing in a single species meant going without food most of the year. Division of labor between tribes paid off – and trade made it possible. The supply of food would nearly double from trade just between two complementary tribes. There were, however, rather than two prey species, often up to a dozen that migrated through most hunting territories in areas like the Serengeti and the European steppe. The amount of meat available to a species-specializing tribe would thus likely more than double with such trade among a handful of neighboring tribes. On top of this, the extra meat would be there when needed most – when the meat from a tribe's own species prey would already have been eaten, and without food the hunters would starve.

Thus there were at least four gains, or sources of surplus, from a trade cycle as simple as two prey species and two non-simultaneous but offsetting trades. These gains are distinct but not necessarily independent:

An available source of meat at a time of the year when one would otherwise starve. An increase in the total supply of meat – they traded the surplus beyond what they could eat immediately or store; what they didn't trade would have gone to waste. An increase in the variety of nutrition from meat, by eating different kinds of meat. Increased productivity from specialization in a single prey species.

Making or saving collectibles to trade for food itself was not the only way to insure against bad times. Perhaps even more common, especially where large prey items were not available, was territoriality combined with trade in foraging rights. This can be observed even in some of the remnants of hunter-gatherer culture that exist today.

The !Kung San of southern Africa, like all other modern remnants of hunter-gatherer cultures, live on marginal lands. They have no opportunity to be specialists but must take the meager remnants available. They may thus be rather uncharacteristic of many ancient hunter-gatherer cultures, and uncharacteristic of the original Homo sapien sapiens, which first seized the lushest lands and best game routes from Homo sapiens neanderthalis and only much later drove the Neanderthals from marginal lands. Yet despite their severe ecological handicap, the !Kung use collectibles as items of trade.

Like most hunter-gatherers, the !Kung spend most of the year in small, dispersed bands and a few weeks of the year in an aggregate with several other bands. Aggregation is like a fair with added features – trade is accomplished, alliances are cemented, partnerships strengthened, and marriages transacted. Preparation for aggregation is filled with the manufacture of tradeable items, partly utilitarian but mostly of a collectible nature. The exchange system, called by the !Kung hxaro, involves a substantial trade in beaded jewelry, including ostrich-shell pendants quite similar to those found in Africa 40,000 years ago.

Pattern of hxaro exchanges and kinship relations among neighboring tribes of !Khung San hunter-gatherers.

Necklaces used in the hxaro exchange.

One of the main things the !Kung buy and sell with their collectibles are abstract rights to enter another band's territory and hunt or gather food there. Trade in these rights is especially brisk during local shortages which can be alleviated by foraging in a neighbor's territory[W77][W82] !Kung bands mark their territories with arrows; trespassing without having purchased the right to enter and forage is tantamount to a declaration of war. Like the inter-band food trade discussed above, the use of collectibles to purchase foraging rights constitutes an "insurance policy against starvation", to use the phrase of Stanley Ambrose[A98].

Although anatomically modern humans surely had conscious thought, language, and some ability to plan, it would have required little conscious thought or language, and very little planning, to generate trades. It was not necessary that tribe members reasoned out the benefits of anything but a single trade. To create this institution it would have sufficed that people follow their instincts to make obtain collectibles with the characteristics outlined below. (as indicated by proxy observations that make approximate estimations for these characteristics). This is to various extents true of the other institutions we will study – they evolved, rather than being consciously designed. No one participating in the institution's rituals would have explained their function in terms of ultimate evolutionary function; rather they explained in terms of a wide variety of mythologies that served more as proximate motivators of behavior than as theories of ultimate purpose or origin.

Direct evidence for trade in food has long since decayed. We may, in the future, find more direct evidence than is now available for this article, via comparison of hunting remains in one tribe with the consumption patterns in another tribe – the hardest part of this task likely being to identify the boundaries of different tribes or kin groups. According to our theory, such transfer of meat from one tribe to another was common in many parts of the world during the Paleolithic where large-scale and specialized big game hunting occurred.

For now, we do have extensive indirect evidence of trade, via the movement of the collectibles themselves. Fortunately there is a good correlation between the durability desired for collectibles and the conditions under which an artifact has survived to be found by today's archaeologists. In the early Paleolithic, when all human movement was on foot, we have instances of perforated sea shells found up to 500 kilometers away from the nearest source[C94]. There was a similar long-distance movement of flint.

Unfortunately, trade was severely restricted by high transaction costs in most times and places. The primary barrier was the antagonism between tribes. The predominate relationship between tribes was one of distrust on good days and outright violence on bad days. Only ties of marriage or kinship could bring tribes into a relationship with trust, albeit only occasionally and of limited scope. The poor ability to protect property, even collectibles worn on the person or buried in well-hidden caches, meant that collectibles had to amortize their costs in a few transactions.

Trade was thus not the only kind of wealth transfer, and probably not the most important kind during the long human prehistory where high transaction costs prevented the development of the kinds of markets, firms, and other economic institutions we now take for granted[L94]. Underneath our great economic institutions are far more ancient institutions that also involved wealth transfer – in prehistoric times, the main kinds of wealth transfer. All of these institutions distinguished Homo sapiens sapiens from previous animals. We now turn to one of the most basic kinds of wealth transfer that we humans take for granted but other animals do not have – passing wealth onto the next generation.

Kin Altruism Beyond the Grave

Coincidence in time and locale of supply and demand for trade was rare – so much so, that most kinds of trades and trade-based economic institutions we now take for granted could not exist. Even more unlikely was the triple coincidence of supply with demand with a major event for a kin group – the formation of a new family, death, crime, or victory or defeat in war. As we shall see, clans, and individuals greatly benefited from a timely transfer of wealth during these events. Such wealth transfer in turn was much less wasteful when it was the transfer of a store of wealth more durable and general than consumables or tools designed for other purposes. The demand for a durable and general store of wealth for use in these institutions was thus even more urgent than for trade itself. Furthermore, the institutions of marriage, inheritance, dispute resolution, and tribute may predate intertribal trade, and involved for most tribes a greater transfer of wealth than trade. These institutions thus more than trade served as the motivator and incubator of the earliest primitive money.

In most hunter-gatherer tribes this wealth came in a form that strikes us preposterously wealthy moderns as trivial – a collection of wooden utensils, flint and bone tools and weapons, shells on strings, perhaps a hut and in colder climates some mangy furs. Sometimes it could all be carried on the person. Nevertheless, these motley assortments were wealth for a hunter-gatherer no less than real estate, stocks, and bonds are wealth for us. To the hunter-gatherer tools and sometimes warm clothes were necessary for survival. Many of the items were highly valued collectibles that insured against starvation, purchased mates, and could substitute for massacre or starvation in event of war and defeat. The ability to transfer the capital of survival to one's descendants was another advantage Homo sapiens sapiens had over previous animals. Furthermore, the skilled tribesman or clan could accumulate a surplus of wealth from the occasional, but cumulative over a lifetime, trade of surplus consumables for durable wealth, especially collectibles. A temporary fitness advantage could be translated into a more durable fitness advantage for one's descendants.

Another form of wealth, hidden from the archaeologist, were titles to offices. Such social positions were more valuable than the tangible forms of wealth in many hunter-gatherer cultures. Examples of such positions included clan leaders, war party leaders, hunting party leaders, membership in a particular long-term trading partnership (with a particular person in a neighboring clan or tribe), midwives, and religious healers. Often collectibles not only embodied wealth, but also served as a mnemonic, representing the title to a clan position of responsibility and privilege. Upon death, to maintain order, the heirs to such positions had to be quickly and clearly determined. Delays could spawn vicious conflicts. Thus, a common event was the mortuary feast, in which the deceased was feted while both his tangible and intangible forms of wealth were distributed to descendants, as determined by custom, clan decision-makers, or the will of the deceased.

Other kinds of free gifts were quite rare in pre-modern cultures, as Marcel Mauss[M50] and other anthropologists have pointed out. Seemingly free gifts in fact implicitly invoked an obligation in the recipient. Before contract law, this implicit obligation of the "gift", along with community dishonor and punishments ensuing if the implicit obligation was not met, was perhaps the most common motivator of reciprocation in delayed exchange, and is still common in the variety of informal favors we do for each other. Inheritance and other forms of kin altruism were the only widely practiced forms of what we moderns would call gift proper, namely a gift that imposed no obligation on the recipient.

Early Western traders and missionaries, who often saw natives as childish primitives, sometimes called their tribute payments "gifts" and trades "gift exchanges", as if they bore more resemblance to the Christmas and birthday present exchanges of Western children than to the contractual and tax obligations of adults. Partly this may have reflected prejudice, and partly the fact that in the West by that time obligations were usually formalized in writing which the natives lacked. Westerners thus usually translated the rich variety of words natives had for their exchange institutions, rights, and obligations as "gift". Seventeenth century French settlers in America were thinly scattered among much larger populations of Indian tribes, and often found themselves paying tribute to these tribes. Calling these payments "gifts" was a way for them to save face with other Europeans who faced no such necessity and found it cowardly.

Mauss and modern anthropologists have unfortunately kept this terminology. The uncivilized human is still like a child, but now innocent like a child, a creature of moral superiority who would not stoop to our kind of base, cold-blooded economic transactions. However in the West, especially in the official terminology used for our laws covering transactions, a "gift" refers to a transfer that imposes no obligation. When coming across anthropological discussions of "gift exchange" these caveats should be kept in mind – modern anthropologists are not at all referring to the free or informal gifts we commonly refer to in our modern use on the term "gift". They are rather referring to any of a wide variety of often quite sophisticated systems of rights and obligations involved in wealth transfers. The only major transactions in prehistoric cultures similar to our modern gift, in that it was neither itself a widely recognized obligation nor imposed any obligation on the recipient, were parents or maternal kin caring for their children and inheritance. (An exception was that inheriting title to a position imposed the responsibilities of the position on the heir as well as its privileges).

Inheritance of some heirlooms might proceed for several generations uninterrupted, but it did not by itself form a closed loop of collectibles transfers. Heirlooms were only valuable if they eventually got used for something else. They often were used in marriage transactions between clans that could form closed loop cycles of collectibles.

The Family Trade

An early and important example of a small closed loop trade network made possible by collectibles involves the much higher investment humans make in raising offspring than our primate relatives, and the related human institution of marriage. Combining arrangements of long-term matches for mating and child-raising, negotiated between clans, with wealth transfer, marriage is a human universal and probably dates back to the first Homo sapiens sapiens.

Parental investment is a long-term and almost one-shot affair – there is no time for repeated interactions. Divorce from a negligent father or unfaithful wife usually represented several years of time wasted, in genetic fitness terms, by the jilted party. Fidelity and commitment to the children were primarily enforced by in-laws – the clan. The marriage was the contract between clans that usually included such promises of fidelity and commitment as well as wealth transfer.

The contributions a man and a woman will bring to a marriage are seldom equal. This was even more true in an era when mate choice was largely determined by clans and the population from which clan leaders could choose was quite small. Most commonly, the woman was considered more valuable and the groom's clan paid a bride price to the brides clan. Quite rare in comparision was dowry, a payment by the bride's clan to the new couple. Mostly this was practiced by upper classes of monogamous but highly unequal socieities in medieval Europe and India, and was ultimately motivated by the far greater reproductive potential of upper class sons than upper class daughters in those societies. Since literature was mostly written about upper classes, dowry often plays a role in European traditional stories. This does not reflect its actual frequency across human cultures – it was quite rare.

Marriages between clans could form a closed cycle of collectibles. Indeed, two clans exchanging partners would be sufficient to maintain a closed loop, as long as brides tended to alternate. If one clan was wealthier in collectibles from some other kind of transfer, it could marry more of its sons to better brides (in monogamous societies) or a greater number of brides (in polygamous societies). In a loop involving only marriages, primitive money would simply serve to replace the need for memory and trust between clans over a long period of delay between unbalanced transfers of reproductive resources.

Like inheritance, lawsuit, and tribute, marriage requires a triple coincidence of the event, in this case the marriage, with supply and demand. Without a transferable and durable store of value, the current ability of a groom's clan to supply the current desires of the bride's clan, to a large enough degree to make up the value mismatch between bride and groom, while also satisfying the political and romantic constraints of the match, were quite unlikely to be well satisfied. One solution is imposing an ongoing service obligation from the groom or his clan to the bride's clan. This occurs in about 15% of known cultures[DW88]. In a much larger number, 67%, the groom or groom's clan pays the brides clan a substantial amount of wealth. Some of this bride price is paid in immediate consumables, in plants to be gathered harvested and animals slaughtered for the marriage feast. In herding or agricultural societies much of the bride price is paid in livestock, a long lasting form of wealth. The balance, and usually the most valuable portion of the bride-price in cultures without livestock, is paid with what are usually the most valuable family heirlooms – the rarest, costliest, and most durable pendants, rings, and so on. The Western practice of the groom giving the bride a ring – and a suitor giving a maiden other kinds of jewelry – was once a substantial transfer of wealth and was common in many other cultures. In about 23% of cultures, mostly modern ones, there is no substantial wealth exchange. In about 6% of cultures there is mutual exchange of substantial wealth between bride and groom clans. In only about 2% of cultures does the bride's clan pay the new couple a dowry.[DW88]

Unfortunately, some wealth transfers were a far cry from the altruism of the inheritance gift or the joy of marriage. Quite the opposite, in the case of tribute.

The Spoils of War

Death rates from violence in chimp troops and hunter-gatherer human cultures alike are far higher than in modern civilizations. This probably dates at least as far back as our common ancestor with the chimpanzees – chimp troops, as well, are constantly fighting.

Warfare involved, among other things, killing, maiming, torture, kidnapping, rape, and the extortion of tribute in exchange for avoiding such fates. When two neighbor tribes were not at war, one was usually paying tribute to the other. Tribute could also serve to bind alliances, achieving economies of scale in warfare. Mostly, it was a form of exploitation more lucrative to the victor than further violence against the defeated.

Victory in war was sometimes followed by an immediate payment from the losers to the victims. Often this just took the form of looting by the enthusiastic victors, while the losers desperately hid their collectibles. More often, tribute was demanded on a regular basis. In this case, the triple coincidence could and sometimes was avoided by a sophisticated schedule of payments in kind that matched the losing tribe's ability to supply a good or service with the victor's demand for it. However, even with this solution primitive money could provide a better way – a common medium of value that greatly simplified the terms of payment – very important in an era when terms of the treaty could not be recorded but had to be memorized. In some cases, as with the wampum as used in the Iriquois Confederacy, the collectibles doubled as a primitive mnemonic device that, while not verbatim, could be used as an aid to recall the terms of the treaty. For the winners, collectibles provided a way to collect tribute at closer to the Laffer optimum. For the losers, collectibles buried in caches provided a way to "under-report", leading the victors to believe the losers were less wealthy and thus demand less than they might. Caches of collectibles also provided insurance against over-zealous tribute collectors. Much of the wealth in primitive societies escaped the notice of the missionaries and anthropologists due to its highly secretive nature. Only archeology can reveal the existence of this hidden wealth.

Hiding and other strategies presented a problem that tribute collectors share with modern tax collectors – how to estimate the amount of wealth they can extract. Value measurement is a thorny problem in many kinds of transactions, but never more so than in the antagonistic collection of tax or tribute. In making these very difficult and nonintuitive trade-offs, and then executing them in a series of queries, audits, and collection actions, tribute collectors efficiently optimized their revenue, even if the results seemed quite wasteful to the tribute payer.

Imagine a tribe collecting tribute from several neighbor tribes it previously defeated in war. It must estimate how much it can extract from each tribe. Bad estimates leave the wealth of some tribes understated, while forcing others to pay tribute based on estimates of wealth they don't actually have. The result: the tribes that are hurt tend to shrink. The tribes that benefit pay less tribute than could be extracted. In both cases, less revenue is generated for the victors than they might be able to get with better rules. This is an application of the Laffer curve to the fortunes of specific tribes. On this curve, applied to income taxes by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.

On a larger scale, the Laffer curve may be the most important economic law of political history. Charles Adams[A90] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives – both their short-term desire for revenue and their long-term success against other governments – to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in detering attack rather than the increased incentives of democracies to optimize to tax collection). When we apply the Laffer curve to examining the relative impact of treaty tributterms on various tribes, we conclude that the desire to optimize revenues causes victors to want to accurately measure the income and wealth of the vanquished. Measuring value is crucial to determining the tributaries' incentives to avoid or evade the tribute by hiding wealth, fight, or flight. For their part, tributaries can and do spoof these measurements in various ways, for example by burying collectibles in caches. Tribute collection involves a measurement game with unaligned incentives.

With collectibles, one can demand tribute at strategically optimal times instead of when items can be supplied by the tributary or is in demand by the victor. The victors can then choose when they will in the future consume the wealth, rather than having to consume it at the time the tribute is extracted. Much later, well into the dawn of history, in 700 BC, though trade was widespread, money still took the form of collectibles – made out of more precious metals, but in their basic characteristics, such as lack of uniform value, similar to most of the proto-money used since the dawn of Homo sapiens sapiens. This was changed by a Greek-speaking culture in Anatolia (modern Turkey), the Lydians. Specifically, the kings of Lydia were the first major issuers of coins in the archaeological and historical record.

From that day to this, government mints with self-granted monopolies, rather than private mints, have been the main issuers of coin. Why wasn't minting dominated by private interests, such as private bankers, which did exist at the time in these semi-market economies? The main explanation for government dominance of coin minting has been that only governments could enforce anti-counterfeiting measures. However, they could have enforced such measures in protection of competing private mints, just as they enforce trademarks today and at that time as well.

It was far easier to estimate the value of a coin than that of a collectible – especially at low transaction values. Far more trades could be made with money instead of barter; indeed many kinds of low-value trades became possible for the first time as the small gains from trade for the first time exceeded transaction costs. Collectibles were low velocity money, involved in a small number of high value transactions. Coins were high velocity money, facilitating a large number of low value trades.

Given what we have seen about the benefits of proto-money to tribute and tax collectors, as well as the critical nature of the value measurement problem in optimally coercing such payments, it is not surprising that tax collectors, specifically the kings of Lydia, were the first major issuers of coinage. The king, deriving his revenue from tax collection, had a strong incentive to measure to value of wealth held and exchanged by his subjects more accurately. That the exchange also benefited from cheaper measurement by traders of the medium of exchange, creating something closer to efficient markets, and allowing individuals to enter into the marketplace on a larger scale for the first time, was for the king a fortuitous side effect. The greater wealth flowing through markets, now available to be taxed, boosted the king's revenues even beyond the normal Laffer curve effect of reducing mis-measurement between given tax sources.

This combination of more efficient tax collection with more efficient markets meant a vast increase in overall tax revenues. These tax collectors almost literally hit a gold mine, and the wealth of Lydian kings Midas, Croesus, and Giges is famous to this day.

A few centuries later, the Greek king Alexander the Great conquered Egypt, Persia and much of India, funding his spectacular conquest by plundering Egyptian and Persian temples, filled with assemblages of low-velocity collectibles, and melting them down into high-velocity coins. More efficient and encompassing market economies as well as more efficient tax collection sprung up in his wake.

Tribute payments did not form by themselves a closed loop of collectibles. These were only valuable if they ultimately could be used by the victors for something else, such as marriage, trade, or collateral. However, victors could coerce the vanquished into manufacturing for obtaining collectibles, even if it did not serve the vanquished's voluntary interests.

Disputes and Remedies

Ancient hunter-gatherers did not have our modern tort or criminal law, but they did have an analogous means of settling disputes, often judged by clan or tribal leaders or vote, that covered what modern law calls crimes and torts. Settling disputes through punishments or payments sanction by the clans of the disputing parties substituted for cycles of revenge or vendetta wars. Most pre-modern cultures, ranging from the Iriquois in America to the pre-Christian Germanic peoples, decided that payment was better than punishment. Prices (e.g. the Germanic "weregeld" and Iriquois blood money) were assigned to all actionable offenses, ranging from petty theft to rape to murder. Where money was available, the payment took the form of money. Livestock was used in herding cultures. Otherwise, payment of collectibles were the most commonly used remedy.

The payment of remedies for damages in a lawsuit or similar complaint led to the same kind of problem of triple coincidence of event, supply, and demand as occurred in inheritance, marriage, and tribute. The judgment of the case had to coincide with the ability of the plaintiff to pay the damages as well as the opportunity and desire of the defendant to benefit from them. If the remedy was a consumable the plaintiff already had plenty of, the remedy still served as a punishment but would not likely satisfy the defendant – and thus would not curb the cycle of violence. Thus, we here again the value added by collectibles – in this case, in making possible the remedy to resolve a dispute or terminate a cycle of revenge.

Dispute remedies would not form a closed loop if the payments served to entirely eliminate vendettas. However, if the payments did not completely damp the vendetta, the payments could form a cycle following the cycle of revenge. For this reason, it is possible that the institution reached an equilibrium when it had reduced but not eliminated cycles of revenge until the advent of more densely connected trading networks.

Attributes of Collectibles

Since humans evolved in small, largely self-sufficient, and mutually antagonistic tribes, the use of collectibles to reduce the need for favor-tracking, and to make possible the other human institutions of wealth transfer we have explored, was far more important than the scale problems of barter for most of the timespan of our species. Indeed, collectibles provided a fundamental improvement to the workings of reciprocal altruism, allowing humans to cooperate in ways unavailable to other species. For them, reciprocal altruism is severely limited by unreliable memory. Some other species have large brains, build their own homes, or make and use tools. No other species has produced such an improvement to the workings of reciprocal altruism. The evidence indicates this new development had matured by 40,000 B.P.

Menger called this first money an "intermediate commodity" – what this paper calls collectibles. An artifact useful for other things, such as cutting, could also be used as a collectible. However, once institutions involving wealth transfer became valuable, collectibles would be manufactured just for their collectible properties. What are these properties? For a particular commodity to be chosen as a valuable collectible, it would have had, relative to products less valuable as collectibles, at least the following desirable qualities:

More secure from accidential loss and theft. For most of history this meant carriable on the person and easy to hide. Harder to forge its value. An important subset of these are products that are unforgeably costly, and therefore considered valuable, for reasons explained below. This value was more accurately approximated by simple observations or measurements. These observations would have had more reliable integrity yet have been less expensive.

Humans the world over are strongly motivated to collect items that better satisfy these properties. Some of this motivation probably includes genetically evolved instincts. Such objects are collected for the sheer pleasure of collecting them (not for any particularly good explicit and proximate reasons), and such pleasure is nearly universal across human cultures. One of the immediate proximate motivations is decoration. According to Dr. Mary C. Stiner, an archaeologist at the University of Arizona, "Ornamentation is universal among all modern human foragers."[W02] For an evolutionary psychologist, such a behavior that has a good ultimate explanation, in terms of natural selection, but has no proximate rationale other than pleasure, is a prime candidate to be a genetically evolved pleasure that motivates the behavior. Such is, if the reasoning in this essay is correct, the human instinct to collect rare items, art, and especially jewelry.

Point (2) requires some further explanation. At first, the production of a commodity simply because it is costly seems quite wasteful. However, the unforgeably costly commodity repeatedly adds value by enabling beneficial wealth transfers. More of the cost is recouped every time a transaction is made possible or made less expensive. The cost, initially a complete waste, is amortized over many transactions. The monetary value of precious metals is based on this principle. It also applies to collectibles, which are more prized the rarer they are and the less forgeable this rarity is. It also applies where provably skilled or unique human labor is added to the product, as with art.

We have never discovered or made a product that does really well on all three scores. Art and collectibles (in the sense that word is used in modern culture, rather in the technical sense it is used in this paper) optimize (2), but not (1) or (3). Common beads satisfy (1) but not (2) or (3). Jewelry, made at first out of the most beautiful and less common shells but eventually in many cultures out of precious metals, comes closer to satisfying all three properties. It is no coincidence that precious metal jewelry usually came in thin forms such as chains and rings, allowing for inexpensive assaying at randomly chosen locations. Coins were a further improvement – substituting small standard weights and trademarks for assays greatly reduced the costs of small transactions using precious metals. Money proper was just a further step in the evolution of collectibles.

The kind of mobile art also made by Paleolithic man, (small figurines and the like) also matches these characteristics well. Indeed, Paleolithic man made very few objects that were not either utilitarian, or shared characteristics (1)-(3).

There are many puzzling instances of useless or at least unused flints with homo sapiens. We have mentioned the unusable flints of the Clovis people. Culiffe[C94] discusses a European Mesolithic era find of hundreds of flints, carefully crafted, but which micrograph analysis reveals were never used for cutting.

Flints were quite likely the first collectibles, preceding special-purpose collectibles like jewelry. Indeed, the first flint collectibles would have been made for their cutting utility. Their added value as a medium of wealth transfer was a fortuitous side effect that enabled the institutions described in this article to blossom. These institutions, in turn, would have motivated the manufacture of special-purpose collectibles, at first flints that need have no actual use as cutting tools, then the wide variety of other kinds of collectibles that were developed by Homo sapiens sapiens.

Shell money from Sumer, c. 3,000 B.C.

During the Neolithic era, in many parts of the Middle East and Europe, some kinds of jewelry became more standardized – to the point where standard sizes and assayability were often valued over beauty. In commercial areas the quantity of this jewelry sometimes greatly exceeded that of traditional jewelry in hoards. This is an intermediate step between jewelry and coins, when some collectibles increasingly took a fungible form. Around 700 B.C., the Lydian kings started issuing coins, as described above. The unforgeable costliness of standard weights of precious metals could now be "assayed" in a marketplace, by wage earners, or by tax collectors via trademark, i.e. trust in the mint's brand, instead of chopping coiled wire at a randomly selected spot.

It is no coincidence that the attributes of collectibles are shared with precious metals, coins, and the reserve commodities that have backed most non-fiat currencies. Money proper implemented these properties a purer form than the collectibles used during almost all of human prehistory.

Silver ring and coil money from Sumer, c. 2,500 B.C. Note the standard size of cross-sections. Many of the pieces had a standard weight, ranging from one-twelfth of a shekel to sixty shekels. To assay a ring or coil, it could be weighed and cut at random locations. (Courtesy Oriental Institute, University of Chicago)

A novelty of the 20th century was the issue of fiat currencies by governments. ("Fiat" means not backed by any reserve commodity, as the gold- and silver-based currencies of previous centuries were). While generally excellent as a media of exchange, fiat currencies have proven to be very poor stores of value. Inflation has destroyed many a "nest egg". It is no coincidence that markets in rare objects and unique artwork – usually sharing the attributes of collectibles described above – have enjoyed a renaissance during the last century. One of our most advanced high-tech marketplaces, EBay, is centered around these objects of primordial economic qualities. The collectibles market is larger than ever, even if the fraction of our wealth invested in them is smaller than when they were crucial to evolutionary success. Collectibles both satisfy our instinctive urges and remain useful in their ancient role as a secure store of value.

Conclusion

Many kinds of wealth transfers – one-way and mutual, voluntary and coerced – face transaction costs. In voluntary trades both parties gain; a truly free gift is usually an act of kin altruism. These transactions create value for one or both parties as much as the physical act of making something. Tribute benefits the victor and a judgment of damages can prevent further violence as well as benefiting the victim. Inheritance made humans the first animals to pass wealth to their next generation kin. These heirlooms could in turn be used as collateral or payment in trade for goods, for food to stave off starvation, or to pay a marriage bride price. Whether the costs of making these transfers – transaction costs – are low enough to make the transfers worthwhile is another matter. Collectibles were crucial in making these kinds of transactions possible for the first time.

Collectibles augmented our large brains and language as solutions to the Prisoner's Dilemma that keeps almost all animals from cooperating via delayed reciprocation with nonkin. Reputational beliefs can suffer from two major kinds of errors – errors of about which person did what, and errors in appraising the value or damages caused by that act. Within clans (the small and immediately local kin group, or extended family, which formed a subset of a tribe), our large brains could minimize these errors, so that public reputation and coercive sanctions superceded the limited motivation provided by the counterparty's ability to cooperate or defect in the future as the main enforcer of delayed reciprocation. In both Homo sapiens neanderthalis and Homo sapiens sapiens, with the same large brain size, it is quite likely that every local clan member kept track of everybody other local clan member's favors. The use of collectibles for trade within the small local kin group may have been minimal. Between clans within a tribe both favor tracking and collectibles were used. Between tribes, collectibles entirely replaced reputation as the enforcer of reciprocation, although violence still played a major role in enforcing rights as well as being a high transaction cost that prevented most kinds of trade.

When costliness becomes forgeable – Glass trade beads, manufactured in Venice in the 16th or 17th century, excavated from Mali, Africa. Such beads were very popular wherever European colonialists encountered Neolithic or hunter-gatherer cultures.

To be useful as a general-purpose store of wealth and means of wealth transfer, a collectible had to be embedded in at least one institution with a closed-loop cycle, so that the cost of discovering and/or manufacturing the object was amortized over multiple transactions. Furthermore, a collectible was not just any kind of beautiful decorative object. It had to have certain functional properties, such as the security of being wearable on the person, compactness for hiding or burial, and unforgeable costliness. That costliness must have been verifiable by the recipient of the transfer – using many of the same skills that collectors use to appraise collectibles today.

The theories presented in this paper can be tested by looking for these characteristics (or the lack of them) in the "valuables" often exchanged in these cultures, by examining the economic gains from the cycles through which these valuables move, and by observing preferences for objects with these characteristics in a wide variety of cultures (including modern ones).

With its unprecedented technology of cooperation, humans had become the most fearsome predator ever seen on the planet. They adapted to a shifting climate, while dozens of their large herd prey were driven, by the hunting and the climate change in America, Europe, and Asia, to extinction. Today, most large animals on the planet are afraid of projectiles – an adaption to only one species of predator [R97]. Cultures based more on gathering than hunting also greatly benefitted. A population explosion followed – Homo sapiens sapiens was able to populate more parts of the planet and at a density over ten times that of Homo sapiens neanderthalis [C94], despite weaker bones and no increase in brain size. Much of this increase may be attributed to the social institutions made possible by effective wealth transfer and language – trade, marriage, inheritance, tribute, collateral, and the ability to assess damages to dampen cycles of vengeance.

Primitive money was not modern money as we know it. It took on some of the function modern money now performs, but its form was that of heirlooms, jewelry, and other collectibles. The use of these is so ancient that the desires to explore, collect, make, display, appraise, carefully store, and trade collectibles are human universals – to some extent instincts. This constellation of human desires might be called the collecting instinct. Searching for the raw materials, such as shells and teeth, and manufacturing of collectibles took up a considerable portion of many ancient humans' time, just as many modern humans expend substantial resources on these activities as hobbies. The results for our ancient forebears were the first secure forms of embodied value very different from concrete utility – and the forerunner of today's money.

References

[A90] Adams, Charles, For Good and Evil: The Impact of Taxes on Civilization ↩ [A98] Tim Appenzeller, "Art: Evolution or Revolution?", Science 282(Nov 20, 1998), p. 1452. See also the home page of Stanley Ambrose ↩ ↩ [B04] The Blombos Cave Project ↩ ↩ [C94] Culiffe, Barry, ed., The Oxford Illustrated History of Prehistoric Europe, Oxford University Press 1994. ↩ ↩ ↩ ↩ ↩ [D89] Dawkins, Richard, The Selfish Gene, Oxford University Press 1989. ↩ ↩ ↩ [D94] Davies, Glyn, A History of Money, From Ancient Times to the Present Day, University of Wales Press 1994. ↩ ↩ ↩ ↩ [DW88] Daly, Martin and Wilson, Margo, Homicide, New York: Aldine (1998). ↩ ↩ [G95] Gilead, I. 1995. "The Foragers of the Upper Paleolithic Period," in Archaeology and Society in the Holy Land. Ed. by T. E. Levy. New York, Facts on File. ↩ [G01] [ref: http://www-geology.ucdavis.edu/~GEL115/115CH1.html] ↩ [Gr01] Graeber, David, Towards an Anthropological Theory of Value, Palgrave 2001. [I98] Ifrah, Georges, The Universal History of Numbers, John Wiley & Sons 1998, pg. 73. [K99] Kohn, M. and Mithen, S. "Handaxes: Products of sexual selection?", Antiquity, 73, 518-526. [K99] Kohn, M. and Mithen, S. "Handaxes: Products of sexual selection?", Antiquity, 73, 518-526. [L94] Landa, Janet, Trust, Ethnicity, and Identity: Beyond the New Institutional Economics of Ethnic Trading Networks, Contract Law, and Gift-Exchange, The University of Michigan Press, second edition, 1998. ↩ ↩ ↩ [M1892] Menger, Carl, "On the Origins of Money" Economic Journal, volume 2,(1892) p. 239-55. translated by C.A. Foley, at http://www.socsci.mcmaster.ca/~econ/ugcm/3ll3/menger/money.txt ↩ [M50] Mauss, Marcel, The Gift, 1950, English translation by W.D. Halls, W.W. Norton 1990. ↩ [M93] (Morse 1993) via http://www.wac.uct.ac.za/wac4/symposia/papers/s095wht1.pdf ↩ [R96] Riddley, Matt, The Origins of Virtue, Viking 1996. [T01] Taylor, Alan, American Colonies – The Settling of North America, Penguin 2001. ↩ ↩ [P89] Plattner, Stuart, Economic Anthropology, Stanford University Press 1989. [W77] Wiessner, P. 1977. Hxaro: a regional system at reciprocity for reducing risk among the !Kung San. Unpublished PhD thesis: University of Michigan. ↩ [W82] Wiessner, P. 1982. Risk, reciprocity and social influences on !Kung San economies. In: Leacock, H. R. & Lee, R.B. (eds) Politics and history in band societies: 61-84. London: Cambridge University Press. [W95] White, Randall, "Ivory Personal Ornaments of Aurignacian Age: Technological, Social and Symbolic Perspectives", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/Ivory/Ivorypersonal.html ↩ [W97] White, Randall, "From Materials To Meaning", Institute For Ice Age Studies, http://www.insticeagestudies.com/library/materialstomeaning/index.html ↩ [W98] Winterhalder, Bruce, "Intra-Group Resource Transfers: Comparative Evidence, Models, and Implications for Human Evolution", http://www.unc.edu/depts/ecology/winterweb/intra_group.html ↩ [W02] Wilford, John, "Debate is Fueled on When Humans Became Human", New York Times, February 26th, 2002 ↩

Acknowledgements

My thanks to Jerome Barkow, Andrew Odlyzko, Bruce Smith, K. Eric Drexler, Markus Krummenacker, Mark Wiley, Norm Hardy, and others for their insightful comments.

Copyright © 2002, 2005 by Nick Szabo

Permission to redistribute without alteration hereby granted

Editor's note: The source file contains comments with additional notes and thoughts by the author. Some links may be broken.Bit Gold

Nick Szabo December 29, 2005

A long time ago I hit upon the idea of bit gold. The problem, in a nutshell, is that our money currently depends on trust in a third party for its value. As many inflationary and hyperinflationary episodes during the 20th century demonstrated, this is not an ideal state of affairs. Similarly, private bank note issue, while it had various advantages as well as disadvantages, similarly depended on a trusted third party.

Precious metals and collectibles have an unforgeable scarcity due to the costliness of their creation. This once provided money the value of which was largely independent of any trusted third party. Precious metals have problems, however. It's too costly to assay metals repeatedly for common transactions. Thus a trusted third party (usually associated with a tax collector who accepted the coins as payment) was invoked to stamp a standard amount of the metal into a coin. Transporting large values of metal can be a rather insecure affair, as the British found when transporting gold across a U-boat infested Atlantic to Canada during World War I to support their gold standard. What's worse, you can't pay online with metal.

Thus, it would be very nice if there were a protocol whereby unforgeably costly bits could be created online with minimal dependence on trusted third parties, and then securely stored, transferred, and assayed with similar minimal trust. Bit gold.

My proposal for bit gold is based on computing a string of bits from a string of challenge bits, using functions called variously "client puzzle function," "proof of work function," or "secure benchmark function." The resulting string of bits is the proof of work. Where a one-way function is prohibitively difficult to compute backwards, a secure benchmark function ideally comes with a specific cost, measured in compute cycles, to compute backwards.

Here are the main steps of the bit gold system that I envision:

A public string of bits, the "challenge string," is created (see step 5). Alice on her computer generates the proof of work string from the challenge bits using a benchmark function. The proof of work is securely timestamped. This should work in a distributed fashion, with several different timestamp services so that no particular timestamp service need be substantially relied on. Alice adds the challenge string and the timestamped proof of work string to a distributed property title registry for bit gold. Here, too, no single server is substantially relied on to properly operate the registry. The last-created string of bit gold provides the challenge bits for the next-created string. To verify that Alice is the owner of a particular string of bit gold, Bob checks the unforgeable chain of title in the bit gold title registry. To assay the value of a string of bit gold, Bob checks and verifies the challenge bits, the proof of work string, and the timestamp.

Note that Alice's control over her bit gold does not depend on her sole possession of the bits, but rather on her lead position in the unforgeable chain of title (chain of digital signatures) in the title registry.

All of this can be automated by software. The main limits to the security of the scheme are how well trust can be distributed in steps (3) and (4), and the problem of machine architecture which will be discussed below.

Hal Finney has implemented a variant of bit gold called RPOW (Reusable Proofs of Work). This relies on publishing the computer code for the "mint," which runs on a remote tamper-evident computer. The purchaser of of bit gold can then use remote attestation, which Finney calls the transparent server technique, to verify that a particular number of cycles were actually performed.

The main problem with all these schemes is that proof of work schemes depend on computer architecture, not just an abstract mathematics based on an abstract "compute cycle." (I wrote about this obscurely several years ago.) Thus, it might be possible to be a very low cost producer (by several orders of magnitude) and swamp the market with bit gold. However, since bit gold is timestamped, the time created as well as the mathematical difficulty of the work can be automatically proven. From this, it can usually be inferred what the cost of producing during that time period was.

Unlike fungible atoms of gold, but as with collector's items, a large supply during a given time period will drive down the value of those particular items. In this respect "bit gold" acts more like collector's items than like gold. However, the match between this ex post market and the auction determining the initial value might create a very substantial profit for the "bit gold miner" who invents and deploys an optimized computer architecture.

Thus, bit gold will not be fungible based on a simple function of, for example, the length of the string. Instead, to create fungible units dealers will have to combine different-valued pieces of bit gold into larger units of approximately equal value. This is analogous to what many commodity dealers do today to make commodity markets possible. Trust is still distributed because the estimated values of such bundles can be independently verified by many other parties in a largely or entirely automated fashion.

In summary, all money mankind has ever used has been insecure in one way or another. This insecurity has been manifested in a wide variety of ways, from counterfeiting to theft, but the most pernicious of which has probably been inflation. Bit gold may provide us with a money of unprecedented security from these dangers. The potential for initially hidden supply gluts due to hidden innovations in machine architecture is a potential flaw in bit gold, or at least an imperfection which the initial auctions and ex post exchanges of bit gold will have to address.Introduction

The last decade has witnessed a revolution in distributed security. Old, pessimistic proofs that security and fault tolerance were "impossible", based on assumptions that protocols had to be deterministic and security and fault tolerance properties had to be absolutely certain, have given way to new proofs and implementations of provable security based on the assumption of cryptography and other randomized protocols that achieving security with very high probability is sufficient. The old view "proved" that the integrity properties of a wide variety of services on which civilization depends, whether synchronized clocks, public directories, censorship-proof file sharing and publication, or issuing money or securities were "impossible" on asynchronous networks like the Internet unless we put unlimited faith in a third party to enforce many of the rules of the service. We now know how to provide such services with a high degree of integrity and availability, yet far more resilient to the possibility that any party might act in a malicious manner.

Fault Tolerance and Security in Networks and Their Services

As a result of these new possibilities, we are witnessing a shift in the way we view trust. The old view in computer and network security was that trust was all-or-nothing – either we must place an essentially blind faith in a third party (for example a certificate authority or an issuer of digital cash) or we must protect against a particular mode of attack completely (as, for example, encryption protects against wiretappers). The old view could not handle most real-life situations which don't fall into either of these extremes. Among knowledgeable distributed security designers, unconditionally trusted third parties are now viewed as a cheat – "here we pray for heavenly benevolence", analogous to the comic-strip mathematician whose proof contains the crucial step, "here a miracle occurs". A third party fully trusted with a security property means that property in fact remains fully insecure – it means the protocol designer has fobbed off security on somebody else rather than actually solved a security problem.

The new view reiterates the desirability of complete protection against attack where it is available, but it adds protection against vast new classes of attacks, and protection of a wide variety of other desirable properties of distributed system, that are impossible to protect without at least some trust assumptions. The new trust assumptions are that participants in a critical public service are partially, usually, or more often than not trustworthy, and often only under certain conditions. The set of parties that make up a critical distributed service is never either completely trustworthy nor all malicious.

Modern protocols for critical services such as public directories construct, out of all possible subsets of all participants, attack structures consisting of the worst combination of malicious parties that be tolerated, and their complement, access structures, the minimal set of parties that need to act correctly during this operation to perform the function. (Note that access structures have nothing to do with access control lists, a traditional security method that assumes a fully trusted third party and consists of a static list of persons or classes of persons and the resources or classes of resources they have access to).

One particular simple example of such an attack and access structure is a threshold structure where the malicious behavior of up to t out of n participants can be tolerated. Although we will describe the protocols below in terms of threshold structures, it will usually be possible to substitute other partitions of the power set of participants into minimum access and maximum attack structures.

A given property of a system has perfect security if its access structure is any participant and its attack structure is the empty set. An example of a property with perfect security is the use of a spinning neutron star called a pulsar as a clock. Its access structure is any party that can receive its natural broadcasts, and its attack structure is the empty set – given the reasonable presumption that there are no aliens out there who can and want to manipulate the very high energy outputs of pulsars in pursuit of some human ends they have learned about.

Another perfect security property is that of encryption against third parties, assuming the encryption is unbreakable. However, if we take into account the receiver of a message as a possible attacker, the broader privacy property is not secure – the receiver is an attack structure of one who can compromise privacy of the entire message encrypted to him.

A security property is almost perfect if its attack structure must contain T-1 out of N participants. For example, in the digital mix of Chaum[C81], for a single message, it would take collusion of N-1 out of N of the mix servers to trace a message. The untraceability property of this system has almost perfect security for a single message. On the other hand, the reliability property of the digital mix is almost perfectly insecure, since any one of the n mix servers can block a message from getting through. Often we must trade off two different properties like this. Since reliability is an error reversible by the end user and a privacy breach is not, the tradeoff made here by Chaum makes sense.

Alas, for many desirable properties we cannot achieve either perfect or almost perfect security. For some properties of replicated services – for some kinds of rules they advertise as following – we can achieve almost perfect security through, for example, the use of cryptography.

For any other properties, the maximum attack structure of malicious and colluding servers that can be tolerated is the set complement of the access structure. For the threshold case, this means that T, the maximum number of malicious and colluding servers that can be tolerated, is a certain fraction of the total number of servers, such as 1/3 or 1/2, of the total number of servers comprising the service, N. That is to say, if T+1 out of N of the servers jointly decide to violate the service's rules and thereby corrupt the system, they can do so. Those who wish to stick to the rules must back out of the corrupted transaction and restart the service out-of-band. For this large class of service properties where the access structure is the set complement of the attack structure, the security of a property is neither perfect or almost perfect at one extreme, nor fully depends on a single trusted party at the other extreme. We say that this class of service properties can be implemented with distributed security.

Three of the properties we most often want to protect are privacy, liveness (a.k.a. availability) and integrity. For a replicated service, the main focus of this article, we focus on the security of the integrity and liveness of a single operation of a service. The goal is to create attack structures that are very highly unlikely to fail. If or when such failures of widespread collusion do occur, relying parties, i.e. parties who depend on the properties being secured, must go "out-of-band" and use supplementary systems to repair the system. These supplementary systems might include a wide variety of interparty integrity constraints, audits, blacklisting, and other schemes involving auditing, reputation, and/or cryptography by participants, relying parties, or third parties. These can further motivate servers to preserve the integrity and liveness of these services, and help users to recover after a (now much rarer) successful attack.

Since a wide variety of trust assumptions can now be made by a security protocol and this variety can for the first time be described mathematically – as attack and access structures – these supplementary systems can focus on keeping the actual attack structures smaller than the maximally tolerated attack structure, rather than on vastly more difficult task of plugging wide-open security holes called "trusted third parties" with these more loosely defined or traditional supplementary institutions.

Partial and Total Orders

A basic issue of security and fault tolerance that must be resolved is the secure determination of which order events occured in. If a contract specifies a deadline and it goes down to the wire, how can a relying party or third party adjudicator determine whether the deadline was met? The outcome itself, and its fairness, may rest on fairly deciding who came first. If Alice tries to double-spend a piece of digital cash[C82], only the recipient who checks with the bank first is entitled to its value. But if the bank servers are replicated, which of the two recipients Bob or Charles checked with the bank first? In the case of a replicated property title service[S98] we have a similar problem – if Alice transfers her title to two other owners, which new owner actually received the deed? If property is homesteaded on a first-come first-serve basis, which of two or more "land rushers" competing for a lucrative parcel is entitled to the land?

Lamport (Causal) Order

Imagine a network where computers don't know how to keep time very well – they are always getting out of synchronization. (Alas, all you have to really think of here is the actual Internet with PCs). Such a network, called an asynchronous network, lacks an accurate and secure global clock time by which computers can determine the order in which events, which might be messages sent or instructions executed on a particular local machine, have happened. Lamport[L78] was among the first to tackle the problem of how to determine the order of events in such a network.

A partial order means that we know in what order some of the elements are, but we aren't sure about some of the others, or some of the others may be equal. An example is the "less than or equal to" relationship among a group of integers, some of which can repeat. Some of the integers we know are less than some others, but an integer paired with itself is equal. A total order, on the other hand, is like the "less than" relationship among unique integers – we can always tell when one integer is less than another – there is no ambiguity left. In the case of events, a partial order means for some pairs of events we know whether one occured before another, and for some others we don't know. We use the same symbols as we would use for the analogous case of the integers, so that "x <= y" means "x either occured before y or we don't know whether it occured before or after y". In a total of events, we know for any two events which one happened first. We write "x < y" meaning "x occured before y."

Lamport's answer to the event ordering problem was to show that parties (or, we use the terms equivalently here, nodes on the network) can agree on a partial order of events based on causal relationships between these events – or at least the subset of events where we can determine that causation could occur. On a network, parties influence each other by talking to each other – in other words, by sending each other messages. Lamport used these messages as the basic building block for constructing his partial order, according to the following rules:

If an event is local to node P, every nonfaulty node agrees on P's opinion of it. Every correct node agrees that every message was sent before it was received. If we agree that event A occured before event B and that event B occured before event C, then we agree that event A occured before event C. In other words, this partial order is transitive.

Breaking Ties – Creating a Fair Total Order

The partial order leaves us with the need to agree on how to break ties – how to resolve the ambiguities where we can't agree which event took place first – and thus create a total order of events. We want to do so in a way that is fair, in other words, in a way that cannot be manipulated to the advantage of any particular party.

An unfair way to create a total order would be to impose a certain predictable rule for breaking ties. For example, we could decide on a total order for the processes and break ties in the causal order by referring to this total order.

However, such a procedure creates a bias that may, depending on the application, favor certain servers over others, and therefore allow those servers to favor certain clients over others.

One way to break ties fairly is have the participants toss fair coins – in other words, generate random numbers in a way that cannot be manipulated and then assign those random numbers to events. There are several ways to toss fair coins over a network and we describe one such way below.

Another way to break ties fairly is to have the participants agree to a global clock time that is more accurate than the message delays faced by those who would manipulate timing in favor of some party. This entails using a network with very predictable message lag for the clock synchronization protocol and a less predictable one for the other services. We will describe how to do this below.

Some Cryptographic Primitives

Certain cryptographic primitives play a crucial role in the recent breakthroughs in distributed security that we will discuss here.

Oblivious Transfer

Oblivious transfer is an important building block of multiparty secure computations and related protocols. Rather than describing it here, we recommend this good introduction.

Bit Commitment

Alice wants to prove that she can predict the stock market. But she doesn't want to actually reveal her choice to Bob or anybody else until she's actually had a chance to trade on her prediction. But after the fact, she could just read the closing price and pretend to Bob that she predicted it. How can Alice prove to Bob that she actually predicted the market? Using bit commitments.

Bit commitments are ways to commit to a string of numbers or data, in such a way that if or when one later publishes the data, it cannot be forged – it must be the same as the data you earlier committed to.

Alice can commit to her data using one-way functions – functions that are much harder to compute one way than another. (One-way functions are the most basic building block of cryptography). A common kind of a one-way function is a cryptographic hash function.

To create a bit commitment, Alice first generates two random numbers. Then she computes the bit commitment by hashing the two random numbers and the data to be committed to. Append on of the random numbers to the end of the hash and sends it to Bob. The next day when Bob wants to examine the data, and prove that it matches the data Alice originally committed to, Alice provides the data along with the second random number. Bob can verify that it is astronomically unlikely that Alice was able to commit to one predication and then later tell Bob she predicted something else.

This protocol is called "bit commitment" because one can commit to even an individual bit this way. If the data has enough entropy one can commit to that data simply by using a hash function and dispense with the random numbers. We will see below how with secure timestamping other parties can determine when the data was committed to.

Multiparty Secure Computation

The ideal protocol would have most trustworthy third party imaginable – a diety who is on everybody's side. All the parties would send their inputs to God. God would reliably determine the results and return the outputs. God being the ultimate in confessional discretion, no party would learn anything more about the other parties' inputs than they could learn from their own inputs and the output.

Network security theorists have recently solved this problem to an astonishing extent. They have developed protocols which create virtual machines between two or more parties. Multiparty secure computation allows any number of parties to share a computation, each learning only what can be inferred from their own inputs and the output of the computation. These virtual machines have the exciting property that each party's input is strongly confidential from the other parties. The program and the output are shared by the parties.

For example, we could run a spreadsheet across the Internet on this virtual computer. We would agree on a set of formulas and set up the virtual computer with these formulas. Each participant would have their own input cells, which remain blank on the other participants' computers. The participants share output cell(s). Each input our own private data into our input cells. Alice could only learn only as much about the other participants' input cells as she could infer from her own inputs and the output cells.

More information on this exciting breakthrough can be found in the accompanying article "The God Protocols". Often, as in the spreadsheet example above, the resulting protocol would be very slow. We will now discuss a special efficient kind of multiparty secure computation – threshold cryptography.

Threshold Cryptography

Threshold cryptography has been used to help achieve Byzantine-resilient replication in Rampart, Fleet, SITRA, and several other distributed service or filesystem architectures. Threshold cryptography is an optimized special case of a more general technique called multiparty secure computation

In a threshold public-key cryptosystem there is a single key for encryption, but each party holds a key share for decryption. A threshold scheme implements the threshold case of distributed security as described above. Any T+1 key share holders are needed to jointly perform a decryption, and any N-T key share holders can collude to prevent a decryption from being performed. The parameter T can be set at any positive integer between 1 and N. Often a more general access structure, under the distributed security constraint that the access structure is the set complement of the attack structure, can be implemented as well.

For some algorithms one must assume a trusted dealer to generate a private key and distribute shares; for some other algorithms a mutually confidential generation of key shares is possible. During the decryption protocol, each party processes a decryption request for a particular ciphertext and output a decryption share together with a proof of its validity. When a party obtains the ciphertext and at least T+1 valid encryption shares, it can recover the message. In the case of threshold signatures, when at least T+1 signature shares have been obtained, a valid signature can be constructed. [C01]

Fair Coin Tosses

Joe Killian introduces this problem as follows[K90]:

Alice and Bob wanted to flip a fair coin, but had no physical coin to flip. Alice offered a simple way of flipping a fair coin mentally. First, you think up a random bit, then I'll think up a random bit. We'll then exclusive-or the two bits together," she suggested. "But what if one of us doesn't flip a coin at random?" Bob asked. "It doesn't matter. As long as one of the bits is truly random, the exclusive-or of the bits should be truly random," Alice replied, and after a moment's reflection, Bob agreed. A short while later, Alice and Bob happened upon a book on artificial intelligence, lying abandoned by the roadside. A good citizen, Alice said, "One of us must pick up this book and find a suitable waste receptacle." Bob agreed, and suggested they use their coin-flipping protocol to determine who would have to throw the book away. If the final bit is a 0, then you will pick the book up, and if it is a 1, then I will," said Alice. "What is your bit?" Bob replied, "1." "Why, so is mine," Alice said slyly. "I guess this isn't your lucky day."

Bruce Schneier[Sh96] goes on to describe what is wrong with this protocol:

Needless to say, this coin-flipping protocol has a serious bug. While it is true that a truly random bit, x, exclusive-ORed with any independently distributed bit, y, will yield a truly random bit, Alice's protocol did not ensure that the two bits were distributed independently. In fact, it is not hard to verify that no mental protocol can allow can allow two infinitely powerful parties to flip a fair coin. Alice and Bob were in trouble until they received a letter from an obscure graduate student in cryptography. The information in the letter ws too theoretical to be of any earthly use to anyone, but the envelope the letter came in was extremely handy. The next time Alice and Bob wished to flip a coin, they played a modified version of the original protocol. First, Bob decided on a bit, but instead of announcing it immediately, he wrote it down on a piece of paper and placed the paper in the envelope. Next, Alice announced her bit. Finally, Alice and Bob took Bob's bit out of the envelope and computed the random bit. This bit was indeed truly random whenever at least one of them played honestly. Alice and Bob had a working protocol, the cryptographer's dream of social irrelevance was fulfilled, and they all lived happily ever after.

On a computer, those "envelopes" are committed bits – see the protocol for bit commitment above. Also see Manuel Blum's landmark paper "Coin Flipping By Telephone"[B82] for more details. He subtitled the paper "A Protocol for Solving Impossible Problems", which was more prescient than he knew.

Fair coin tosses can be used to create a fair total order of events out of a partial order of events, defined by sending and receiving times for messages, in an asynchronous distributed system. They can similarly be used to achieve atomic broadcast, and thus Byzantine agreement and replication[C01][CP02].

The threshold coin-tossing system developed by Cachin, Kursawe, and Shoup [C01] solves the fair coin tossing problem by implmenting a cryptographic pseudorandom number generator (PRNG) is a distributed manner using threshold cryptography. They use their protocol to solve the Byzantine generals problem for asynchronous networks. We will describe the Byzantine generals problem and its solution on asynchronous networks further below.

Against Traffic Analysis

There are a wide variety of other cryptographic primitives and protocols, beyond the well-known symmetric and asymmetric cryptosystems, that give us security properties not otherwise in distributed systems, including and mixing and channel padding[C81] and blind signatures[C82] to combat traffice analysis.

Physical Broadcasts and Global Clocks

Canonical Bells

In our time, the tallest and most expensive buildings belong to some of our most important economic institutions – multinational corporations. The size and expense of our skyscrapers will provide future archaeologists an important clue that these institutions played a big role in our economy. In the high and late Middle Ages, the tallest structures in Europe were bell towers – larger and more numerous in that region than on any other continent. Chartres in the year 1169 boasted a 437 foot tower, the world’s tallest. These towers, besides the churches they were built upon, were also the most expensive structures in town.

Some historians claim that the size and expense of Europe’s steeples and public clocks, like the size and expense of the churches they were built upon, reflected the predominant role of religion in medieval life, as opposed to business in ours. Given that the churches and cathedrals themselves were expensive, this is a plausible claim. However, the Church also played a leading role in the economy, both by its own economic activities and by its role in commercial law. The church bells and their clocks also played a major economic role.

Telling time was not the only, and perhaps not even initially the main, function of church towers and their bells. An important early function of the bell tower was as an alarm, to inform the town of emergencies such as a fire or attacking army. The towers also sometimes made a good vantage point to detect such events. They tolled for events such as baptisms and funerals. Timekeeping became its primary function, first in order to call people to mass, but soon as a general service the Church provided to the surrounding Catholic community that supported it. Long before the mechanical clock, residents within a few miles of a church started working their schedules around the canonical hours – sundial-based unequal hours – tolled on its bells. Thus in many European cities, long before the invention of the mechanical clock, the local church was trusted to ring the hours. Churches, funded mainly by the nearby parishioners, but often also by the city or directly by a guild of merchants, lavished enormous resources to build, operate, and maintain the towers as well as the bells, and later for the clocks that were installed in those towers. The productive synchronization of human relationships funded the bell towers; the bell towers would provide a ready market for public clocks. Thus did in Europe emerge a "virtuous circle" that would advance both its timekeeping technologies and time-dependent institutions beyond those of the other continents.

The time rung on the bells was mainly read from a sundial. By the 11th century these were often supplemented by water clocks. By the end of the 14th century most were using the new mechanical clock, backed up by another new technology of that century, the more reliable and personally secure sandglass.

In the larger and more important belfries were present at least two bell-ringers. They lived up there full-time[D96]. This arrangement is an example of the pattern of dual control – each ringer served as a check for the other; neither could spoof the time or other bell signals without the collusion of both.

The heaviest and most expensive elements of the towers were the bells. Bells smiths competed to produce the most distantly hearable ringing. The "Maria Angola" bell, cast in 1659 and installed in a cathedral in Cusco, Peru could be heard up to 25 miles away[G95]. In Cordova in the 16th century, a cathedral boasted a one-ton bell that could be heard 8 miles away. At the cathedral at Rouen, in 1321, a carillon was installed that played on an array of bells a hymn audible 5 miles away[D96]. The typical range of a parish church’s bells was 3-5 miles. These bells would primarily be heard and in the surrounding town; larger bells could also be heard by peasants working in the fields miles away.

The most valuable property of the bell tower time was not its accuracy, but its fairness. Even if it broadcast the wrong time, it broadcast the same wrong time to everybody. An employer, even if he was colluding with the Church to bias the sometimes subjective ringing of the canonical hours, couldn’t tell his favorite employees that it was time to go home, while making other employees work extra, and pretend that it was the same time. (In contrast, on our computer networks such "Byzantine" attacks are possible, without advanced safeguards, when "broadcasting" time or other information).

While nearby churches or monasteries provided the public, standard time, workers and employers both often employed their own timekeeping devices as a check. Peasants could tell the time by observing their own shadow against some standard sized object. In Germany and Flanders, even the smallest peasant villages had "quadrants to indicate the hours without the sun". Miners, working underground, followed work bells, operated by the employers, and passed their signal on through the tunnels by workers banging on tools. As a check, the miners had their own marked tallow candles[D96]. Despite the public broadcast of authoritative time, few dispensed with the option to check their own independent sources.

See the accompanying article "On Time" for more of the fascinating history of Europe's development of clocks and accompanying economic institutions.

Natural Broadcasts

Broadcasts using sound or radiation, from sources such as bell towers, radio towers, satellites, and pulsars, must send out the same value to every receiver. A remote beacon such as a pulsar has perfect security: the access structure is any party, and its complement, the attack structure, is the empty set. For human controlled broadcasts, the attack structure consists only of the broadcaster and the access structure is any receiver.

Natural broadcasts are thus immune to the problem, described in the discussion of the Byzantine Generals problem below, of a transmitter sending different values to different receivers. Indeed, as we will see below, distributed researchers have gone to great lengths just to recreate this simple property on the Internet with logical broadcast protocols.

Natural Clocks

Nature provides clocks that are oblivious to the malicious intentions of any outside parties. In the case of a remote high-energy system such as a pulsar, this means anybody. and many orders of magnitude more accurate than random delays that face attackers on the Internet. If critical Internet servers were synchronized to natural clocks in a secure and timely fashion, they would be immune to attacks that relied on uncertainties in timing. Here are some comparisons of the stability (error creep) in good natural clocks:

Oscillator Stability 1 sec 1 day 1 month Quartz 10-12 10-9 10-8 Rubidium 10-11 10-12 10-11 Cesium Beam 10-10 10-13 10-13 Hydrogen Maser 10-13 10-14 10-13 Pulsar 10-11 10-12 10-13 Io orbit

Pulsars overtake atomic clocks in accuracy after about 4 months.

Ladies and Gentlemen, Set Your Watches

The Internet with its wide and unpredictable variances in message delays makes for an extremely poor method of distributing time. Some clock synchronization protocols for an asynchronous network are described in [C??][CF94]. Unfortunately, their accuracy is limited to the same order of magnitude of uncertainty as that would face an attacker. So they don't clearly eliminate the possibility that an attacker could take advantage of the different servers hosting a critical service disagreeing on the time.

Far more accurate are the distribution methods, especially radio broadcast, described in this excellent survey of timekeeping techniques.

This article also contains an excellent discussion of the highly distributed system used for reaching agreement on the global standard UTC time. Over 200 centers use their own atomic clocks to update UTC time. This recalibration uses a sophisticated averaging formula that throws out extreme values. There are also 50 centers in 30 different countries that can be queried at any time during the month for the current recalibration according to their own atomic clocks. In addition, there are a variety of services that broadcast UTC time, with varying levels of delay uncertainty and cost that the article describes in detail. The security and tolerance to extreme faults of the entire system from atomic clock to delivery of time updates to relying parties is not clear but probably high. The jurisdictional diversity of the atomic clock sources is far higher than that of common delivery systems such as GPS, but the results of the latter can after the fact be easily checked against the former, keeping the latter honest, so that the resulting end-to-end system is almost universally trusted (taking into account certain well-known adjustments such as selective availability in GPS).

Secure Time-stamping

Secure time-stamping is a way for a party with a confidential document, or two or more parties sending private messages, to commit to each other and third parties an unforgeable, non-repudiable time-stamp. This time-stamp consists of a place in a total order consisting of this message, other parties' messages, and clock ticks. This commitment is accomplished without the parties having to reveal the actual contents of those messages, unless or until challenged for proof, to any third parties. (Even then, there exist zero-knowledge proofs that allow the party to prove he has a document corresponding to the time-stamp without revealing the document).

These protocols work by users sending a cryptographic hash (a.k.a. message digest) of their document to the time-tstamping servers. The servers chain messages and click ticks together by order of arrival. Replicated servers can break ambiguities in order of arrival with a protocol such as fair coin tossing to achieve a fair total order.

The Byzantine Generals Problem

Lamport created a theoretical structure for security and fault tolerance in a distributed service with the Byzantine generals problem. These generals might be loyal, following orders and passing them on faithfully, or they may be traitors. The worst-case behavior of traitorous generals is modelled by the nasty trick of sending out contradictory orders – for example, telling one general that the order is to march and another general that the order is to retreat.

(Lamport just meant the Byzantine generals story as an interesting, cartoonish illustration of the theory of fault tolerance against corruption by malicious adverseries, but this kind of problem has actually sometimes occurred among generals. The actual generals of the Byzantine Empire were no more prone to such treachery than any of their enemies, such as the Persians or Turks. If one is partial towards the Byzantines, one can think instead of the Iraqi generals in the current war there – the Coalition generals hope that some of the Iraqi generals will defect and are trying to insert forged messages into their communications network. They hope some generals will be duped into following these specious orders).

There are N generals; one of them is the commanding general or field marshall. They can send and receive messages between each other. The Byzantine generals problem is to develop a protocol for the commanding general to send messages to his N-1 subordinates so that

All loyal generals obey the same order, and If the field marshall is loyal, every loyal general obeys the orders he sends.

The protocol should be able to resist up to T traitorous generals. In the case of a fully deterministic protocol (no random choices or cryptography allowed) the best we can do is tolerate T = floor(N/3) - 1 generals for a synchronous network. For an asynchronous and deterministic network no traitors at all can be tolerated.[FLP85]

However, the Byzantine general's problem is easily solved by unjammable physical broadcast. Not coincidentally, solving the logical broadcast problem on network where physical broadcast is absent is very similar to, and as hard as, solving the Byzantine generals problem.

The above pessimistic results regarding T on deterministic networks – and the inefficiency of protocols that could provide these weak solutions to the Byzantine generals problem – until recently has discouraged researchers and engineers from finding practical solutions to securing distributed services. However, under only slightly weaker assumptions – those of cryptography, that we need only achieve security with a very high probability – agreement between the Byzantine generals has not only been achieved [Ben-Or] but achieved efficiently [Cachin]. The basic insight in these solutions is that we can break ties in a Lamport partial order in a an unbiased way with random numbers.

Logical Broadcast Over the Internet

Point-to-point communications is sufficient for many applications. For many others, nodes need to send a message to many other nodes, or multicast. We call the simple case where a node sends messages to all other nodes participating in a system broadcast.

As we've seen, broadcast can be implemented directly in physical media such as sound and radio. We will discuss the problem of implementing logical broadcast over an asynchronous network that directly supports only point-to-point communications. Such broadcasting protocols are subject to node and communications failures, including malicious attacks.

Four important design criteria of such a logical network are reliability, consistent ordering, causality preservation, and fairness. Reliability means that a message once broadcast be received by all the functional nodes. Consistent ordering means that different messages sent by different nodes are delivered to all the nodes in the same order. Causality is preserved if this order is consistent with with the causal order in which messages were sent and received. Fairness means that no node can breach the rules or properties of the system we want to protect, particular to some parties advantage or disadvantage, by manipulating this order.

Note that physical broadcasts, if they cannot be jammed, easily have these properties. Since the broadcast medium has a finite velocity, messages might not all be received in the same order as sent. However, the receiving nodes can deduce from the physical properties of the medium the expected time lag at their distance and thereby deduce sending times. We say in this case that messages are received in a certain order, queued, and then delivered in a possibly different order.

The basic issue here is message delays – some servers receive messages in different order from others. Clock synchronization can reduce the scope of this problem – even eliminate it if done over a network where unpredictability in message lag times are much less than in the network over which we run the other services we wish to secure. In such cases clocks can be synchronized with sufficient accuracy that global clock time cannot be spoofed to reorder messages with significant probability. Where we choose not to implement such a global clock (because, for example, the price of retrofitting services with a radio time synchronization service as described above), we have another option for creating a fair total order – the fair coin flipping methods described above. The result is a logical broadcast with the same basic security properties as an unjammable physical broadcast.

Byzantine-Resilient Replication

The theory of the Byzantine generals has a practical equivalent – the problem of replicating a serivce – or, equivalently, a distributed object – in such as way as to provide distributed security, or fault tolerance against arbitrary behavior of up to T malicious and colluding servers.

These services or distributed objects are sometimes called "intrusion tolerant", because the replicated service can resist attack and corruption of up to T servers. However, in the real world more perpetrated by insiders rather than intruders. Byzantine-resilient replication of a service across administrative domains or jurisdictions solves both problems.

Several Byzantine-resilient replicated service infrastructures have been implemented . They use techniques such as threshold cryptography and fair coin tossing to achieve logical broadcast on asynchronous networks like the Internet, protected against attack structures of colluding and malicious servers, such that the attack structure is the set complement of the access structure. See Appendix A below for sources of more information. A wide variety of Byzantine-resilient services can be built on top of logical broadcast. A high bandwidth, many-to-many unjammable physical broadcast network might provide similar but more efficient solutions in the future. A Byzantine-resilient replicated object library, for implementing online services with distributed trust in the CORBA distributed object system is described in this presentation and this paper.

The basic system has the ability to replicate stateful objects resilient to up to 1/3 Byzantine (arbitrarily malicious) failures.

In other words, object replication is used to distribute trust in the integrity of data and computations. Instead of obtaining a critical service from a single trusted server – which may be innately malicious or may get cracked by an outsider – one obtains the service from N different servers, and the service maintains its integrity as long as less than N/3 of the Vats are malicious.

Note that the "voting" implicit in Byzantine resilient protocols like that used here protects the integrity of a particular remote method call. Between such invocations, clients can update their own blacklists of servers they have found to be unreliable. With such a blacklist the attacker must manifest their faulty behavior in over N/3 servers during the same call in order to corrupt the call. Once this is discovered the client can blacklist them, removing them from the list of trusted Vats for subsequent calls.

Integrity techniques such as cryptographic hashes, digital signatures, secret sharing, and threshold cryptography can be layered on top of this basic Byzantine-resilient replication system to further increase the integrity of certain properties of the replicated state. Which of these techniques are used, and how, depends on what the critical functionality is that one is protecting.

Replication of course does not distribute trust in the privacy of the data – quite the opposite, it magnifies the exposure. However, where this problem is relevant it can easily be overcome with encryption and/or multiparty secure computation, described above.

A necessary part of any good distributed security toolkit is a diverse cryptographic library, implementing not only symmetric and assymetric primitives but also those described or referred to in this article.

Some Applications

A wide variety of other applications once thought "impossible" to secure can now be implemented securely.

On a public network a wide variety of values must be agreed upon across trust boundaries, such as mappings of names or addresses to keys (as in a public key infrastructure) or of names to addresses (as in the Domain Name System). Such agreements across trust boundaries can best be thought of as simple kinds of private property to be controlled by their owner, within constrains enforced by the rules followed by the replicated service, a public property titles system.

Whether thought of as property rights or not, a wide variety of such currently centralized services can be re-implemented with much greater ensurable integrity and availability by distributing their trust with techniques such as Byzantine-resilient replication.

Another large class of potential services that can be distributed are issuers of digital bearer instruments, such as digital cash.

This author's design for a secure property title service uses cryptographic hash functions and digital signatures (without the need for a PKI) on top of a Byzantine-resilient replicated object service to maintain the integrity of chains of property titles. It's also suitable for property-like directories such as the Internet's Domain Name System (DNS).

Conclusion

The old pessimism has been overturned. Old proofs of "impossibility", based on strict insistence in perfect certainty, have given way to new proofs demonstrating how to do the "impossible" by being satisfied with extremely high probability against a sophisticated but computationally bounded opponent – the assumption of cryptography – rather than of absolute certainty. This overturning of the old view has led to a raft of new possibilities for securing distributed applications. The simple protocol of the bell tower, which broadcast to every resident of a medieval town the same time, can now be implemented on a network – either through logical broadcast on the Internet or physical broadcast with radio. For the first time we can implement on the Internet the integrity properties on which civilization depends – including synchronized clocks, unforgeable transactions, and censorship-proof publishing. Where today's Internet, lacking this technology, fails to provide many of these properties, we now know how to provide them with a greater degree of integrity and availability than either the Internet or any previous media was capable of.

Appendex A – Implementations

Byzantine-Resilient Replication

Traffic Analysis Reistant Messaging

Blind Signatures and Bearer Instruments

Hash Chain Structures and Secure Time-stamping

Oblivious Transfer and Multiparty Secure Computation

Capabilities / Smart Sandboxes

References

Copyright © 2003 by Nick Szabo

rough draft – quoting or redistribution without permission of the author prohibited

Editor's note: Some links may be broken.The Playdough Protocols

Nick Szabo 2002

Commercial security at the birth of writing, arithmetic, and religion in ancient Sumer (modern Iraq).

Table of Contents

Introduction

It is five thousand years ago, and you pace fretfully in your office. Located in the temple of the great goddess Inanna in ancient Nippur (now in Iraq) you are buried, not in a blizzard of paper, but an avalanche of clay. You fret. You have entrusted a valuable cargo of sheep, barley, and beer to a crusty group of sailors from the Baba Temple in the nearby Lagash[1]. These navy types are far from pious devotees of the goddess Inanna and the great god Enlil with whom you are familiar.

The sailors‘ job, and your payoff – take the goods down the Persian Gulf and across the sea to Mohenjo-Daro, in the valley of the Indus River (in modern Pakistan). There they will be delivered to your old friend, a trusted agent of Inanna, and sold to the locals for a very substantial amount of silver.

Will the sailors get hungry and eat the sheep and barley? Party and drink the beer? Get nasty and poison the lot, throwing disrepute on the great goddess Inanna? Perhaps they will get clever and water down the beer – or get still more clever and resell your high-quality goods under the name of their crude god.

You needn‘t worry so much. Long-distance commerce may be a novelty, but you have the clay.

Nor, thanks to five thousand years of experience with the technologies of tamper evidence, need we worry so much in our modern era. The occasional embezzlement and rare but quite nasty poisoning occur far less often due to our technological and institutional descendants of the ancients‘ clay. And using the digital equivalent of seals, we can bring data integrity and unforgeable identities to online commerce.

Seals and Sealing

Terra cotta sealing (bottom) and rectangular stamp seals, Mohenjo-Daro, Indus Valley, c. 2,000 B.C. The central sign on the top seal may represent a house or temple and is a symbol that is often repeated on Indus seals with horned deities seated in yogic position. Courtesy harappa.com.

Let‘s follow the professional archaeologists and distinguish between seals, the often cleverly carved cylinders or stamps that make the impressions, and sealings, the resulting impressions rolled or stamped on wet clay, and the clay they were impressed upon. Sealings of clay were wrapped around rope knots to seal bales of goods, and around the rims of wicker baskets and pottery jars to seal in their contents. Since these ancients lacked good locks, clay sealings were wrapped around door latches to seal rooms. The security provided – evidence of tampering, due to damage of the container itself or the clay that sealed it.

Seals were carved from hard materials – usually stone but sometimes faience, glass, metal, wood, or bone. Sometimes sun-dried or baked clay itself was used. The Greeks and Romans used signet rings, their action ends shaped from metal or carved from gems, to stamp wax.

The seal design was usually recessed, resulting in a raised impression; occasionally this was reversed. To creating a sealing, first wet clay was shaped around the plug of a jar, the rim of a basket, the knot of a well wrapped rope on a bale, or the latch of a door. Then the surface of the clay was thoroughly covered by the impressions of the seal. The Sumerians commonly used cylinder seals, repeating the pattern across the entire clay surface. Sometimes stamp seals were used for smaller surfaces. Finally, the clay was left to dry, in the sun if possible.

While sun-dried clay could usually be remoistened and rewritten, it would have been very difficult to hide from a trained eye. Rejoining the breached container lid, knot, or latch and replacing the broken seal with a new, identical seal would have been, short of stealing the original unique seal carving, impossible to hide from the inspector. Looking for a particular seal impression and examining the container, the inspector could reliably tell whether the contents had been tampered with. The difference between an accidental crack, from dropping or hitting the object, and a breach that allowed the thief or adulterator access to the goods, would also be apparent. Ancient inspectors undoubtedly became experts at looking for clues to distinguish accident from fraud. In any case, a broken seal then as now indicated suspect goods suitable perhaps for the discount bin, but more normally for the trash. It also indicated error for fraud – and potential punishment.

Cylinder seal (left) and its sealing (right), King Darius the Great, Persia, 586–522 B.C., with weapons of war

The earliest stamp seals found were used in Iran in 5,000 B.C. Later on archaeologists can use both the trade in seals themselves, as well as the distances between seals and the corresponding sealings, to trace long-distance trade networks. One such set of seals were manufactured around 1,900 B.C. on two important island trading cities in the Persian Gulf – Bahrein and Failaka. These seals were traded all over the Middle East, and have been found at diverse and distant locations such as Susa in Iran , Bactria in Afghanistan, Ur in Iraq, and Lothal on the west coast of India. By 1,750 B.C. Common Style seals are found in locations ranging from Spain, to Mycenaean Greece, to Marlik near the shores of the Caspian Sea. These seals were made from faience, a less expensive material, and used by smaller merchants.[2]

The first cylinder seals belonged to the now long dead civilization of the Sumerians, the inhabitants of Nippur, Lagash, and other cities on the Euphrates and Tigris rivers in what is now Iraq. They spoke a strange language – neither Semitic nor Indo-European, the family of languages spoken by many later civilizations and the most current inhabitants of the Middle East. Sumerian was an agglunative tongue, bearing resemblance to such diverse agglutinative languages as Turkish, Finnish, Japanese, and Dravidian. Indeed, it was probably some version of the latter tongue that was spoken by their neighbors, the early inhabitants of the Indus river valley. These Indus valley people developed, soon after the Sumerians, their own civilization and unique style of seals. Modern speakers of Dravidian languages are scattered all over the Indian subcontinent, including remnants in Afghanistan and a large number of Tamils in southern India. Seal impressions have been found in the ancient city of Harrapan, in the Indus River valley (modern Pakistan), that had been made by seals found in Lagash in Sumeria (modern Iraq). From 3,600 B.C. in Sumer, and a little later in the Indus Valley, we can find seals made out of a rare high-quality stone, lapis lazuli. These stones could only have originated from rather distant and inaccessible mines in Afghanistan.

For the Sumerians a business protocol was also a religious ritual, and the reverse was usually true as well. In the Middle East seal breaking became one of the most important of these rituals, with terrifying spiritual consequences if the seal were broken by the wrong person or at the wrong time. Three thousand years later these poetic images had reached apocalyptic proportions in the writings of the early Christian mystic John. The grave religious powers that could be unleashed by breaking a seal are well illustrated by his book of Revelations, in which the breaking of the first four seals of a holy book release the Four Horsemen of the Apocalypse:

6:1 And I saw in the right hand of him that sat on the throne a book written within and on the backside, sealed with seven seals. 6:2 And I saw a strong angel proclaiming with a loud voice, Who is worthy to open the book, and to loose the seals thereof? …

A worthy deity is found, who starts breaking the seals and thereby loosing the Horsemen –

6:5 When he opened the third seal, I heard the third living creature saying, “Come and see!” And behold, a black horse, and he who sat on it had a balance in his hand. 6:6 I heard a voice in the midst of the four living creatures saying, “A choenix of wheat for a denarius, and three choenix of barley for a denarius! Don‘t damage the oil and the wine!”[3]

The Sumerians used thin wires and flat ingots of gold and silver, carefully weighed in balance scales, rather than coins like the Roman denarius. Except for paying the price in coins rather than coils, the commerce of the Third Horseman would have sounded quite familiar to our Sumerian merchant.

Wire ring and coil money, Sumeria, c. 2,500 B.C.

Clay Documents and Envelopes

The first documents ever written, in the 4th millennium B.C., were also about wheat and barley, and also sealed. Far earlier still, at least as far back as 8,000 B.C., archeologists have found even more alient artifacts – vast numbers of little clay tokens. In the first half of the 20th century archaeologists, looking for important artifacts of civilization like statues of gods and Moses-style law tablets, dismissed these tokens as some kind of trivia, probably game tokens or cheap unstrung beads. Now we know that these tokens led directly to what are now the very basics of our civilization – reading, writing, and arithmetic.

Recall our merchant, entrusting goods to sailors. Not all goods could be sealed in a jar or small room – a flock of sheep entrusted to shepherds, for instance. And in some cases it was expected that goods would be have to be opened en route – for example, to be audited by a customs inspector. For this reason, a separate record of the goods was needed. Without writing, how was such a record created?

Pebbles, shells, and other counters have long been used to count things. Without even knowing how to verbally count in order – some cultures do not have words for numbers above three – one can “count” objects by placing a pebble, on a pile or in a bag, one for each object. One nomadic tribe in Africa[4] counts cattle passing through a gate by drilling furrows. As each cattle paces, a pebble is placed in the rightmost furrow. When there are nine pebbles in this furrow, and the tenth cow goes through the gate, the pebbles are removed from the first furrow and a single is placed in the next furrow to the left. This is a “carry” operation, used in abacuses around the world and even used in modern computers. These nomads have, along with many other cultures, invented a kind of abacus, with a ones place, a tens place. A zero is simply an empty furrow. Many other cultures (though not this one) have taken this to the next step and used this abacus, in the form of pebbles on a board or beads strung on rods, to add, subtract, multiply, and perform other computations. Indeed, until the advent of our modern Arabic numbers, everywhere calculations were done by the abacus or fingers, not on paper.

Clay envelope and tokens, Sumer, c. 3,400 B.C.

In the ancient Middle East, these pebbles took the form of dried clay tokens. The clay was formed into pebbles of various shapes and sizes. Some represented sheep, some standard sized pots of barley, and so on. The number of kinds grew as commerce grew. Some represented one, five, or a dozen of the kind.

Soon after 4,000 B.C., the clay tokens were combined with the idea of sealing to create bills of lading and warehouse receipts. To create a bill of lading for a consignment of sheep, the owner put in a one-sheep token for every sheep. Every time he counted five sheep, a five-sheep token could be substituted for a one-sheep token. Once the owner and the consignee agreed on the count, the tokens were placed in a wet clay envelope. The owner and the consignee rolled their seals over the envelope, then let it dry. The procedure for a warehouse receipt was similar. An owner of wheat or barley could consign his fresh harvest to the protection of a warrior-priest in his walled fortress. The receipt was tokens sealed in an envelope – when the owner got hungry, or wanted to sell to the hungry, or wanted the seed to plant next spring – he would take the envelope to the warehouse. The claimant and the warehouse operator would inspect the seal, break it, inspect the tokens, and then deliver the goods.

It would be nice if one could learn the contents of the envelope – the number and kind of tokens – without having take the ominous and irreversible step of breaking the seal. Around 3,400 B.C. in Sumer, marks started appearing on the outside of these envelopes. These marks were simply made by the tokens themselves. The different shapes and sizes of the tokens created correspondingly unique impressions, and thus the same symbols.[4][5]. Such external marks weren‘t as secure – they could be erased, albeit not without detection by a well trained eye.

As warehouse receipts and bills of lading became common, commerce diversified. So many different kinds and numbers of goods were involved that the shapes and sizes of clay tokens were growing out of control. What computer scientists call a “level of indirection” was needed. With different tokens for one sheep, five sheep, one pot of barley, five pots of barley, and so forth, we get m*n different tokens, where m are the numerical denominations of the tokens and n are the number of different kinds of commodities. By creating separate tokens for the numbers and the goods, the number of different kinds of tokens were reduced to m + n, at the cost of up to twice as many tokens per envelope.

This development wasn‘t entirely new. Abstract counting tokens, reused for sheep and people and pots of barley, are probably far more ancient. Nor were separate words for “sheep”, and “barley” new. What was new were the separate tokens for “sheep”, “barley”, to be used, like the counting tokens, in the bills of lading and warehouse receipts. The were still thought of as corresponding to the objects they represented, not the words “sheep” and “barley”, but it was a big step towards written language. Naturally these symbols also became external marks[4][5].

The first written tablets, dating around 3,300 B.C. and again in Sumer, were simply these external marks, inscribed on clay tablets. To maintain the security properties of tokens in clay envelopes, some the tablets were themselves are sealed in clay envelopes.

The evolution of writing proceeded from there. A hundred years later reed styluses were being used to badly mimic the clay token marks. Over succeeding centuries, scribes supplemented or replaced token-derived symbols with pictographs for the objects. The pictographs attempted to bring to mind the object visually. Both kinds of symbols became stylized as wedges, or “cuneiform”, optimized for the reed stylus. Still later, words represented by neither pictographs nor token-derived symbols come to be represented by a rebus. An example of a rebus in English is representing the word “I” with a pictographic symbol for “eye”. This gave rise to a semi-phonetic alphabet. From this evolved the Phoenician or true phonetic alphabet, which was in turned borrowed by the Greeks and Romans. We use the Roman alphabet.

Tamper Evident Numbers

Evolving beyond clay tokens, accounting was the first use of the external marks and started to take a familiar form. Along with the tamper evident clay, the Sumerians developed a kind of virtual tamper evidence. It took the form of two sets of numbers. On the front of the tablet, each group of commodities would be recorded separately – For example on the front woudl be recorded 120 pots of wheat, 90 pots of barley, and 55 goats. On the reverse would simply be recorded “265” – the same objects counted gain, probably in a different order, and without bothering to categorize them. The scribe, or an auditor, would then verify that the sum was correct. If not, an error or fraud had occured. Note the similarity to tamper evident seals – if a seal is broken, this meant that error or fraud had occured. The breaker of the seals, or the scribe who recorded the wrong numbers, or the debtor who paid the wrong amounts of commodities would be called on the carpet to answer for his or her discrepancy.

Checksums still form the basis of modern accounting. Indeed, the principle of double entry bookeeping is based on two sets of independently derived numbers that must add up to the same number. Below, we will see that modern computers, using cryptographic methods, can now compute unspoofable checksums.

Modern Sealing

Breaking a seal still, but fortunately only quite rarely, can have implications that are apocalyptic – at least for the individuals involved. Tylenol in 1982 and 1986, Excedrin and Lipton Cup-A-Soup in 1986, Sudafed in 1991, and Goody's Headache Powder in 1992 all were tampered with by sickos who added cyanide to the product and killed people. This spurred a new emphasis on tamper evident plastic packaging which can now be found protecting a wide variety of the products we use.

Everybody is familiar with shrink-wrapped plastic, a less secure but commonly used technology – as common as the ubiquitous price tag. Another favorite tamper-evident device is the seal used to protect pill bottles.

Evidence bag. Courtesy Custom Specialties Inc. [no relationship to author].

Bank employees, our modern descendants of ancient temple accountant-priests, still sometimes work in edifices designed to look like Roman temples. They carry cash, checks, and other valuables in tamper-evident clear plastic envelopes. Evidence of tampering comes either as a tear in the plastic, or from opening the bag normally. In the latter case, a seal (the same place you'd find the zip seal on a Zip-Loc bag) chemically alters, and words such as “VOID” or “OPENED” appear in large letters. When these bags carry unique serial numbers, inspectors at both ends can record the serial number while examining the bag for tampering. The unique serial number prevents the tamperer from simply transferring the contents from one such bag to another. Modern plastic bags with the altering chemical seal, used in conjunction with the tracking of unique serial numbers, provide a very strong kind of tamper evidence, and are used by high security institutions ranging from banks to the military to cryptographic certificate authorities. The evidence bags used by many police departments work the same way.

Tamper evident tape on a cabinet door. Note the sequential number, which when recorded and checked detects the replacement of the original tape with a new one. (The security of the serial number assumes that this label is not easy to duplicate using a laser printer). On the right, the broken seal has left a difficult to remove mark including the word “tamper”. Courtesy tamper.com [no relationship to author].

Many other kinds of security, from ancient to modern, can be thought of as providing a kind of tamper evidence. Laser-break and glass-break sensors can make an entire building trespass evident. Similarly, guard dogs bark to protect their territories, alterting their masters to visitors.

One of the most high-tech kinds of security, cryptography, is no longer just secret writing, but has spawned a whole new family of mathematical functions to protect the integrity of digital data. These functions are quite analogous to the function of ancient seals.

One cryptographic function, the hash function, acts like the Sumerian checksum described above. The difference is that the “numbers” it adds up are the binary digits that make up text, images, or other data. A second difference is that, by using a one way function and very large numbers, it can make the checksum practically unspoofable. The way accountants normally use checksums, the fraudster can sometimes with some ingenuity guess what the input numbers are. With cryptographic hash functions, this is practically impossible for a human, and for a computer it would almost always take millions of years of brute-force guessing to reverse-engineer the checksum.

Another cryptographic protocol, the “digital signature”, resembles one of these ancient seals much more than it does a modern autograph. The protocol operates in two steps. In the first step, a piece of data is sealed using a hash function as describe above. This is analogous to surrounding a basket lid with clay. Then a reverse public key cryptography operation (mathematically equivalent to decrypting a message) is performed. This second step is analogous to rolling the cylinder on the seal to identify the sealer.

The digital signature can be made only by the possessor of a private key just as a seal could be made only by the possessor of the unique seal carving. If the digital signature is bad, this provides evidence that the data was tampered with or the signature forged.

References

Acknowledgements

My thanks to Andrew Odlyzko and K. Eric Drexler for their insightful comments.

Originally published on Nick Szabo’s Papers and Concise Tutorials.

Nick Szabo Originally published in 1997

A crucial issue in transaction costs economics

Introduction

An acquaintance does you a favor. How can you pay her back and deepen the relationship? An investor examines the balance sheet of a company. What do the numbers mean? Are they even trustworthy? A judge must decide on an award for damages done to a plaintiff. What amount of money, if any, fairly compensates for the plaintiff's suffering?

A wide variety of human relationships and institutions, from the most friendly to the most antagonistic, must tackle the thorny problem of value: how can we securely distinguish, using the inputs of our fallible senses, that which we value from that which we do not? How can we figure out what another person values? Money, wage labor, markets, and many other economic institutions take the forms they do primarily because they solve problems of measuring value. Such questions also lie at the heart of the current crisis in accounting.

Questions of value are inherently subjective and personal. Value is very different from the objective phenomena of physics, chemistry, and the like. Societies have evolved institutions such as firms and competitive markets to set prices, legal precedents and judicial proceedings to make judgments, and so forth. These institutions in turn often rely on answering the second question, the topic of our essay – how can we securely determine value from what we observe? We will examine tax collection as an antagonistic instance of the measurement problem. The last section of this essay will focus on a particular institution developed to measure value – accounting – and suggest how it might rise to challenge the radical changes underway in our services and information economies.

Economic Relationships

In the nineteenth century economists developed a theory of perfectly competitive commodity markets (often now called the "neoclassical model"). This is the source of supply and demand curves, for example. In the ideal market, supply balances demand resulting in a price that incorporates all the relevant skills and preferences of the market's participants. In such a market, this balance between skills needed to create a commodity and the preferences for that commodity constitute the value of that commodity – we can measure value by the equilibrium market price. Some modern markets, especially well known ones such as the commodity futures markets, approach this ideal in practice. However, many other institutions, such as the hierarchical firm, operate in very different ways. And modern markets are mostly quite recent in origin. Even today most human economic relationships, such as those that occur within a firm, are far from this ideal.

In the competitive market, one commodity is traded for another. (Money is just a particularly interesting kind of commodity). In order for this market to work – in order for prices to accurately communicate value – first the participants must be able to measure the value of the two commodities traded. Indeed, that's the main property that distinguishes a commodity from a less economically tractable good or service – the ability of parties to measure its value – the ability of parties to observe properties of a good or service, matching what they observe against their private preferences, and making sure this process isn't spoofed by wily traders.

The competitive market model was so successful that modern economists are now approaching other economic institutions that we take for granted – such as the firm – and asking why they exist at all! They are working backwards from a very clear theory of competitive markets to explain the wide variety of other kinds of economic relationships, usually formalized by property rights and contracts, that we enter into. This school is most widely known as the "transaction cost" school of economics. Often it is referred to as "new institutional", or "property rights school." The idea of transaction costs was developed by Nobel prize winning economist Ronald Coase. His brilliant heirs include Oliver Hart and Oliver Williamson, along with Steve Cheung, Yoram Barzel, Armen Alchian, Harold Demsetz, Janet Landa, Robert Ellickson, and many others.

By comparing a wide variety of contractual forms to the ideal commodity market, and by re-using many of the same assumptions used by neoclassical economists – individuals with rational self-interest, unique preferences, and unique skills – we are better understanding these other economic institutions. Modern economies contain a wide variety of commercial institutions, from hierarchically commanded firms on the one hand to freely competitive commodity markets on the other. In between are a wide variety of institutions and the contracts that formalize them.

When somebody starts a new company rather than hiring on as an employee at a current one, we can think of this decision as a "vote" that the economy needs more market relationships and less employee-employer relationships. Contrariwise, when one firm buys out another, they are implicitly betting that the economy needs less market and more firm. Socialists, seeing the trends of integration and economies of scale in industrial capitalism, thought the world would end up as one big firm, and decided this firm should be run by the government. That worked out horribly. Others have idealized a world in which there are no firms – everybody is a private contractor, selling their services to other individuals. In many industries that's a non-starter as well. Oliver Williamson and other economists have studied many of these forms and come up with some criteria that make competitive commodity markets less than perfect, causing other contractual forms to be used. (Here "contractual form" is shorthand for a certain kind business relationship – employment, franchising, commodity exchange, etc. The contract used by the parties is usually the most formal and complete description of their relationship, as well as the "security protocol" that defines the basic rules of the relationship).

These economists have identified a number of limitations of ideal commodity exchange that often cause other contractual forms to be used instead. These include:

Security costs. Other kinds of transaction costs are incurred from parties that are opportunistic – they are self-interested, but they follow the letter if not necessarily the spirit of the rules of a relationship (whether these rules are legal, contractual, or informal). Security costs are incurred from, or to protect a relationship against, parties that are outright malicious – they might break any of the rules, use threats of force, or actually carry out acts of trespass, theft, or violence, in order to satisfy their (alas, not so rare) coercive kinds of preferences. Rule incompleteness – the difficulty for parties to anticipate all contingencies that might occur in a relationship, and thus the inability to plan for them with rules (for example, by terms in a contract). Most disputes that go to court, and most interesting new legal precedents, occur over situations that the parties entering into a relationship didn't foresee well enough to deal with up front. Exit costs and/or investments that are specific to a particular relationship. For example, when you take a class to learn how to use Windows or Word, you are investing in a relationship with Microsoft. Another example is when a railroad is built to a coal mine – the railroad now depends on the mine for business, and the mine operator depends on the railroad to ship his coal. A third example is the layout on a factory floor, where the results of one machine's operation feed into another specific machine. The most common examples are employees developing relationships and learning skills that are specific to a particular job. In these kinds relationships with high investments or exit costs, without good contractual safeguards you can end up stuck in a bad relationship – even if it goes sour, the other guy cheats on you, it may be too expensive to exit the relationship, or you may lose your investment. When there is both lack of ability to specify rules and relationship specific investments, the result is often vertical integration into a single firm. The coal mine might buy the railroad, the machine operations occur on a factory floor owned by a single company, and so on. On the other hand, a firm has diseconomies of scale due to the increasing inability to match preferences to skills in larger firms. As Friedrich Hayek pointed out, diseconomies of scale in the distribution of knowledge about skills and preferences are a big reason why socialism works so much more poorly than market economies. More generally, these diseconomies limit firm size. Certain innovations (such as in accounting at the beginning of the industrial revolution, or in supply chain management in the last two decades) have improved the reliable distribution of knowledge within a firm and thereby allowed firms to grow larger. Innovations that better cover contingencies or reduce the need for relationship specific investments and exit costs can disadvantage larger firms and advantage a larger number of smaller firms. Rather than an commodity market often a contractual form intermediate between a market and a firm, such as a franchise, is used. A franchise is a long term contract that, roughly speaking, specifies many basic rules for operating a business but leaves temporary or unique problems to the discretion of the local operator. We will shortly turn to perhaps the most important kind of transaction cost, the measurement of value, the main subject of our essay.

Before we do that, however, let us note that these kinds of transaction costs, while first studied in the context of markets, are not confined to markets or even market-embedded institutions. They occur any time a good is transferred or a service rendered according to a set of rules or customs, however simple or complicated. Not only do these transaction costs provide a basis for comparing non-market or extra-market institutions such as the firm to the market; they also apply to a wide variety of other institutions, including many we may not typically think of as economic institutions. So, for example, the ancient institutions of inheritance, marriage, tribute, tax collection, and tort law all involved an important component of wealth transfer. All are subject to the main kinds of transaction costs outlined here – including that of our main topic.

Measurement of Value

The measurement problem is very broad. It comes into play in any system of exchange – reciprocation of favors, barter, money, credit, employment, or purchase in a market. It is important in extortion, taxation, tribute, and the setting of judicial penalties. It is even important in reciprocal altruism in animals. Consider monkeys exchanging favors – say pieces of fruit for back scratches. Mutual grooming can remove ticks and fleas that an individual can't see or reach. But just how much grooming versus how many pieces of fruit constitutes a reciprocation that both sides will consider to be "fair", or in other words not a defection? Is twenty minutes of back-scratching worth one piece of fruit or two? And how big a piece? And just how long is twenty minutes anyway? In some cases this is relatively easy to solve, as with the delayed barter of blood for blood in vampire bats. These bats can come home from a hunting mission either overstuffed or starving. Overstuffed bats can regurgitate blood to feed hungry ones. The grateful recipient can remember the favor an return it in a future hunting trip when the tables might be turned. And indeed, some degree of reciprocal trade takes place between vampire bats, even among non-kin.

Even this simple case of trading blood for blood, is, however, far more complicated then it seems. Just how do the bats estimate the value of blood they have received? Do they estimate the value of a favor by weight, by bulk, by taste, by its ability to satiate hunger, or other variables? Just the same, measurement complications arise even in the simple monkey exchange of "you scratch my back and I'll scratch yours".

For the vast majority of potential exchanges, the measurement problem is intractable for animals. Even more than the easier problem of remembering faces and matching them to favors, the ability of both parties to agree with sufficient accuracy on an estimate of the value of a favor in the first place is probably the main barrier to reciprocal altruism among animals.

It is also likely the most important barrier to exchange among humans. Many kinds of exchange, probably many more than most economists perceive, are rendered infeasible by the inability of one or both parties to the exchange to estimate its value. For most of human history, most kinds of markets that are possible today were not then feasible, in large part due to the inability of potential market participants to measure value: to estimate the value of the transaction to themselves and then use these estimates to discover and agree on a common objective measurement. Measurement of value was and is also important to the development of many economic institutions related to markets. Accounting, which we will examine below, was crucial to the development of large companies and modern systems of taxation.

The process of determining the value of a product from observations is necessarily incomplete and costly. For example, a shopper can see that an apple is shiny red. This has some correlation to its tastiness (the quality a typical shopper actually wants from an apple), but it's hardly perfect. The apple's appearance is not a complete indicator – an apple sometimes has a rotten spot down inside even if the surface is perfectly shiny and red. We call an indirect measure of value – for example the shininess, redness, or weight of the apple – a proxy measure. In fact, all measures of value, besides prices in an ideal market, are proxy measures – real value is subjective and largely tacit.

Such observations also come at a cost. It may take some time to sort through apples to find the shiniest and reddest ones, and meanwhile the shopper bruises the other apples. It costs the vendor to put on a fake shiny gloss of wax, and it costs the shopper because he may be fooled by the wax, and because he has to eat wax with his apple. Sometimes these measurement costs comes about just from the imperfection of honest communication. In other cases, such as waxing the apple, the cost occurs because rationally self-interested parties play games with the observable.

Measures are critical components of institutions – such as auctions, contracts, accounting systems, legal damage rules, tax rules, etc. – that align incentives between parties who, prior to participating in the institution, have incompatible incentives. We can divide the measurement problem into two components – the first, choosing the phenomena and units that will be measured, and second, measuring those attributes in a way that minimizes spoofing of the measure between parties whose incentives with respect to the value are misaligned.

Cost can usually be measured far more objectively than value. As a result, the most common proxy measures are various kinds of costs. Examples include:

Paying for employment in terms of time worked, rather than by quantity produced (piece rates) or other possible measures. Time measures sacrifice, i.e. the cost of opportunities foregone by the employee. Most numbers recorded and reported by accountants for assets are costs rather than market prices expected to be recovered by the sale of assets. Non-fiat money and collectibles obtain their value primarily from their scarcity, i.e. their cost of replacement.

We now look at a particularly challenging set of measurement problems – those faced by a tax collector. Taxation being the least cooperative kind of economic relationship – the incentives between the parties being the most misaligned – the measurement game played between the parties takes its most serious form.

The Tax Collector's Problem

Tax collection is the most efficient department of government. Its efficiency rivals that of many private sector institutions.

From the point of view of many taxpayers this is an incredible claim, given that tax collectors take money we ourselves know how to spend quite well, thank you, and often spend it on amazingly wasteful activities. And the rules by which they take it often seem quite arbitrary. Tax rules are usually complex but nevertheless fail to let us account for many events important to the earning of our incomes that differentiate us from other taxpayers.

How the money gets spent is outside the scope of the claim that tax collectors are uncommonly efficient. It is the collection process itself that is the subject of that claim, and the tax collection rules. This essay will demonstrate the efficiency of tax collector's rules by two arguments:

First, we will show why tax collectors have an incentive to be efficient (and what "efficiency" means in this context) Second, we will explore the problem of creating tax rules, and see how the difficulty of measuring value rears its ugly head. Tax rules solve the value measurement problem through brilliant, often very non-obvious solutions similar to solutions developed in the private and legal sectors. Often (as, for example, with accounting) tax collectors share solutions used to measure value in private relationships (such as the absentee investor-management relationship in joint stock corporations). It is in making these very difficult and nonintuitive trade-offs, and then executing them in a series of queries, audits, and collection actions, that tax collectors efficiently optimize their revenue, even if the results seem quite wasteful to the taxpayer.

The tax collector's incentives are aligned with the other branches of their government in a task that benefits all associated with the government, namely the collection of their revenue. No organization of any type collects more revenue with fewer expenditures than tax collection agencies. Of course, they have the advantage of coercion, but they must overcome measurement problems that are often the same as other users of accounting systems, such as owners of large companies. It is not surprising, then, that tax collectors have sometimes pioneered value measurement techniques, and often have been the first to bring them into large scale use.

Like other kinds of auditors, the tax collector's measurement problem is tougher than it looks. Investment manager Terry Coxon has described it well[6]. Bad measures or inaccurate measurements allow some industries to understate their income, while forcing others to pay taxes on income they haven't really earned. Coxon describes the result: the industries that are hurt tend to shrink. The industries that benefit pay fewer taxes than could be extracted. In both cases, less revenue is generated for the tax man than he might be able to get with better rules.

This is an application of the Laffer curve to the fortunes of specific industries. On this curve, developed by the brilliant economist Arthur Laffer, as the tax rate increases, the amount of revenue increases, but at an increasingly slower rate than the tax rate, due to increased avoidance, evasion, and most of all disincentive to engage in the taxed activity. At a certain rate due to these reasons tax revenues are optimized. Hiking the tax rate beyond the Laffer optimum results in lower rather than higher revenues for the government. Ironically, the Laffer curve was used by advocates for lower taxes, even though it is a theory of tax collection optimum to government revenue, not a theory of tax collection optimal to social welfare or individual preference satisfaction.

On a larger scale, the Laffer curve may be the most important economic law of political history. Adams[1] uses it to explain the rise and fall of empires. The most successful governments have been implicitly guided by their own incentives – both their short-term desire for revenue and their long-term success against other governments – to optimize their revenues according to the Laffer Curve. Governments that overburdened their taxpayers, such as the Soviet Union and later Roman Empire, ended up on the dust-heap of history, while governments that collected below the optimum were often conquered by their better-funded neighbors. Democratic governments may maintain high tax revenues over historical time by more peaceful means than conquering underfunded states. They are the first states in history with tax revenues so high relative to external threats that they have the luxury of spending most of the money in non-military areas. Their tax regimes have operated closer to the Laffer optimum than those of most previous kinds of governments. (Alternatively, this luxury may be made possible by the efficiency of nuclear weapons in deterring attack rather than the increased incentives of democracies to optimize to tax collection).

When we apply the Laffer curve to examining the relative impact of tax rules on various industries, we conclude that the desire to optimize tax revenues causes tax collectors to want to accurately measure the income or wealth being taxed. Measuring value is crucial to determining the taxpayer's incentives to avoid or evade the tax or opt out of the taxed activity. For their part, taxpayers can and do spoof these measurements in various ways. Most tax shelter schemes, for example, are based on the taxpayer minimizing reported value while optimizing actual, private value. Tax collection involves a measurement game with unaligned incentives, similar to but even more severe than measurement games between owner and employee, investor and management, store and shopper, and plaintiff-defendant (or judge-guilty party).

As with accounting rules, legal damage rules, or contractual terms, the choice of tax rules involves trading off complexity (or, more generally, the costs of measurement) for more accurate measures of value. And worst of all, as with the other rule-making problems, rule choices ultimately ground out on subjective measures of value. Thus a vast number of cases are left where the tax code is unfair or can be avoided. Since tax collectors are not mind readers, tax rules and judgments must substitute for actual subjective values its judgments of what the “reasonable” or “average” person's preferences would be in the situation. Coxon provides the following example. Imagine that we wanted to optimize the personal income tax rules to measure income as accurately as possible. We might start reasoning along these lines:

... look a little closer and you find that an individual incurs costs and expenses in earning a salary. He has to pay for transportation to and from work. He may spend money on clothes he wouldn't otherwise buy and on lunches that would cost less at home. And he may have spent thousands of dollars acquiring the skills and knowledge he uses in this work. Ideal, precise rules for measuring his income would, somehow, take all these and other costs into account. The rules would deduct the cost of commuting (unless he enjoys traveling about town early in the morning and later in the afternoon). They would deduct the cost of the clothes he wouldn't otherwise pay (to the extent it exceeds the cost of the clothes he would buy anyway). They would deduct the difference between the cost of eating lunch at work and the cost of lunch at home (unless he would eat lunch out anyway). And each year these ideal rules would deduct a portion of the cost of his education (unless he didn't learn anything useful in school or had enough fun to offset the cost).

Because there are limits to complexity, and

because tax agents can't read minds, the government gives them arbitrary rules to follow: no deductions are allowed for commuting expenses, for clothing that is suitable for wearing outside of work, for lunches that aren't part of the “business entertainment” or for the cost of acquiring the skills a job requires (although you can deduct the cost of improving your skills).

The resulting rules often seem arbitrary, but they are not. They are trade-offs, often non-obvious but brilliant, between the costs of measuring more value with greater accuracy and extra revenue extracted thereby. However, the value measurement problem is hardly unique to tax collection. It is endemic when assessing damages in contract and tort law, and when devising fines punishments in administrative and criminal law. Many private sector rules found in contracts, accounting, and other institutions also have the quality that they use highly non-obvious measures of value that turn out, upon close examination, to be brilliant solutions to seemingly intractable problems of mind-reading and the unacceptable complexity of covering all cases or contingencies. Such measurement problems occur in every kind of economic system or relationship. The best solutions civilization has developed to solve them are in most institutions brilliant but highly imperfect. There is vast room for improvement, but failed large-scale experiments in attempts to improve these measures can be devastating.

The Laffer curve and measurement costs can also be used to analyze the relative benefits of various tax collection schemes to government. Prior to the industrial revolution, for example, the income tax was infeasible. Most taxes were on the prices of commodities sold, or on various ad-hoc measures of wealth such as the frontage of one's house. (This measurement game resulted in the very tall and deep but narrow houses that can still be found in some European cities such as Amsterdam. The stairs are so narrow that even normal furniture has to be hauled up to the upper story and then through a window with a small crane, itself a common feature on these houses).



Taxes distorted the economy of the Netherlands – quite literally. Here are some houses in Amsterdam built in the 17th and 18th centuries, and a typical narrow staircase. Furniture and other large objects must be hauled up by the small cranes seen above the top-story windows.

Prior to the industrial revolution, incomes were often a very private matter. However, starting in England in the early nineteenth century, large firms grew to an increasing proportion of the economy. Broadly speaking, large firms and joint-stock companies were made possible by two phases of accounting advances. The first phase, double-entry bookkeeping, was developed for the trading banks and "super companies" of early fourteenth century Italy. The second phase were accounting and reporting techniques developed for the larger joint stock companies of the Netherlands and England, starting with the India companies in the seventeenth century. Accounting allowed manager-owners to keep track of employees and (in the second phase) for non-management owners to keep track of managers. These accounting techniques, along with the rise of literacy and numeracy among the workers, provided a new way for tax collectors to measure value. Once these larger companies came to handle a sufficient fraction of an jurisdiction's value of transactions, it was rational for governments to take advantage of their measurement techniques, and they did so – the result being the most lucrative tax scheme ever, the income tax.

While the incentives between investors and managers of public companies are not as badly misaligned as that between tax collector and taxpayer, the incentives to play games with measurements are still quite substantial. Let's now look at the challenges that investors, playing an accounting game with management, face as we move beyond the industrial era.

Intangible Assets on Financial Statements

Intangible assets – in the form of trade secrets, intellectual property, brands, human resources, and so on – have become more valuable than tangible assets to many of today's businesses. In business in general, and accounting in particular, it is common to use cost as a proxy measure for value. Indeed, while the actual economic value of an asset is the discounted value of expected future cash flows, most assets are assigned a value based on their costs rather than their expected future cash flow stream.

This usually works because (a) costs are usually based on verifiable events which can be signed off on and audited, whereas predictions of cash flow are mere speculations about the future, (b) under most conditions we expect that managers have acted rationally, expending money only where they expect, on average, an eventual greater return, and (c) skilled readers of financial statements have learned from experience what games can be played by managers (because their incentives differ from other stakeholders), and to detect signs that managers have acted irrationally (e.g. over or under investment in particular assets).

Thus, accounting numbers for tangible assets have never been take too literally or in isolation by skilled readers of financial statements. Indeed, the seeming concreteness of tangibles can be quite misleading. A skilled reader knows that most accounting numbers represent costs not value, and apply their knowledge of the industry to determine for themselves how well value may actually be estimated by these costs. For example, a naive reader will take current assets at face value, whereas a skilled reader will look for conditions such as abnormal growth of inventory or receivables. The actual function of a financial statement is to provide clues for analysts based on well-verified facts, not to provide pat final answers for those seeking to evaluate a company.

Some objections to including intangibles on the balance sheet are invalid. For example, it is argued that internally generated intangibles cannot be valued because they have not been purchased on the market. However, this is also often the case for unique industrial investments and inventories. We have developed methods such as specific identification to value internally generated assets, and these could be applied to internally generated intangibles as well. Allocation of costs common to several intangible assets (e.g. a software library used in two different software products) can be based on long experience allocating costs common to multiple tangible assets.

Another more valid objection is that the actual value, in expected cash flow, of intangibles is far more uncertain than for most physical assets. Thus, the mapping from cost to value is far more uncertain. This mapping can be done with greater certainty only over an aggregate of diverse investments. However, there are certain kinds of physical assets whose value is also highly uncertain, yet are assigned a value based on costs. Rational managers discounted their original investments to take into account such risks. The same is true for intangible assets. Skilled readers of financial statements know when to expect high uncertainty. Often they will demand further details from management about the specific investments. Providing greater detail where intangibles are involved is highly advisable, a point I return to below.

On the other hand, many proposed measures of intangible value are non-starters for the purposes of accounting or financial statements. For example, various measures have been put forth allegedly related to expected cash flows (e.g. measuring web site hits, customer retention rates, etc. to try to estimate the value of a brand). The only time expected value rather than cost is used on a balance sheet for tangibles is when the asset can be currently priced on an efficient, competitive, and public market. (For example, inventories of publically traded commodities can be valued in this manner). Otherwise, it is far better to use cost, the actual event of expenditure, and let the skilled readers of the financial statement interpret these numbers properly.

Here are some specific comments and proposals for specific kinds of intangible assets:

Patents and Copyrights

A company owns these legal rights in all developed and most undeveloped economies. Copyrights are very well defined but in some cases very difficult for the company or the state to actually control. Patents can be very ill defined, so that the occurrence of a loss of rights over the actual technology is unclear. However, presumably managers discount their original investments to take into account such risks. Thus, if costs can be allocated to particular patents and copyrights, they constitute a proxy measure for the value of patented and copyrighted assets. This is quite similar to using the cost of a physical asset, whose eventual cash flow value is highly uncertain, to value that asset, and allowing the skilled reader to interpret the resulting number properly.

Brands

A company owns legal rights to its trademark in all developed and most undeveloped economies. Companies further have some control over perception in people's minds, insofar as their observable actions influence this perception. Some major brands names have shown a very persistent value, while lesser ones are more likely to be forgotten. One can map current accounting treatments for investment in, maintenance of, and depreciation of physical assets to investment in and maintance of a brand, as well as the tendency of customers to forget over time a brand that is not maintained.

Human Resources

Employees are not owned, but the labor market is not perfectly fungible. There is some stickiness to it. Indeed, this stickiness can be measured by the turnover rate for the company. The turnover rate, a quite auditable number, may provide an excellent way to depreciate an asset defined by the costs of hiring and training.

Final Comment on Intangibles

Until long experience is gained by stakeholders with particular kinds of intangible investments, the ability to judge whether costs are rational, and satisfy the interests of stakeholders besides management, will be poor. A wide variety of reporting experiments, most of which will fail, are nevertheless essential to achieving more accurate reporting of asset values to stakeholders. Interpretation of intangible-heavy financial statements is a job for skilled analysts, not casual readers. For the expert more information is better – the detailed records of expenditures and their allocation to intangible assets are more important to the skilled stakeholder than the summary totals. Such detailed records should be released to stakeholders despite objections about confidentiality. Only long experience with these details will teach stakeholders whether and how to judge summary totals involving intangibles.

Conclusion

The measurement of value is one of the most intractable problems of civilization. Brilliant and highly non-obvious solutions to this problem – from markets to money to the time-wage to cost accounting – have constituted some of the most important steps from animal to civilization. Historically, the solutions to one value measurement problem (e.g., accounting for value in a large firm) made possible other institutions as well (e.g. income tax, which must first solve the same kind of problem in order to be Laffer competitive with other kinds of taxation). Intangible asset accounting may now be the most important value measurement problem we face as we move beyond the era where tangible industrial commodities dominated the economy.

Bibliography

(under construction)Intrapolynomial Cryptography

Nick Szabo 1999



Researchers have proposed a variety of “client puzzle” or “busy-work” proposals like hashcash, MicroMint, bit gold, and compute-cost postage to create independent currencies or make spamming costly. The mathematical implication of these proposals is that there is such a thing as intrapolynomial cryptography. Four motivations for intrapolynomial cryptography theory are (a) novel constructions such the aforementioned applications, (b) more accurate estimation of the computational cost of cracking a cipher, (c) it might be easier to prove lower bounds, rather than just conjecture them as is the case with superpolynomial (standard) cryptography, and (d) if there do not exist one-way functions, standard cryptography is intrapolynomial rather than superpolynomial.

I propose the following formalization:

f: {0,1}* --> {0,1}* is called a strong k-benchmark function for machine model M and k>=1 if the following hold: 1. f is computable in O(p(n)) time on M, where p is a polynomial. 2. f does not shrink the input more than q(n,k), where q(n,k) is a polynomial of degree k. 3. For every randomized algorithm A running on M in time less than q(n,k)p(n), there exists an N such that for n > N Pr[A(f(x)) = f^-1(f(x))] < 1/q(n,k)p(n)

In other words, there is no algorithm running faster than q(n,k)p(n) which can invert f for more than a negligibly small number of values.

One can similarly define average-case, best-case, and worst-case k-degree benchmark functions, analogously to one-way functions. Open question (analogous to the open question in superpolynomial cryptography of whether one-way functions exist): can one prove (3) as lower and upper bounds for some function and k>=1 on some realizable machine model such as RAM-log?

Strong and average case are most apropos to cryptography related applications. Unfortunately for these purposes we'd also need:

a list of machine models which is comprehensive of all physically realizable machines, in the sense that any such machine can be simulated with a very small overhead, such as constant or O(log(n)), by some model on the list, and to prove lower bounds on a benchmark function for all models on the list

Since this is at least very tedious, one hopes we can in practice get away with a short list which covers all plausibly implemented machine architectures. This might work where for example the total exposure from cracking a protocol is less than the R&D costs of designing and building a novel machine architecture to defeat it. Cryptanalyis would include discovering the machine architectures optimal for breaking an intrapolynomial cipher.

There are at least two practical implications of the above analysis. One is that there is very little room for error in the analysis and implementation of compute-cost postage, hashcash, bit gold, MicroMint, and other such intrapolynomial cryptography schemes. Another is that, unless the opponent has a very low budget and is thus limited to standard personal computers, it does not make sense to analyze the security or cost of these schemes without reference to machine architecture. For example, spammers may be able to defeat compute-cost postage by using custom chips optimized for computing the particular puzzle function.Smart Contracts Glossary

Nick Szabo Originally published in 1995

Agent: A person or organization, usually represented by a true name or nym. Also, a computer program controlled by, and acting on behalf of, an agent. More generally, a combination of a nym with a persistent pattern of behavior, upon which can be based a reputation. Note that this differs from the legal and business definitions of"agent", but corresponds more closely to the economics and computer science uses of the term.

Contract: A set of agreements or promises between agents.

Parties (aka Principals): Agents who have agreed to the contracting question.

Third Parties: Agents who have not agreed to the contract in question.

Performance: Carrying out the promises specified in a contract.

Contractual Security: A paradigm for making security arrangements between organizations, based on two claims: (1) the primary goal of inter-organization security is to protect and enforce the performance of contracts, and (2) where this goal is achieved, dependence on reputation, outside enforcement, and other factors for the secure performance of that organization's contracts is minimized.

Contractual Key Distribution: a paradigm for distributing keys among individuals and organizations, in which the key distribution and certificate structure reflects the contractual arrangements between parties.

Protocol: A sequence of messages between multiple agents.

Smart contract: A set of promises, including protocols within which the parties perform on the other promises. The protocols are usually implemented with programs on a computer network, orin other forms of digital electronics, thus these contracts are "smarter" than their paper-based ancestors. No use of artificial intelligence is implied.

Alice and Bob: Our exemplar parties to a smart contract.

Eve: Our exemplar eavesdropper, whose objective is to find out valuable information about about a contract and its performance without being a party to that contract.

Mallet: Our exemplar active attacker. His objective might either be stealing something of value involved in the performance of a smart contract, or denying it to the parties to the contract. He might either be an economically rational agent, out for pure personal gain,or Byzantine, a worst-case attacker who inflicts the greatest possible damage on one or more of the parties regardless of personal loss.

Mediator: A third party involved realtime in the protocols between smart contract parties, trusted with some of the contents and/or performance of that contract.

Arbitrator: A third party trusted with some of the contents,and some of the history of performance, of a contract, and trusted by contracted parties to resolve disputes arising from that contract fairly.

Unbundling: The principle of distribution of trust. Unbundling of mediation and arbitration functions separates tasks, spreads risk, minimizes vulnerability, and reduces linkability, but often at the cost of greater complexity.

Enemy (aka attacker): An agent whose preferences could cause another agent harm; a third party who influences performance of a contract to the detriment of one or both parties.

Object: Herein used to refer generically to any kind of digital data, which could be a key, a credential, a contract, a program, or a wide variety of other things.

Credential: A claim made by one agent about another.

Positive credential: A claim made about an agent, that the agent would prefer to reveal, such as a degree from a prestigious school.

Negative credential: A claim made about an agent, that the agent would prefer not to reveal, such as a bad credit rating.

Cryptographic protocol: A protocol that uses mathematical principles and keys to accomplish smart contract objectives.

Privity: The principle that only the parties to a contract, including its designated arbitrators, need to have knowledge of or control over the contents and performance of that contract. Privity as an objective of smart contract is a generalization of the legal principle of privity. It formalizes the tradition of "it's none of your business". Attacks against privity are epitomized by Eve the eavesdropper, a passive observer of contents or performance, and malicious vandal Mallet, who actively interferes with performance or steals value. Privacy and confidentiality, or protecting the value of information about a contract, its parties, and its performance from Eve, is thus subsumed under privity. Privity often comes into conflict with observability and verifiability.

Observability: The ability of the parties to a contract to observe each other's performance of that contract, or to prove their performance to the other party. Also, the ability to differentiate between intentional violations of the contract and good faith errors. An important objective of smart contract design that often comes into conflict with privity.

Verifiability: The ability of a party to prove to an arbitrator that a contract has been performed or breached, and to differentiate between intentional violation and good faith errors. An important objective of smart contract design that often comes into conflict with privity.

Reputable name: A nym or true name that has a good reputation, usually because it carries many positive credentials, has a good credit rating, or is otherwise highly regarded. Companies strive to carry reputable brand names, while professionals such as doctors and lawyers strive to have many good personal recommendations of their name. Reputable names can be difficult to transfer between agents, because reputation assumes persistence of behavior, but such transfer can sometimes occur (for example, the sale of brand names between companies).

True name: An identifier that links many different kinds of information about an agent, such as a full birth name or social security number. As in magick, knowing a true name can confer tremendous power to one's enemies. It also can have major economic value among those who cooperate peacefully, as in the use of direct marketing to target product information to those agents most likely to be interested in those particular products.

Mix: A cryptographic protocol for messaging, in which analysis of who is talking to whom (traffic analysis) by Eve is prevented by the Russian-doll encryption of the message by the sender with the public keys of each mix operator in the chain, and the mixing of messages by each operator, so that panoptic wiretapper Eve loses track of the messages. Only 1 out of N of the operators needs to be trusted with the traffic information, although Eve can sometimes gather statistics over large numbers of messages to eventually guess who is talking to whom. The communicating parties can also be mutually anonymous, and with normal encryption need trust no other parties with the content of messages. Confidential messaging is necessary for the some of the privity features of Chaumian credentials and bearer securities to be strongly implemented on an actual network. Another confidential messaging system is the "Dining Cryptographers" net, also invented by Chaum.

Nym: An identifier that links only a small amount of related information about a person, usually that information deemed by the nym holder to be relevant to a particular organization or community. Examples of nyms include electronic bulletin board nicknames, pen names, aliases, and brand names. A nym may gain reputation within its community. For example, a conglomerate may sell a wide variety of brand names, each reputable in its own market niche. With Chaumian credentials, a nym can take advantage of the positive credentials of the holder's other nyms, as provably linked by the is-a-person credential.

Name space: a set of short identifiers with a simple syntax, such as telephone numbers, computer-readable Internet address numbers, human-readable Internet domain names, etc.

Chaumian credentials: a cryptographic protocol for proving one possesses claims made about oneself by other nyms, without revealing linkages between those nyms.

Is-a-person credential: In Chaumian credentials, the true name credential, used to prove the linkage of otherwise unlinkable nyms, and to prevent the transfer of nyms between agents.

Key: A focus of obscurity and control; a random number drawn from a name space so large that a lucky guess is vastly improbable. The public key half of an assymetric key pair can also act as a nym.

Biometric: Information pattern used to identify a particular body, such as a fingerprint, autograph, retina scan, password, etc.

Authentication: Proof that one is communicating with an agent that possesses a particular key.

Secret key (symmetric) cryptography: Uses a key shared between agents to communicate with confidentiality and authentication.

Public key (assymmetric) cryptography: Uses two keys, the private key and the public key. The public key is used to encrypt objects,and to verify digital signatures. The private key is used to to decrypt and sign objects, and is typically kept secret by one or more key holders. Allows key distribution without exposing the key.

Secret sharing: method of splitting a key (and thus, in effect,any object encrypted with that key) into N parts, of which onlyM are needed to recreate the key, but less than M of the parts provide no information about the key. A potent tool for distributing control over objects between agents.

Digital signature: Cryptographic protocol, based on public key cryptography, that proves that an object was in active contact with the private key corresponding to the signature: the object was actively "signed" with that key. Probably should have been called a "digital stamp" or "digital seal" since its function resembles more those methods than an autograph.

Bit commitment: A variant of digital signatures, used to commit an object, such as a promise or prediction, without revealing that object until later. It is impossible to unobservably violate the protocol, or to modify the object after it has been committed.

Blind signature: digital signature and secret-key encryption protocols that together have the mathematical property of commutativity, so that they can be stripped in reverse of the order they were applied. The effect is that Bob "signs" an object, for which he can verify its general form, but cannot see its specific content. Typically the key of the signature defines the meaning of the signed object, rather than the contents of the object signed, so that Bob doesn't end up signing a blank check. Used in digital bearer instruments, where Bob is the clearing agent, and Chaumian credentials, where Bob is the credential issuer.

Digital bearer instruments: Objects identified by a unique key,and issued, cleared, and redeemed by a clearing agent. When an the object is transferred, the transferee can request the clearing agent to verify that the key has never before been cleared, and issue a new key. The clearing agent prevents multiple clearing of particular objects, but can be prevented from linking particular objects one or both of the clearing nyms who transferred that object. These instruments come in an "online" variety, cleared during every transfer, and thus both verifiable and observable, and an "offline" variety, which can be transferred without being cleared, but is only verifiable when finally cleared, by revealing any the clearing nym of any intermediate holder who transferred the object multiple times (a breach of contract). Privacy from the clearing agent can take the form of transferree-unlinkability, transferrer-unlinkability, or "double blinded" where both transferrer and transferee are unlinkable by the clearing agent. Digital cash is a popular form of digital bearer instrument.

Locality:

immediacy, such as that provided by online clearing of digital bearer instruments

dealing with the agents one knows best

dealing in one's area of specialty

Hot Backup: A backup service which comes online upon failure of the current service. Usually triggered by a dead-man switch.

Zero-Knowledge Interactive Proof (ZKIP): A cryptographic protocol that can be used to prove that an agent possesses a key (and by weaker implication, that otherwise normally functioning agents who have an incentive to respond properly to the challenge, but fail to do so, do not possess the key), without revealing any information about that key. Currently used for authentication, and in smart weapons for Identification Friend or Foe (IFF).

Smart Property: Software or physical devices with the desired characteristics of ownership embedded into them; for example devices that can be rendered of far less value to agents who lack possession of a key, as demonstrated via a zero knowledge interactive proof. Methods of implementing smart property might include OND (cf.), and engrained immobilizing or destructive devices to foil attempts to hot-wire the property.

Operation Necessary Data (OND): Data necessary to the operation of smart property. For example, a complex, proprietary firing sequence needed to operate a computerized engine, a CAD file needed to manufacture a specialized part, etc. To avoid theft of service, ZKIP is required to open an encrypted channel to the device. To avoid leaking the OND to Eve, tamper detection combined with a dead-man switch can be used on the device end of the channel.

Smart Lien: Sharing control of smart property between parties, usually two parties called the owner and the lien holder. This property may be in the proximate possession of the owner or the lien holder, corresponding to the common-law notions of "artisan's lien" and "innkeeper's lien" respectively. Might be used to secure lines of credit, insurance policies, and many other kinds of contracts that involve smart property.

Security: Represents a basic asset, such as a share of ownership (stock) or a claim debt (bonds, cash).

Contingent contract: Contains terms which depend on the choice of a party or a state of the world. An option is an example of a contingent contract.

Derivative: A call or put option, future, or synthetic asset;such a contract is "derived" from a basic underlying security.

Synthetic asset: A derivative constructed, or "synthesized", by combining securities and other derivatives. Cash flows for sophisticated synthetics can be calculated to high precision, by means of finely grained decision trees.

Cash flow: The expected sequence of payments according to the terms of a contract. From cash flow can be computed the basic financial objectives of a contract, such as net present value.

Copyright © 1995 by Nick Szabo

Permission to redistribute without alteration hereby grantedScarce Objects

Nick Szabo Originally published in 2004

Abstract

A more intuitive and secure approach to programming with objects distributed across trust boundaries is presented. The approach involves scarce objects and software to support markets in trading scarce objects "rights."

Introduction

Scarce objects are computational objects that like physical objects are finite and excludable, and force the client to either conserve or consume (use up) their own rights to use the object. References to scarce objects are bearer certificates with two key properties: (1) they are use-once or use-N-times tokens, and (2) like digital cash they are transferred using online clearing using "spent lists" to conserve the number of these scarce object references.

Scarce objects, a.k.a. conserved objects, provide a user and programmer friendly metaphor for distributed objects interacting across trust boundaries. (To simplify the language, I will use the present tense to describe architectures and hypothetical software). Scarce objects also give us the ability to translate user preferences into sophisticated contracts, via the market translator described below. These innovations will enable us for the first time to break through the mental transaction cost barrier to micropayments and a micromarket economy.

A scarce object is a software object (or one of its methods) which uses a finite and excludable resource – be it disk space, network bandwidth, a costly information source such as a trade secret or a minimally delayed stock quotes, or a wide variety of other scarce resources used by online applications. Scarce objects constrain remote callers to invoke methods in ways that use only certain amounts of the resources and do not divulge the trade secrets. Furthermore, scarce object wrappers form the basis for an online economy of scarce objects that makes efficient use of the underlying scarce resources.

Scarce objects are also a new security model. No security model to date has been widely used for distributing objects across trust boundaries. This is due to their obscure consequences, their origins in single-TCB computing, or both. The security of scarce objects is much more readily understood, since it is based on duplicating in computational objects the essential intuitive features of physical possessions. Our brains reason in much more sophisticated ways about physical objects than about computational objects. Scarce objects are thus readily understood by programmers and end users alike. Scarce objects lower mental transaction costs, which are the main barrier to sophisticated small-scale commerce on the Net. Finally, scarce objects will solve for the first time denial of service attacks, at all layers above the primitive scarce object implementation.

The intuitive physical metaphor of scarce objects gives scarce objects the following basic properties:

Conservation of atomic objects Hierarchical composition of objects (analogous to spatial composition)

Closely related to these is a social property of objects critical to the success of economies:

A clear delineation of property rights and responsibilities. In other words, minimal externalities. Property rights specify residual control and liability over states of the world for which specific obligations or rights are not completely specified in contracts.

Property rights and contracts are highly evolved methodologies for dealing with economic objects and each other across trust boundaries. Scarce object architecture can reuse this working paradigm, because it reuses the mental model of the physical world in which this security paradigm was invented.

With scarce objects, any computation across trust boundaries will have these properties of atomicity, conservation, composition, and the accompanying clear delineation of rights and responsibilities. This model is rather restrictive compared to what we are used to within trust boundaries. However, it will much more readily keep programmers from writing obscurely insecure code, which is easy to do with either ACLs, capabilities, or cryptography. Furthermore, conservation (scarcity) and lack of externalities are the two major assumptions of microeconomics, the study of commercial transactions across trust boundaries. So the scarce objects security model allows us to inherit a rich literature of formal reasoning about such systems.

Scarce objects are, in other words, online commodities. These commodities may represent, typically, rights (or expectations) to services – the right to use an e-mail or news service (or a component of that bundle of rights, e.g. the right to use that service’s e-mail server), the right to upload or cache content, the "right" (here more like an expectation) to have e-mail read (digital postage to prevent spam), etc. Such service rights will usually be limited against the client by time or resource usage or number of invocations. When represented properly, by scarce objects, these services are conserved. Such "rights" or codified expectations are enforced against the server by reputation, by the "physics" of scarce objects, or both, in substitute for or in addition to expensive traditional legal means.

Scarce objects may also represent unique or finite relationships between people and bits – names that correspond to addresses, ownership of trademarks, authorship of content, ownership of certain rights to content (which probably does not, for security reasons, include the right to exclude others from copying the bits), etc.

Scarce objects are not a complete model of computation across trust boundaries. Indeed, there are many smart contracts that can be implemented with cryptographic protocols and/or secure hardware but not with scarce objects. What scarce objects provide is a straightforward basis for implementing, in an intuitively secure way, the anonymous commodity exchange economies formalized in microeconomics in a P2P fashion on the Internet.

Another area important to scarce objects is in reasoning about supply chains. In distributed objects, the call graph is the supply chain. To stretch call graphs across trust boundaries, we must replace rigid client-server relationships with dynamically adaptable customer-supplier relationships. The ideal here is to create a rich toolset of exception handling across trust boundaries. Note that credit risks are a proper subset of supply chain risks. Ka-Ping Yee recently put the supply chain problem succinctly: "be wary of return values from objects you don't trust."

Usage Control vs. Access Control

The scarce object architecture suggested here shares some things in common with capabilities, but it secures more kinds of resources and is far more affordable for users and programmers. Capabilities (along with ACLs) are a means of implementing access control. Access control simply deals with the first-level of issue of whether an entity has access or not to a given resource. If an entity has such access, this access is, as modelled or implemented by basic capabilities or ACLs, effectively unlimited in scope. Scarce objects, on the other hand, limit resource usage in three ways – first, by limiting the amount of resources used per invocation, second, by limiting the number of resources used per right (per ticket), and third, by limiting the number of tickets issued.

Scarce Objects and POLA

A raw distributed capability system (i.e. what Mark Miller refers to as "caps-as-data", to distinguish from capabilities local to the TCB ("object caps") which have strictly stronger security properties) give out capabilities of infinite duration and unlimited invocations, cannot be considered to be a true principle of least authority (POLA) system. For an object reference to implement POLA, it must be finite in every dimension. A true POLA system never gives out more authority than is necessary and proper to compute the needed function. It is never either necessary or proper to allocate infinite resources, and usually it is not necessary to allocate large resources. The scarce object architecture is the first design for object systems to achieve finite authority, and to allow small allocations for objects that need only small amounts of resources. Scarce objects are thus the first architecture to make true POLA possible.

Scarce Object Architecture

Scarce object architecture depends on a distributed object architecture that makes minimal security assumptions. A good implementation strategy may be therefore to implement this model on top of E. No sophisticated use of its distributecd capability architecture need be made to securely distribute scarce objects; rather the resource-conserving features of scarce objects can be relied on for securing resources.

A bearer right to invoke a scarce object method takes the form of a bearer certificate, or ticket. It can be generic, meaning a right to an N invocations of one of a set of similar or identical objects, or specific, meaning a right to invoke a particular object method in a unique way. Generic rights are fungible and can be transferred unlinkably, using Chaumian blinding.

The general steps to build a scarce object are (1) define a normal object, then (2) wrap it in a layer that protects its public methods using tickets. Our sketch of the architecture here describes how this wrapping layer can work.

The wrapping layer involves three different servers: a transfer agent (TA), a Provider, and an Issuer. The Issuer and TA operate like an accountless digital cash mint. The Issuer signs tickets. The TA clears the transfer of tickets for generic rights. Both the Issuer and TA have copies of the private keys ("plates") corresponding to each issue of generic right. A particular kind of generic right (e.g., a particular denomination of digital coin) can have multiple issues, usually ordered sequentially. Digital cash is a special case: money is the most generic of rights. Here is another example of a generic right, or class of fungible objects: "A queriable SQL database with up to 10 MB of storage, and certain standard response time guaruntees".

It is a design option whether to combine the Issuer and TA into a single server (thereby reduce exposure of the private key) or keep them separate (thereby enable certain personell controls based on separation of duties). Distributed servers, described below, are an even better way to increase the trustworthiness of Issuers and TAs.

The Provider is responsible for actually holding the object, which can contain unique state. It publishes a signed description of its scarce object method, describing a particular kind of generic right (e.g. in the form of design-by-contract pre- and post-conditions). The issuer and transfer agent then create plate(s) and prepare to issue tickets for the method.

Any or all of these component servers can be distributed, using the methods described here and here. A distributed signature is used to issue tickets (M out of N must sign using a distributed private key for a verifiable signature to be produced). Such distribution greatly reduces exposure to breach of trust and thus lowers the mental transaction costs of reputation tracking.

To implement exclusive transfers, the TA keeps a list of cancelled ticket numbers. A ticket is cancelled whenever it is transferred or used. The Provider instructs the TA when a ticket has been used, or alternatively they both write to a shared list of cleared tickets.

The TA and Issuer see only classes of fungible objects. The Provider and users see particular instances with unique state. In the above example of a database generic right, the Provider sees a database filled with unique information while the TA and Issuer see only the generic description of the database object invocation methods.

In contrast to the servers, the remote user of a scarce object wraps his object invocation stub with calls that trade for needed tickets (again using a market translator), send the tickets as needed with method invocations to those methods’ Provider(s). In some (hopefully many) cases sufficiently identical generic services will be provided by competitors. Where this occurs a "ticket client" may also "shop around" in the sense that if the pre- or post-conditions of the method invocation fail, or if the invocation is otherwise detected as faulty, the ticket client will retry by invoking the competitor's method.

The Provider server is almost just another ticket client to the TA, which like other clients can transfer or receive tickets. It special role is in informing the TA when tickets have been used thus should be cancelled (or, altrneatively, writing the cancelled ticket number directly to a list of cancelled ticket numbers that it shares with the TA). Only the Issuer can create tickets, and only the Provider can consume them.

At the core of the Provider is the raw object itself, the set of methods that provide the defined services for scarce object clients. The Provider is the wrapper around this object. Besides its gatekeeping, ticket verification, and ticket consumption functions, the Provider can keep track of and inform the Issuer regarding resource usage.

The Issuer in turn is the interface to the micromarket functions, especially the market translator described below. The Issuer may, for example, via a market translator, which incorporates the preferences of the person who operates the Provider, negotiate barter deals in which certain tickets are issued and exchanged for certain other tickets giving rights to invoke the counterparty's or a third party's scarce object methods. The negotiations might also be multi-party, i.e. auctions, and secondary exchanges for generic rights may also be developed for scarce object tickets. In turn, the market translator, to enable automated (low mental transaction cost) bartering operations, depends on the existence of reasonably liquid online exchanges of generic scarce object rights.

The TA generates ticket supply only at the behest of the Issuer, and destroys it only at the behest of the Provider. All its own transfers conserve the supply of a particular generic right. The Provider is also responsible for the delivery of service to the client that satisfies the service description (contract, e.g. pre and post conditions), at which time the Provider "deposits" the generic ticket(s), i.e. adds them to the cancelled list.

The Provider issues along with the initial generic rights ticket a signed affadavit, machine or human readable, describing aspects of the object which may be non-exlusive and unique, along with that instance's ticket number and the public key(s) of the generic right(s) for which it is valid. For example, it might say "a database containing quotes of these two dozen listed stocks as of 12:22 pm Monday", without actually containing those quotes. Often such description is worth more when bundled with generic exclusive rights, such as the right to a fast response time. The specific rights can elaborate in unique ways upon the generic rights, as long as these elaborations are not taken to define exclusive rights. The generic rights let the TAs garuntee exclusivity to users and conservation of resources to Providers, while the specific rights describe the unique state to any desired degree of elaboration. The Provider must be prepared to service any specific promise it has issued, as long as it is accompanied by the proper conserved generic tickets.

This method of composing specific and generic rights, transferred as a bundle but with exlusive generic atoms cleared by different TAs, allows arbitrarily sophisticated rights bundles, referring to objects with arbitrarily unique state, to be transferred unlinkably. A wide variety of derivatives and combinations are possible. The only restriction is that obtaining rights to specific exclusive resources must either be deferred to the consumption phase, or transferred with online clearing via expensive communications mix.

If the Provider wished to garuntee exclusivity to a specific right, transfer seems to require an expensive communications mix between Provider and transferee, rather than a cheap blinded ticket. For example, "Deep Space Station 60 from 0500-0900 Sunday" or "a lock on autoexec.bat now" demands exclusivity to a specific right, and thus seems to require a communications mix to unlinkably transfer. On the other hand, "A one hour block on DSS-60 in May" and "the right to lock autoexec.bat at some point" are generic and can be transferred privately with the much less expensive blinding, given a sufficient population of other ticket for this class of generic right transfered between the issuance and consumption of a given ticket.

Clients can deal with the TA without a communications mix. They deal with the Provider via a communications mix. If both the initial and final holders failed to do this, the Provider could link them. If just the final holder failed to do so, the Provider could identify him as the actual user of the resource. Thus for full privacy generic transfers are cheap, and nonexclusive transfers are cheap, while specific exsclusive transfers and actually using the object seem to require the expensive communications mix.

Here's a review of our architecture:

Composable conserved atomic objects (scarce objects proper):

Tickets (bearer contracts) are digital certificates, issued by trusted or distributed issuers. Each kind of ticket represents a specific and limited right to a scarce object – for example the right to invoke a method on that object (i.e., use a service provided by that object) up to N times, or up to a certain resource usage limit. Tickets are an essential part of the "object wrapper" that makes a scarce object look and act scarce.



Distributed issuers, which maintain property titles for certain bearer contracts, namespaces, and other otherwise insecurely conserved publically identifiable entities.



Design by contract (e.g., detailed specification and testing of pre- and post- conditions) as a central rather than optional part of object programming.

An advanced scarce object infrastructure may also include:

Exception handling as bankruptcy or contract breach procedure, to convert rigid client-server relationships into mutually beneficial and dynamically reconfigurable (competitive) customer-supplier relationships, suitable for object invocation across trust boundaries.



Reputation tracking of the behavior of supply chains. Cryptographic protocols, such as those used to create unforgeable and confidentially auditable transaction logs, can be used to improve the privacy vs. reputation information tradeoff, as long as they are hidden under an intuitively clear metaphor for the reputation of supply chain behavior.

Scarce objects, by creating a simpler and far more intuitive model of computation across trust boundaries, can make the distribution of objects on the global Internet a reality, just as the simplification of hypertext into HTML made the Web a reality.

Diagram of Proposed Scarce Object Architecture

Click for larger version

Shopping for Scarce Objects – The Market Translator

The mental transaction cost problem is one that underlies all markets – the mental effort it takes to shop – to map private preferences to prices to decide whether a bundle of rights is worth the cost. In particular this problem presents a severe barrier to micropayments and market-based resource allocation for networks and computers.

The market translator is aimed squarely at solving, for the first time, this problem for Internet commerce. A market translator both enables and depends on online micromarkets to automate resource allocation among scarce objects. It will do so by enabling the following:

Expression of preferences – and their translation into codified expectations, or rights and duties – with both user-friendly GUIs ("source language") and a formal contract language ("target language"), and translation between them.

The bundling and recombination of sophisticated structures of rights.

The input of user preferences, and their translation from human expressible to computer readable form.

The Problem

The problem of "translating" between bearer contracts (which represent and secure rights to scarce objects) can be cast as a problem of translating between monetary currencies. For our purposes, a "currency" in a scarce object economy is simply any kind of bearer contract used for holding and transferring wealth, rather than for consumption by the holder. It is thus a "collectible" (or "intermediate commodity", to use Carl Menger’s term). The market translator, incidentally, makes the O(n^2) prices in a barter economy, versus O(n) in a monetary economy, a far less important distinction.

So let’s look at currencies. Let's say small businessman Alice is negotiating cyberspace contracts with Bob, Charlie, etc. Typical of international contracts, terms can be denominated in a variety of ways. These are potentially unreliable: Joe-Bob's remailer postage, U.S. Federal Reserve Notes in their 1970s mode (or in 2003), Seychelles gold cache warehouse receipts, "Asian Tiger" currencies in 1997, and so on.

Unreliable currencies can play havoc with:

contractual terms of long duration long term accounting of one's own budget in a consistent manner.

Each problem interferes with potential solutions to the other. On the one hand, picking one single best currency for all contracts concentrates risk. In some cases there is nothing close to a reliable currency, and in any case diversification is preferable. Without hedging Alice remains exposed to risks that more sophisticated traders can easily hedge.

Another way of looking at it: there are no issuers in the world who are 100% trustworthy and 100% reliable. Lacking a security protocol to ensure that a currency retains its value, Alice needs risk management.

On the other hand Alice, to plan her (personal and/or small business) budget and properly express her preferences, needs a simple, consistent long-term unit of account. Budgeting with a single fluctuating currency is bad enough, but if Alice denominates different expenditures and revenues in different currencies, her budget becomes an inconsistent mess. It's also unreasonable to ask a non-financial professional to worry about the finer points of exchange rates, hedging, etc.

What is Alice to do? Old answer: Alice either hires, at a cost of both money and privacy, an accountant or financial planner, and may gain a few crude improvements. Mostly, she's out of luck: small businessmen have left most international trade to big corporations, whose finance officers partake in sophisticated hedging strategies.

Proposed new answer: use a market translator to help Alice draft her contracts. This market translator should be useful for both normal law-enforced contracts and untraceable self-enforcing contracts, where the latter are feasible. In the following post I will sketch how a market translator can work.

A Solution

Automatic currency conversion, as done today by some credit cards and ATM machines, is a useful primitive kind of market translation. The casual reader (and user) can think of the market translator (MT) as a fancy kind of automated currency convertor, and get the basic gist of it. The MT serves to convert, hedge, and in general restructure the payment terms contracts negotiated in any manner.

Our main novelty is to account for personal budgets, not in terms of any external standard of value, but rather in terms of personal accounting units (PAUs). PAUs correspond to what Alice can express of her personal utility. The MT determines Alice's static and and temporal preferences from the budget Alice already maintains (for example, her small business budget in Quicken). Additional preference specification forms may be provided beyond those of a normal budgeting program. For example, Alice’s software preference settings, her behavior with keyboard and mouse, and similar clues might be usefully interpreted as economic preferences, for example with regard to where to allocate scarce screen real estate and network bandwidth.

For convenience Alice's PAU might correspond to the local currency most commonly used by Alice. If most of Alice's budget items deal with online contracts negotiated via MT, then using the local currency is by no means necessary, and is undesirable if that currency is unstable.

Here is a diagram showing Alice and Bob negotiating a contract using their market translators:

Alice Bob Draft Contract, "source" Draft Contract, "source" (Alice PAUs) (Bob PAUs) ^ ^ | | MT MT | | v v Draft Contract, "target" Draft Contract, "target"

One mode in which the MT can be used is to have Bob offer a take-it-or-leave-it binary contract, corresponding to the current retail practice of take-it-or-leave-it prices. In the mode pictured above, Alice and Bob negotiate back and forth. The negotation of the source contract terms will usually be manual. The "source language" will typically be a human readable GUI, while the "target" will be a standard formal contract language. If Alice and Bob can input preferences leading to automated negotiations, then a "shopping bot" and "catalog bot" respectively may be used. This is a layer above and beyond the scope of the MT. The MT is only a "shopping bot" in the restricted but important area of contracts composed of atomic bearer contracts – rights to scarce objects – to the extent that the price relationships between these bearer contracts are available from quoted markets.

The MT acts like a computer language compiler. But it translates both ways, and in real time as Alice and Bob negotiate payment terms. So, for example, Alice changes a term in her contract, proposing to pay fewer Alice-PAUs for Bob's services. Her MT translates this into a series of payments and hedges: a sophisticated synthetic contract as obscure to Alice and Bob as binary code is to many programmers these days. This synthetic is constructed out of liquid market securities (bearer contracts) and derivatives of low transaction cost. A synthetic contract is naturally represented as a composite object, a part-whole hierarchy composing primitive contractual "atoms", such as securities and derivatives.

Bob's MT reverse-translates the actual market terms into Bob-PAUs. Although they each agree to different looking amounts of payment, the visible structure besides amounts and the complete underlying contract is the same. They can be confident that when their preferences have been satisfied, their minds have met and they can commit to the contract.

As a result, both Alice and Bob see the contract in terms of their own consistent personal utility units. All consideration of exchange rates, inflation risks, and so on is handled by the MT.

Alice and Bob's MTs can make side conversions, hedges, and restructurings to balance their portfolios. These side hedges are not revealed to each other. Any binary terms which can be side hedged can be made almost arbitrarily distant from what Alice and Bob prefer financially. Thus Alice and Bob need not reveal their financial preferences to each other.

(Note: For contracts with delayed payment terms, Alice and Bob determining the credit risk caused by each others' credit exposures is an important problem, but beyond the scope of the MT as I have described it).

The whole set of Alice's contracts with all her counterparties constitutes her complete portfolio – not merely a segregated investment portfolio, but a complete portfolio encompassing all her finances. This portfolio is is represented as a composite of composite contracts, and forms the basis for all of Alice's financial planning, and for the automated portfolio rebalancing activity of the MT.

The main data structure representing the contracts for analytical purposes is the chance/choice decision tree. This tree has two kinds of nodes, "chance" nodes which iterate through all material possibilities, and "choice" nodes where the optimal choice is made. The result is the expected value of a set of contractual terms. The trees can represent a large number of contracts with low resolution (lots of pruning and heuristics), or a simple contract with high resolution (all possibilities considered). Desktop computers are or will soon be fast enough to search through thousands of contingencies, and synthetic contracts composed of hundreds of atomic contracts, with delays less than Internet latencies. So the binary contract can be a very sophisticated synthetic, as long as its analysis is fully automated, and still conserve mental transaction costs.

Conclusion

The MT relies on online, automated exchanges hosting liquid markets for fixed income securities and derivatives. These markets reveal the information the MT needs to properly hedge currencies. Market makers and arbitrageurs maintain these markets, ensuring the most accurate information on risk premiums, yield curves, and so on is available to MTs. Some information not automatically derivable from market prices might be made available online by financial consultants, in a standard format, downloadable by MTs for a fee.

The source contract is normally negotiated and closed manually, as per normal shopping. The MT is a a "shopping bot", but only in the very restricted but important realm of finance related to payment terms. Since

Alice has sufficiently input her financial preferences for risk and time value, via her budget program and/or specialized forms, and these preferences apply to all the payment terms used by the MT, All the information necessary to determine the risk posed by a payment term is available online (usually in the form of market prices for securties and derivatives, but also from online financial consultants who publish financial news in MT-readable format), and By assumption all the hedging securities and derivatives can be automatically purchased or sold by the MT,

there should be no need for manual intervention in the hedging translation process. If such manual intervention is required, the system very quickly loses its appeal for most users.

If the preference or market information is not available, or the securities and derivatives exchanges are not available, the market translator can revert back to simple automated currency conversion.

The market translator thus solves a vexing problem faced by multinational small business, the hedging of payment terms using potentially unreliable currencies. More generally, the market translator built on a scarce object architecture will lower the mental transaction cost barrier to micropayments and micromarkets. It will translate skills and preferences into microrights and microduties for use in fine-grained allocation of resources and services – whether online e-mail accounts, online game collectibles, screen real estate, network bandwidth and caching, or a variety of other network objects which, thanks to scarce object architecture, become economic objects.Negative Reputation

Nick Szabo 1996



An important and general problem seems to be that of tagging a negative behavior source for future recognition. The tag might be used for negative information shared publically (eg, credit ratings) or kept private (eg, kill files). The behavior source might be non-human (eg, recognizing virus patterns for the purposes of virus scanning). Where the behavior source is adaptable and self-interested, it has an incentive to spoof the tagging: a debtor to change names to avoid paying his debt, a virus to scramble its pattern to avoid scanning, and so on. If the tag carries a greater positive reputation (where zero is the reputation of a newcomer) this incentive is lost and the negative side of the reputation — the disreputation — must be borne.

Can digital credentialling systems facilitate such negative reputation handling?

Service-specific, aka local, nym reputation may not be able to accomplish such tracking of negative reputation. If a local nym accumulates more negative than positive credentials, it can simply be replaced by a newcomer local nym for this service, without harming the positive reputation capital of the other behavior source local nyms. Hostile sources can continuously spoof innocent newcomers. Counterparties lose the ability to determine a history of previous hostile behavhior — kill files, virus scanning, credit ratings, etc. fail.

Chaumian credentials also give the credential holder control over the transfer of credentials between his local nyms, creating an incentive to show positive credentials and hide negative ones. To remedy this, counterparties can demand "non-negative credentials" (in a form such as, "Alice in many transactions recorded by me in area X has never done bad things x,y,z"), Non-negative credentials are limited to areas that can be well-tracked. One such may be credit ratings, as long as one is doing the bulk of one's credit transactions through is-a-person linked local nyms.

Where Chaumian credentials are inapplicable, we might raise the cost of entry to be greater than that of a newcomer. This gives us two clearly defined reputation points to compare on an otherwise rather subjective scale: participation threshold and newcomer reputation. Both are subjective in the eye of the party choosing whether or not to participate in an activity with the nym.

A participation threshold greater than newcomer reputation clashes with the desirable goal, that one be able to make a fresh start. For that matter, unless previous nyms and their positive reputations are linked to their new nyms, the pioneers cannot make a start, so that the institution itself cannot be started. Ditto for for institutional growth.

Tags that bundle the results of a wide variety of transactions — global nyms, aka universal IDs, aka "True Names" — seem to provide the most incentive for parties to carry their negative credentials. Most people have accumulated enough positive reputation is some areas that it is well-nigh impossible for them to start over their entire lives as newcomers.

A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.

A big problem arises with negative credentials when they are used, not merely to avoid engaging in a particular activity with a party, but for retribution against that party. Retribution may take some nonviolent online form, such as slander, denial of service attack, and so on, but the most worrisome form of retribution is a violent physical attack. Could we have digital tags that, while tracking negative behavior sources through the digital world, remain strictly unlinked to any kind of physical location data? Alas, we have several important systems, such as cellular phones, shipping addresses, etc. that provide such linkage.

The question may become one of deciding what of these three dimensions are most important, and how they can be traded off:

The gains to be had from tracking and thereby avoiding negative behavior sources

The gains to be had from a nonviolent digital world (ie, a virtual realm within which any digital action can have no physically violent consequences).

The inconvenience (and perhaps impracticality) of partitioning the physical and digital worlds into different ID systems (more realistically, some "pure" subset of the digital world completely partitioned from location devices, physical shipping information, etc.)

Keep in mind too, that in practice these are evaluated primarily by a market evolving from its current state, rather than by abstract ethical philosophies.

Robin Hanson has noted that in a world of global nyms, the use of a local nym may signal the hiding of negative credentials, so that the use of global nyms is in equilibrium. A further problem with local nyms is that our relationships are often not neatly compartmentalizable into standard service types, and even where they are we might like to expand them into new areas. I suggest that, at minimum, we will want to reveal progressively more local nyms to our counterparties as our relationships with them become closer and more co-exposed.

While the global nym equilibrium may hold for many of our relationships, there may be plenty of areas where the privity benefits of localizing nyms outweigh the costs of being less or unable to differentiate newcomers from hostiles. (By "privity" I refer the entire general task of protecting relationships from hostile third parties; confidentiality and protection of property from theft are two examples of privity). For example, the preference-tracking service at www.firefly.com increases participation via the use of pseudonyms, and suffers little exposure from hostiles. On the other hand, credit transactions typically demand identifying information, because the contractual exposure typically outweighs benefits of privity.

Global nym public keys, which have many drawbacks in terms of privity, may be the best way to track negative reputation, but they are no panacea. There is an important conundrum in an ID-based key system: the conflict between the ability to get a new key when the old one is or could be abused by another (key revocation), and the ability of another to be sure they are dealing with the same person again. This may also provide an opportunity for parties to selectively reveal positive credentials and hide negative ones. For example, a person with a bad credit rating could revoke the key under which that rating is distributed and create a new one, while selectively updating their positive credentials to the new key (eg, have their alma mater create a new diploma). Key revocation authorities might combine forces with credit rating agencies to avoid such erasure of negative history, but this gives them even more centralized control — not merely over IDs but over important elements of reputation associated with those IDs. This further violates the principles of separation of powers and segregation of duties, providing added opportunity for fraudulent issue or revocation of IDs along with fraudulent communication of reputation information.

The current universal (non-cryptographic) key in the U.S., the SSN, is very difficult to revoke. Much easier to change your name. This policy is probably no accident, since the biggest economic win of global nym identification is the tracking of negative reputations, which revocation can defeat. As long as the SSN is a shared database key, not used for the purpose of securely identifying a faceless transaction, there is little need for revocation beyond the undesired erasure of negative history. Combining a secret authentication key, which must be revocable, with a public universal ID is quite problematic.

Copyright © 1996 by Nick Szabo

Permission to redistribute without alteration hereby granted